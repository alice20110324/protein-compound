{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3985fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-fa30c2b7a15e>, line 156)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-fa30c2b7a15e>\"\u001b[1;36m, line \u001b[1;32m156\u001b[0m\n\u001b[1;33m    teacher_model=\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.multiprocessing as mp\n",
    "from torch.cuda.amp import GradScaler\n",
    "from loader1 import MoleculeDataset,MoleculeDatasetBig, SeqDataset,SeqMolDataset,SmileDataset#########################\n",
    "import torch\n",
    "import torch\n",
    "#import args\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "#from loader import MoleculeDataset#################\n",
    "#from torch_geometric.data import DataLoader\n",
    "#from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import GNN, GNN_graphpred,GNN_graphpred_1\n",
    "\n",
    "\n",
    "from splitters import scaffold_split,scaffold_split_1\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tensorboardX import SummaryWriter\n",
    "#import esm2_t33_650M_UR50D\n",
    "import esm\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import rank_zero_warn, rank_zero_only, seed\n",
    "#from finetune.tokenizer.tokenizer import MolTranBertTokenizer\n",
    "from fast_transformers.masking import LengthMask as LM\n",
    "#from rotate_attention.rotate_builder import RotateEncoderBuilder as rotate_builder\n",
    "from fast_transformers.feature_maps import GeneralizedRandomFeatures\n",
    "from functools import partial\n",
    "from apex import optimizers\n",
    "import subprocess\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "#from utils import normalize_smiles\n",
    "import sys\n",
    "sys.path.append('finetune/')\n",
    "from utilss import normalize_smiles\n",
    "from tokenizer.tokenizer import MolTranBertTokenizer\n",
    "from rotate_attention.rotate_builder import RotateEncoderBuilder as rotate_builder\n",
    "#from SeqMolModel import InteractionModel,InteractionModel_1,SequenceModel,InteractionModel_4\n",
    "#from SeqMolSmile import InteractionModel_4\n",
    "#from SeqMolModel import InteractionModel_4\n",
    "from SeqMolSmile_model2 import InteractionModel_4\n",
    "#print(torch.cuda.is_available())\n",
    "import torch\n",
    "torch.cuda.current_device()\n",
    "torch.cuda._initialized = True\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--device', type=int,default=0,\n",
    "                        help='which gpu to use if any (default: 0)')#0000\n",
    "parser.add_argument('--gpu',default='0,1,2')\n",
    "parser.add_argument('--batch_size', type=int, default=16,\n",
    "                        help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=400,\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.1,\n",
    "                        help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--lr_scale', type=float, default=1,\n",
    "                        help='relative learning rate for the feature extraction layer (default: 1)')\n",
    "parser.add_argument('--decay', type=float, default=0,\n",
    "                        help='weight decay (default: 0)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                        help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                        help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.5,\n",
    "                        help='dropout ratio (default: 0.5)')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                        help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                        help='how the node features across layers are combined. last, sum, max or concat')\n",
    "parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "parser.add_argument('--dataset', type=str, default = 'davis', help='root directory of dataset. For now, only classification.')\n",
    "#parser.add_argument('--input_model_file', type=str, default = 'None', help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--input_model_file', type=str, default = 'Mole-BERT', help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--filename', type=str, default = '', help='output filename')\n",
    "parser.add_argument('--seed', type=int, default=42, help = \"Seed for splitting the dataset.\")\n",
    "parser.add_argument('--runseed', type=int, default=0, help = \"Seed for minibatch selection, random initialization.\")\n",
    "parser.add_argument('--split', type = str, default=\"scaffold\", help = \"random or scaffold or random_scaffold\")\n",
    "parser.add_argument('--eval_train', type=int, default = 1, help='evaluating training or not')\n",
    "parser.add_argument('--num_workers', type=int, default = 8, help='number of workers for dataset loading')\n",
    "#parser.add_argument('--gpu', type=int, default=0, help='')\n",
    "parser.add_argument('--rank',type=int,default=0,help='')\n",
    "parser.add_argument('--world_size', type=float,default=0.1,help='')\n",
    "parser.add_argument('--dist_backend ',type=str, default='nccl',help='')\n",
    "\n",
    "parser.add_argument('--n_head', type=int, default = 12, help='number of workers for dataset loading')\n",
    "parser.add_argument('--local_rank',type=int,default=0,help='')\n",
    "parser.add_argument('--n_layer', type=int, default = 12, help='number of workers for dataset loading')\n",
    "parser.add_argument('--d_dropout', type=float, default = 0.1, help='number of workers for dataset loading')\n",
    "parser.add_argument('--n_embd', type=int, default = 768, help='number of workers for dataset loading')\n",
    "parser.add_argument('--dropout', type=float, default = 0.1, help='number of workers for dataset loading')\n",
    "parser.add_argument('--lr_start', type=float, default =  3e-5, help='number of workers for dataset loading')\n",
    "parser.add_argument('--max_epochs', type=int, default = 500, help='number of workers for dataset loading')\n",
    "parser.add_argument('--num_feats', type=int, default = 32, help='number of workers for dataset loading')\n",
    "parser.add_argument('--checkpoint_every', type=int, default = 100, help='number of workers for dataset loading')\n",
    "parser.add_argument('--seed_path', type=str, default =  'data/checkpoints/N-Step-Checkpoint_3_30000.ckpt', help='number of workers for dataset loading')\n",
    "parser.add_argument('--dims', type=list, default = [ 768, 768, 768, 1], help='number of workers for dataset loading')\n",
    "\n",
    "args = parser.parse_args(args=[])###############33\n",
    "import torch.nn.functional as F\n",
    "num_epochs=200\n",
    "def train(teacher_model, student_model,trainloader):\n",
    "    for epoch in range(num_epochs):\n",
    "        student_model.train()\n",
    "        teacher_model.eval()\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 生成教师和学生模型的输出\n",
    "        teacher_outputs = teacher_model(inputs)\n",
    "        student_outputs = student_model(inputs)\n",
    "\n",
    "        # 标准的交叉熵损失\n",
    "        #loss_ce = criterion(student_outputs, labels)\n",
    "\n",
    "        # 教师机与学生机输出的损失（比如使用均方误差）\n",
    "        loss_kd = F.mse_loss(student_outputs, teacher_outputs.detach())\n",
    "\n",
    "        # 组合两种损失\n",
    "        #loss = loss_ce + alpha * loss_kd  # alpha 是一个超参数，用于平衡两种损失\n",
    "        loss = loss_kd \n",
    "        # 计算损失并进行反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "if __name__ == '__main__':\n",
    "    teacher_model=\n",
    "    student_model=\n",
    "    trainloader=\n",
    "    train(teacher_model,student_model,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6669717",
   "metadata": {},
   "outputs": [],
   "source": [
    "davis_pd=pd.read_csv('dataset/pretrain_dataset/davis_train.csv',sep=',')\n",
    "kiba_pd=pd.read_csv('dataset/pretrain_dataset/kiba_train.csv',sep=',')\n",
    "\n",
    "two_pd = pd.concat([davis_pd, kiba_pd])\n",
    "two_pd=two_pd.drop_duplicates(inplace=True)\n",
    "two_pd.to_csv('dataset/pretrain_dataset/two_pd.csv')\n",
    "\n",
    "\n",
    "\n",
    "from loader1 import MoleculeDataset,MoleculeDatasetBig, SeqDataset,SeqMolDataset,SmileDataset\n",
    "from utilssssss import *\n",
    "smilesList=two_pd['compound_iso_smiles']\n",
    "sequenceList=two_pd['target_sequence']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec4d1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_file_train = 'dataset/processed/' + g_dataset + '_train.pt'\n",
    "processed_data_file_test = 'dataset/processed/' + g_dataset + '_test.pt'\n",
    "    \n",
    "df = pd.read_csv('dataset/' + g_dataset + '_train.csv')\n",
    "train_drugs, train_prots,  train_Y = list(df['compound_iso_smiles']),list(df['target_sequence']),list(df['affinity'])\n",
    "#XT = [seq_cat(t) for t in train_prots]#####################\n",
    "train_drugs, train_prots,  train_Y = np.asarray(train_drugs), np.asarray(train_prots), np.asarray(train_Y)\n",
    "\n",
    "\n",
    "# make data PyTorch Geometric ready\n",
    "print('preparing ', dataset + '_train.pt in pytorch format!')\n",
    "gnn_train_dataset = TestbedDataset(root='dataset', dataset=g_dataset+'_train', xd=train_drugs, xt=train_prots, y=train_Y,smile_graph=smile_graph)\n",
    "seq_train_dataset=SeqDataset('dataset/processed/'+g_dataset+'_train_sequence.csv')\n",
    "smiles_train_dataset=SmileDataset('dataset/processed/'+g_dataset+'_train_smiles.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_train_dataloader=torch_geometric.data.DataLoader(gnn_train_dataset,batch_size,num_worker,shuffle)\n",
    "seq_train_dataloader=torch.util.data.DataLoader(seq_train_dataset,batch_size,num_worker,shuffle)\n",
    "smiles_train_dataloader=torch.util.data.DataLoader(smiles_train_dataset,batch_size,num_worker,shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    seq_embd_dim=1280\n",
    "    output_embd_dim=256\n",
    "    teacher_model=SeqTeacher(1280,256)\n",
    "    teacher_model.cuda()\n",
    "    \n",
    "    student_model=SeqMLPStudent()\n",
    "    student_model.cuda()\n",
    "    \n",
    "    train(teacher_model, student_model,train_loader=seq_train_loader)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
