nohup: ignoring input
Global seed set to 42
True
Not from scratch
rese:model_gin
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Pre-processed data found: /media/ext_disk/zhenfang/dataset/davis/processed/davis_train_mols.pt, loading ...
seq_train_dataset: <class 'pandas.core.series.Series'>
seq_train_dataset: <class 'loader.SeqDataset'>
scaffold
fold: 0
/home/zhenfang/anaconda3/envs/pytorch_3.8/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
fold,epoch,train_loss: 0 0 661048.56
/home/zhenfang/anaconda3/envs/pytorch_3.8/lib/python3.8/site-packages/fast_transformers/feature_maps/fourier_features.py:37: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)
  Q, _ = torch.qr(block)
fold,epoch,train_loss: 0 1 36.227844
fold,epoch,train_loss: 0 2 26.920412
fold,epoch,train_loss: 0 3 17.565132
fold,epoch,train_loss: 0 4 9.906383
fold,epoch,train_loss: 0 5 4.8410788
fold,epoch,train_loss: 0 6 2.2702298
fold,epoch,train_loss: 0 7 1.3319497
fold,epoch,train_loss: 0 8 1.1074427
fold,epoch,train_loss: 0 9 1.0774065
fold,epoch,train_loss: 0 10 1.0740036
fold,epoch,train_loss: 0 11 1.0738709
fold,epoch,train_loss: 0 12 1.0741184
fold,epoch,train_loss: 0 13 1.0742221
fold,epoch,train_loss: 0 14 1.0763084
fold,epoch,train_loss: 0 15 1.0745127
fold,epoch,train_loss: 0 16 1.0748448
fold,epoch,train_loss: 0 17 1.0744095
fold,epoch,train_loss: 0 18 1.0774102
fold,epoch,train_loss: 0 19 1.0753158
fold,epoch,train_loss: 0 20 1.0760409
fold,epoch,train_loss: 0 21 1.077844
fold,epoch,train_loss: 0 22 1.0832912
fold,epoch,train_loss: 0 23 1.0823531
fold,epoch,train_loss: 0 24 1.0833151
fold,epoch,train_loss: 0 25 1.0795588
fold,epoch,train_loss: 0 26 1.0865704
fold,epoch,train_loss: 0 27 1.0871079
fold,epoch,train_loss: 0 28 1.0906255
fold,epoch,train_loss: 0 29 1.0890689
fold,epoch,train_loss: 0 30 1.0895518
fold,epoch,train_loss: 0 31 1.0852815
fold,epoch,train_loss: 0 32 1.0922292
fold,epoch,train_loss: 0 33 1.0856069
fold,epoch,train_loss: 0 34 1.0958751
fold,epoch,train_loss: 0 35 1.0903051
fold,epoch,train_loss: 0 36 1.090048
fold,epoch,train_loss: 0 37 1.086328
fold,epoch,train_loss: 0 38 1.0903776
fold,epoch,train_loss: 0 39 1.0888716
fold,epoch,train_loss: 0 40 1.0902985
fold,epoch,train_loss: 0 41 1.0891795
fold,epoch,train_loss: 0 42 1.0959057
fold,epoch,train_loss: 0 43 1.0811567
fold,epoch,train_loss: 0 44 1.092827
fold,epoch,train_loss: 0 45 1.0931703
fold,epoch,train_loss: 0 46 1.0869645
fold,epoch,train_loss: 0 47 1.0910003
fold,epoch,train_loss: 0 48 1.0878292
training Epoch: 50, train_Loss: 1.3094
training Epoch: 50, train_Loss: 0.5349
training Epoch: 50, train_Loss: 0.1657
training Epoch: 50, train_Loss: 0.7593
training Epoch: 50, train_Loss: 0.6958
training Epoch: 50, train_Loss: 1.3423
training Epoch: 50, train_Loss: 0.3233
training Epoch: 50, train_Loss: 0.6064
training Epoch: 50, train_Loss: 0.3612
training Epoch: 50, train_Loss: 1.1323
training Epoch: 50, train_Loss: 0.6808
training Epoch: 50, train_Loss: 1.4200
training Epoch: 50, train_Loss: 1.0172
training Epoch: 50, train_Loss: 0.7301
training Epoch: 50, train_Loss: 0.3351
training Epoch: 50, train_Loss: 0.3989
training Epoch: 50, train_Loss: 1.0115
training Epoch: 50, train_Loss: 1.0434
training Epoch: 50, train_Loss: 2.2502
training Epoch: 50, train_Loss: 0.9444
training Epoch: 50, train_Loss: 0.3719
training Epoch: 50, train_Loss: 1.8807
training Epoch: 50, train_Loss: 1.0647
training Epoch: 50, train_Loss: 0.9045
training Epoch: 50, train_Loss: 0.8297
training Epoch: 50, train_Loss: 1.7561
training Epoch: 50, train_Loss: 1.0498
training Epoch: 50, train_Loss: 0.6030
training Epoch: 50, train_Loss: 0.3528
training Epoch: 50, train_Loss: 0.5769
training Epoch: 50, train_Loss: 1.0817
training Epoch: 50, train_Loss: 1.9871
training Epoch: 50, train_Loss: 1.6940
training Epoch: 50, train_Loss: 0.4363
training Epoch: 50, train_Loss: 1.2627
training Epoch: 50, train_Loss: 1.2848
training Epoch: 50, train_Loss: 2.0433
training Epoch: 50, train_Loss: 0.4914
training Epoch: 50, train_Loss: 1.3115
training Epoch: 50, train_Loss: 1.4857
training Epoch: 50, train_Loss: 1.1780
training Epoch: 50, train_Loss: 0.7297
training Epoch: 50, train_Loss: 0.5385
training Epoch: 50, train_Loss: 1.1724
training Epoch: 50, train_Loss: 0.6435
training Epoch: 50, train_Loss: 0.7577
training Epoch: 50, train_Loss: 1.3808
training Epoch: 50, train_Loss: 1.5192
training Epoch: 50, train_Loss: 0.4651
training Epoch: 50, train_Loss: 3.2578
training Epoch: 50, train_Loss: 0.2292
training Epoch: 50, train_Loss: 0.8150
training Epoch: 50, train_Loss: 1.4470
training Epoch: 50, train_Loss: 0.7878
training Epoch: 50, train_Loss: 1.0952
training Epoch: 50, train_Loss: 0.8316
training Epoch: 50, train_Loss: 0.4816
training Epoch: 50, train_Loss: 0.6779
training Epoch: 50, train_Loss: 1.1426
training Epoch: 50, train_Loss: 0.9559
training Epoch: 50, train_Loss: 1.0174
training Epoch: 50, train_Loss: 2.6126
training Epoch: 50, train_Loss: 1.7058
training Epoch: 50, train_Loss: 0.4429
training Epoch: 50, train_Loss: 1.6258
training Epoch: 50, train_Loss: 0.8791
training Epoch: 50, train_Loss: 0.5722
training Epoch: 50, train_Loss: 0.9312
training Epoch: 50, train_Loss: 0.4880
training Epoch: 50, train_Loss: 2.0729
training Epoch: 50, train_Loss: 1.7293
training Epoch: 50, train_Loss: 1.0259
training Epoch: 50, train_Loss: 1.6901
training Epoch: 50, train_Loss: 2.5437
training Epoch: 50, train_Loss: 0.7265
training Epoch: 50, train_Loss: 0.9424
training Epoch: 50, train_Loss: 0.7110
training Epoch: 50, train_Loss: 0.5427
training Epoch: 50, train_Loss: 0.5580
training Epoch: 50, train_Loss: 1.1075
training Epoch: 50, train_Loss: 1.6663
training Epoch: 50, train_Loss: 1.6261
training Epoch: 50, train_Loss: 1.1558
training Epoch: 50, train_Loss: 0.5817
training Epoch: 50, train_Loss: 0.5264
training Epoch: 50, train_Loss: 0.5797
training Epoch: 50, train_Loss: 0.3759
training Epoch: 50, train_Loss: 0.9294
training Epoch: 50, train_Loss: 1.5858
training Epoch: 50, train_Loss: 0.4877
training Epoch: 50, train_Loss: 1.3298
training Epoch: 50, train_Loss: 1.0640
training Epoch: 50, train_Loss: 0.3754
training Epoch: 50, train_Loss: 1.0041
training Epoch: 50, train_Loss: 0.6502
training Epoch: 50, train_Loss: 0.3612
training Epoch: 50, train_Loss: 1.3818
training Epoch: 50, train_Loss: 0.2996
training Epoch: 50, train_Loss: 0.8758
training Epoch: 50, train_Loss: 0.3453
training Epoch: 50, train_Loss: 0.3790
training Epoch: 50, train_Loss: 1.5777
training Epoch: 50, train_Loss: 0.3392
training Epoch: 50, train_Loss: 0.9931
training Epoch: 50, train_Loss: 0.3945
training Epoch: 50, train_Loss: 0.7225
training Epoch: 50, train_Loss: 0.7268
training Epoch: 50, train_Loss: 0.7188
training Epoch: 50, train_Loss: 1.0386
training Epoch: 50, train_Loss: 0.8690
training Epoch: 50, train_Loss: 2.0757
training Epoch: 50, train_Loss: 0.2406
training Epoch: 50, train_Loss: 0.2586
training Epoch: 50, train_Loss: 0.5267
training Epoch: 50, train_Loss: 0.8039
training Epoch: 50, train_Loss: 0.3632
training Epoch: 50, train_Loss: 0.5420
training Epoch: 50, train_Loss: 1.8281
training Epoch: 50, train_Loss: 1.4598
training Epoch: 50, train_Loss: 1.2657
training Epoch: 50, train_Loss: 0.4903
training Epoch: 50, train_Loss: 0.9717
training Epoch: 50, train_Loss: 0.3370
training Epoch: 50, train_Loss: 0.4601
training Epoch: 50, train_Loss: 0.4203
training Epoch: 50, train_Loss: 0.3255
training Epoch: 50, train_Loss: 0.1311
training Epoch: 50, train_Loss: 1.1115
training Epoch: 50, train_Loss: 0.4701
training Epoch: 50, train_Loss: 1.0222
training Epoch: 50, train_Loss: 1.3161
training Epoch: 50, train_Loss: 2.8634
training Epoch: 50, train_Loss: 1.0225
training Epoch: 50, train_Loss: 1.5203
training Epoch: 50, train_Loss: 0.8197
training Epoch: 50, train_Loss: 0.3459
training Epoch: 50, train_Loss: 1.4331
training Epoch: 50, train_Loss: 0.2486
training Epoch: 50, train_Loss: 1.9544
training Epoch: 50, train_Loss: 0.4297
training Epoch: 50, train_Loss: 0.9571
training Epoch: 50, train_Loss: 3.2871
training Epoch: 50, train_Loss: 1.8666
training Epoch: 50, train_Loss: 2.0866
training Epoch: 50, train_Loss: 1.8018
training Epoch: 50, train_Loss: 0.7034
training Epoch: 50, train_Loss: 0.8122
training Epoch: 50, train_Loss: 1.5353
training Epoch: 50, train_Loss: 1.7148
training Epoch: 50, train_Loss: 0.8828
training Epoch: 50, train_Loss: 1.5263
training Epoch: 50, train_Loss: 0.7815
training Epoch: 50, train_Loss: 0.7429
training Epoch: 50, train_Loss: 2.0902
training Epoch: 50, train_Loss: 0.6509
training Epoch: 50, train_Loss: 0.9636
training Epoch: 50, train_Loss: 0.8253
training Epoch: 50, train_Loss: 1.0743
training Epoch: 50, train_Loss: 1.1289
training Epoch: 50, train_Loss: 1.2447
training Epoch: 50, train_Loss: 0.6149
training Epoch: 50, train_Loss: 1.0490
training Epoch: 50, train_Loss: 0.8517
training Epoch: 50, train_Loss: 0.3716
training Epoch: 50, train_Loss: 1.4961
training Epoch: 50, train_Loss: 0.9209
training Epoch: 50, train_Loss: 2.4620
training Epoch: 50, train_Loss: 0.6296
training Epoch: 50, train_Loss: 0.4204
training Epoch: 50, train_Loss: 1.6142
training Epoch: 50, train_Loss: 0.3857
training Epoch: 50, train_Loss: 0.8751
training Epoch: 50, train_Loss: 3.0112
training Epoch: 50, train_Loss: 0.9102
training Epoch: 50, train_Loss: 1.5125
training Epoch: 50, train_Loss: 1.0661
training Epoch: 50, train_Loss: 0.6412
training Epoch: 50, train_Loss: 0.5315
training Epoch: 50, train_Loss: 3.1961
training Epoch: 50, train_Loss: 1.0190
training Epoch: 50, train_Loss: 1.7160
training Epoch: 50, train_Loss: 1.7702
training Epoch: 50, train_Loss: 2.6697
training Epoch: 50, train_Loss: 0.8701
training Epoch: 50, train_Loss: 1.0541
training Epoch: 50, train_Loss: 1.3204
training Epoch: 50, train_Loss: 1.6561
training Epoch: 50, train_Loss: 1.0053
training Epoch: 50, train_Loss: 0.8983
training Epoch: 50, train_Loss: 1.3401
training Epoch: 50, train_Loss: 1.1364
training Epoch: 50, train_Loss: 1.2856
training Epoch: 50, train_Loss: 0.7066
training Epoch: 50, train_Loss: 1.0935
training Epoch: 50, train_Loss: 2.2970
training Epoch: 50, train_Loss: 0.5220
training Epoch: 50, train_Loss: 0.8470
training Epoch: 50, train_Loss: 1.1532
training Epoch: 50, train_Loss: 2.0205
training Epoch: 50, train_Loss: 1.7221
training Epoch: 50, train_Loss: 1.0171
training Epoch: 50, train_Loss: 2.0790
training Epoch: 50, train_Loss: 1.8249
training Epoch: 50, train_Loss: 1.6243
training Epoch: 50, train_Loss: 0.7934
training Epoch: 50, train_Loss: 0.6630
training Epoch: 50, train_Loss: 2.2727
training Epoch: 50, train_Loss: 2.2912
training Epoch: 50, train_Loss: 1.7634
training Epoch: 50, train_Loss: 0.8841
training Epoch: 50, train_Loss: 1.8648
training Epoch: 50, train_Loss: 0.9901
training Epoch: 50, train_Loss: 0.6881
training Epoch: 50, train_Loss: 1.6543
training Epoch: 50, train_Loss: 0.5378
training Epoch: 50, train_Loss: 2.7389
training Epoch: 50, train_Loss: 1.1100
training Epoch: 50, train_Loss: 0.7936
training Epoch: 50, train_Loss: 0.7367
training Epoch: 50, train_Loss: 1.9158
training Epoch: 50, train_Loss: 2.1458
training Epoch: 50, train_Loss: 0.5994
training Epoch: 50, train_Loss: 0.6119
training Epoch: 50, train_Loss: 0.7443
training Epoch: 50, train_Loss: 0.6771
training Epoch: 50, train_Loss: 0.4822
training Epoch: 50, train_Loss: 2.0210
training Epoch: 50, train_Loss: 0.4431
training Epoch: 50, train_Loss: 1.9614
training Epoch: 50, train_Loss: 1.0873
training Epoch: 50, train_Loss: 1.6229
training Epoch: 50, train_Loss: 1.0959
training Epoch: 50, train_Loss: 1.1150
training Epoch: 50, train_Loss: 0.8873
training Epoch: 50, train_Loss: 0.2323
training Epoch: 50, train_Loss: 1.0022
training Epoch: 50, train_Loss: 1.3353
training Epoch: 50, train_Loss: 0.4634
training Epoch: 50, train_Loss: 1.6610
training Epoch: 50, train_Loss: 1.3415
training Epoch: 50, train_Loss: 0.3126
training Epoch: 50, train_Loss: 1.8598
training Epoch: 50, train_Loss: 1.5505
training Epoch: 50, train_Loss: 0.7146
training Epoch: 50, train_Loss: 1.5632
training Epoch: 50, train_Loss: 0.4907
training Epoch: 50, train_Loss: 1.1028
training Epoch: 50, train_Loss: 0.8183
training Epoch: 50, train_Loss: 0.5052
training Epoch: 50, train_Loss: 0.6136
training Epoch: 50, train_Loss: 0.6185
training Epoch: 50, train_Loss: 0.6419
training Epoch: 50, train_Loss: 0.6394
training Epoch: 50, train_Loss: 0.8252
training Epoch: 50, train_Loss: 0.7625
training Epoch: 50, train_Loss: 1.7492
training Epoch: 50, train_Loss: 0.3547
training Epoch: 50, train_Loss: 2.9212
training Epoch: 50, train_Loss: 0.7717
training Epoch: 50, train_Loss: 0.9399
training Epoch: 50, train_Loss: 0.9447
training Epoch: 50, train_Loss: 2.1808
training Epoch: 50, train_Loss: 1.2456
training Epoch: 50, train_Loss: 2.0830
training Epoch: 50, train_Loss: 0.6588
training Epoch: 50, train_Loss: 0.4733
training Epoch: 50, train_Loss: 0.5732
training Epoch: 50, train_Loss: 0.7212
training Epoch: 50, train_Loss: 1.8014
training Epoch: 50, train_Loss: 0.7788
training Epoch: 50, train_Loss: 1.1656
training Epoch: 50, train_Loss: 2.2386
training Epoch: 50, train_Loss: 0.5004
training Epoch: 50, train_Loss: 0.4415
training Epoch: 50, train_Loss: 0.9278
training Epoch: 50, train_Loss: 0.8717
training Epoch: 50, train_Loss: 0.8685
training Epoch: 50, train_Loss: 0.7119
training Epoch: 50, train_Loss: 0.4892
training Epoch: 50, train_Loss: 0.5147
training Epoch: 50, train_Loss: 0.7136
training Epoch: 50, train_Loss: 1.8691
training Epoch: 50, train_Loss: 3.1991
training Epoch: 50, train_Loss: 0.8600
training Epoch: 50, train_Loss: 1.3147
training Epoch: 50, train_Loss: 2.1625
training Epoch: 50, train_Loss: 0.3332
training Epoch: 50, train_Loss: 1.0460
training Epoch: 50, train_Loss: 0.3157
training Epoch: 50, train_Loss: 1.0190
training Epoch: 50, train_Loss: 1.1969
training Epoch: 50, train_Loss: 0.6760
training Epoch: 50, train_Loss: 0.7966
training Epoch: 50, train_Loss: 0.8941
training Epoch: 50, train_Loss: 0.3519
training Epoch: 50, train_Loss: 0.9028
training Epoch: 50, train_Loss: 0.8229
training Epoch: 50, train_Loss: 3.5295
training Epoch: 50, train_Loss: 0.9194
training Epoch: 50, train_Loss: 0.9924
training Epoch: 50, train_Loss: 1.4028
training Epoch: 50, train_Loss: 1.0315
training Epoch: 50, train_Loss: 1.0808
training Epoch: 50, train_Loss: 1.2998
training Epoch: 50, train_Loss: 1.2399
training Epoch: 50, train_Loss: 0.4414
training Epoch: 50, train_Loss: 0.8424
training Epoch: 50, train_Loss: 0.8464
training Epoch: 50, train_Loss: 2.2192
training Epoch: 50, train_Loss: 0.5722
training Epoch: 50, train_Loss: 0.8825
training Epoch: 50, train_Loss: 2.0525
training Epoch: 50, train_Loss: 1.0944
training Epoch: 50, train_Loss: 0.7560
training Epoch: 50, train_Loss: 1.1716
training Epoch: 50, train_Loss: 1.7326
training Epoch: 50, train_Loss: 1.0247
training Epoch: 50, train_Loss: 0.8490
training Epoch: 50, train_Loss: 0.6028
training Epoch: 50, train_Loss: 1.2603
training Epoch: 50, train_Loss: 1.3546
training Epoch: 50, train_Loss: 2.0399
training Epoch: 50, train_Loss: 0.4378
training Epoch: 50, train_Loss: 2.1334
training Epoch: 50, train_Loss: 1.1579
training Epoch: 50, train_Loss: 1.5629
training Epoch: 50, train_Loss: 0.5839
training Epoch: 50, train_Loss: 1.2511
training Epoch: 50, train_Loss: 1.3593
training Epoch: 50, train_Loss: 2.2699
training Epoch: 50, train_Loss: 0.5951
training Epoch: 50, train_Loss: 0.3538
training Epoch: 50, train_Loss: 1.5261
training Epoch: 50, train_Loss: 1.5464
training Epoch: 50, train_Loss: 1.1269
training Epoch: 50, train_Loss: 0.5799
training Epoch: 50, train_Loss: 0.5565
training Epoch: 50, train_Loss: 0.7974
training Epoch: 50, train_Loss: 0.8359
training Epoch: 50, train_Loss: 1.5352
training Epoch: 50, train_Loss: 0.9037
training Epoch: 50, train_Loss: 1.2246
training Epoch: 50, train_Loss: 0.5131
training Epoch: 50, train_Loss: 0.8298
training Epoch: 50, train_Loss: 1.9794
training Epoch: 50, train_Loss: 1.6019
training Epoch: 50, train_Loss: 0.8163
training Epoch: 50, train_Loss: 1.1032
training Epoch: 50, train_Loss: 1.5909
training Epoch: 50, train_Loss: 2.1566
training Epoch: 50, train_Loss: 0.7631
training Epoch: 50, train_Loss: 1.1207
training Epoch: 50, train_Loss: 0.8031
training Epoch: 50, train_Loss: 1.0494
training Epoch: 50, train_Loss: 1.0710
training Epoch: 50, train_Loss: 0.6437
training Epoch: 50, train_Loss: 1.4482
training Epoch: 50, train_Loss: 1.2900
training Epoch: 50, train_Loss: 1.7780
training Epoch: 50, train_Loss: 0.4248
training Epoch: 50, train_Loss: 0.5573
training Epoch: 50, train_Loss: 0.7335
training Epoch: 50, train_Loss: 0.3664
training Epoch: 50, train_Loss: 2.4943
training Epoch: 50, train_Loss: 2.4021
training Epoch: 50, train_Loss: 0.6556
training Epoch: 50, train_Loss: 2.5949
training Epoch: 50, train_Loss: 0.6280
training Epoch: 50, train_Loss: 1.0718
training Epoch: 50, train_Loss: 0.5997
training Epoch: 50, train_Loss: 1.8748
training Epoch: 50, train_Loss: 0.3844
training Epoch: 50, train_Loss: 0.9909
training Epoch: 50, train_Loss: 0.9819
training Epoch: 50, train_Loss: 0.6327
training Epoch: 50, train_Loss: 1.6093
training Epoch: 50, train_Loss: 0.7773
training Epoch: 50, train_Loss: 1.0087
training Epoch: 50, train_Loss: 1.2688
training Epoch: 50, train_Loss: 1.0578
training Epoch: 50, train_Loss: 0.6869
training Epoch: 50, train_Loss: 2.9475
training Epoch: 50, train_Loss: 1.0545
training Epoch: 50, train_Loss: 1.3194
training Epoch: 50, train_Loss: 2.0327
training Epoch: 50, train_Loss: 1.3433
training Epoch: 50, train_Loss: 0.3775
training Epoch: 50, train_Loss: 0.8988
training Epoch: 50, train_Loss: 0.6968
training Epoch: 50, train_Loss: 1.5176
training Epoch: 50, train_Loss: 0.6814
training Epoch: 50, train_Loss: 0.3744
training Epoch: 50, train_Loss: 0.5718
training Epoch: 50, train_Loss: 1.1443
training Epoch: 50, train_Loss: 0.9386
training Epoch: 50, train_Loss: 0.4705
training Epoch: 50, train_Loss: 1.0355
training Epoch: 50, train_Loss: 3.6178
training Epoch: 50, train_Loss: 2.6265
training Epoch: 50, train_Loss: 0.4824
training Epoch: 50, train_Loss: 0.7481
training Epoch: 50, train_Loss: 0.5353
training Epoch: 50, train_Loss: 0.4194
training Epoch: 50, train_Loss: 1.5821
training Epoch: 50, train_Loss: 0.4372
training Epoch: 50, train_Loss: 1.4102
training Epoch: 50, train_Loss: 0.5336
training Epoch: 50, train_Loss: 2.5025
training Epoch: 50, train_Loss: 3.4720
training Epoch: 50, train_Loss: 0.8166
training Epoch: 50, train_Loss: 0.7503
training Epoch: 50, train_Loss: 0.6445
training Epoch: 50, train_Loss: 0.9478
training Epoch: 50, train_Loss: 0.9359
training Epoch: 50, train_Loss: 0.6632
training Epoch: 50, train_Loss: 0.7323
training Epoch: 50, train_Loss: 1.7700
training Epoch: 50, train_Loss: 1.5873
training Epoch: 50, train_Loss: 1.8701
training Epoch: 50, train_Loss: 0.9239
training Epoch: 50, train_Loss: 0.9248
training Epoch: 50, train_Loss: 0.5540
training Epoch: 50, train_Loss: 0.9885
training Epoch: 50, train_Loss: 1.3194
training Epoch: 50, train_Loss: 1.3091
training Epoch: 50, train_Loss: 0.9352
training Epoch: 50, train_Loss: 0.5552
training Epoch: 50, train_Loss: 0.9603
training Epoch: 50, train_Loss: 2.1775
training Epoch: 50, train_Loss: 0.5507
training Epoch: 50, train_Loss: 0.3308
training Epoch: 50, train_Loss: 1.0696
training Epoch: 50, train_Loss: 2.8452
training Epoch: 50, train_Loss: 1.3803
training Epoch: 50, train_Loss: 0.7685
training Epoch: 50, train_Loss: 0.6340
training Epoch: 50, train_Loss: 1.0039
training Epoch: 50, train_Loss: 0.4452
training Epoch: 50, train_Loss: 0.2666
training Epoch: 50, train_Loss: 1.0049
training Epoch: 50, train_Loss: 0.5317
training Epoch: 50, train_Loss: 1.8777
training Epoch: 50, train_Loss: 0.2128
training Epoch: 50, train_Loss: 1.8852
training Epoch: 50, train_Loss: 0.7879
training Epoch: 50, train_Loss: 0.8459
training Epoch: 50, train_Loss: 1.5068
training Epoch: 50, train_Loss: 0.3834
training Epoch: 50, train_Loss: 0.1851
training Epoch: 50, train_Loss: 1.0365
training Epoch: 50, train_Loss: 2.7621
training Epoch: 50, train_Loss: 0.7688
training Epoch: 50, train_Loss: 0.7921
training Epoch: 50, train_Loss: 0.9493
training Epoch: 50, train_Loss: 0.4250
training Epoch: 50, train_Loss: 1.8061
training Epoch: 50, train_Loss: 1.7474
training Epoch: 50, train_Loss: 1.0758
training Epoch: 50, train_Loss: 2.1367
training Epoch: 50, train_Loss: 0.3834
training Epoch: 50, train_Loss: 1.0505
training Epoch: 50, train_Loss: 1.5000
training Epoch: 50, train_Loss: 0.5744
training Epoch: 50, train_Loss: 1.7682
training Epoch: 50, train_Loss: 1.3701
training Epoch: 50, train_Loss: 0.7918
training Epoch: 50, train_Loss: 1.2900
training Epoch: 50, train_Loss: 0.7335
training Epoch: 50, train_Loss: 0.7712
training Epoch: 50, train_Loss: 0.7913
training Epoch: 50, train_Loss: 0.8311
training Epoch: 50, train_Loss: 0.5469
training Epoch: 50, train_Loss: 1.5900
training Epoch: 50, train_Loss: 0.5059
training Epoch: 50, train_Loss: 0.4528
training Epoch: 50, train_Loss: 0.4144
training Epoch: 50, train_Loss: 1.6648
training Epoch: 50, train_Loss: 1.4733
training Epoch: 50, train_Loss: 0.2694
training Epoch: 50, train_Loss: 1.6546
training Epoch: 50, train_Loss: 3.6561
training Epoch: 50, train_Loss: 2.1864
training Epoch: 50, train_Loss: 0.5914
training Epoch: 50, train_Loss: 0.6765
training Epoch: 50, train_Loss: 0.9069
training Epoch: 50, train_Loss: 2.1288
training Epoch: 50, train_Loss: 0.5176
training Epoch: 50, train_Loss: 2.2736
training Epoch: 50, train_Loss: 1.7683
training Epoch: 50, train_Loss: 0.5874
training Epoch: 50, train_Loss: 0.4595
training Epoch: 50, train_Loss: 0.5732
training Epoch: 50, train_Loss: 0.4165
training Epoch: 50, train_Loss: 1.3966
training Epoch: 50, train_Loss: 1.0600
training Epoch: 50, train_Loss: 1.1157
training Epoch: 50, train_Loss: 1.1927
training Epoch: 50, train_Loss: 0.8940
training Epoch: 50, train_Loss: 0.3696
training Epoch: 50, train_Loss: 0.4838
training Epoch: 50, train_Loss: 2.2432
training Epoch: 50, train_Loss: 0.7494
training Epoch: 50, train_Loss: 0.3565
training Epoch: 50, train_Loss: 1.6282
training Epoch: 50, train_Loss: 0.8747
training Epoch: 50, train_Loss: 0.4466
training Epoch: 50, train_Loss: 1.2860
training Epoch: 50, train_Loss: 0.3818
training Epoch: 50, train_Loss: 1.8653
training Epoch: 50, train_Loss: 0.3636
training Epoch: 50, train_Loss: 0.8891
training Epoch: 50, train_Loss: 0.6494
training Epoch: 50, train_Loss: 2.1050
training Epoch: 50, train_Loss: 0.3037
training Epoch: 50, train_Loss: 0.3013
training Epoch: 50, train_Loss: 0.3311
training Epoch: 50, train_Loss: 0.2502
training Epoch: 50, train_Loss: 1.6763
training Epoch: 50, train_Loss: 0.5432
training Epoch: 50, train_Loss: 0.5925
training Epoch: 50, train_Loss: 0.9177
training Epoch: 50, train_Loss: 1.8998
training Epoch: 50, train_Loss: 0.9720
training Epoch: 50, train_Loss: 0.7939
training Epoch: 50, train_Loss: 0.8710
training Epoch: 50, train_Loss: 0.2180
training Epoch: 50, train_Loss: 1.2466
training Epoch: 50, train_Loss: 1.9591
training Epoch: 50, train_Loss: 0.8742
training Epoch: 50, train_Loss: 0.6395
training Epoch: 50, train_Loss: 0.5737
training Epoch: 50, train_Loss: 0.6060
training Epoch: 50, train_Loss: 1.5024
training Epoch: 50, train_Loss: 0.5741
training Epoch: 50, train_Loss: 1.1582
training Epoch: 50, train_Loss: 1.1120
training Epoch: 50, train_Loss: 1.1408
training Epoch: 50, train_Loss: 0.7110
training Epoch: 50, train_Loss: 0.9101
training Epoch: 50, train_Loss: 1.3234
training Epoch: 50, train_Loss: 0.6463
training Epoch: 50, train_Loss: 0.6406
training Epoch: 50, train_Loss: 0.9567
training Epoch: 50, train_Loss: 0.3195
training Epoch: 50, train_Loss: 1.2031
training Epoch: 50, train_Loss: 0.4100
training Epoch: 50, train_Loss: 0.4856
training Epoch: 50, train_Loss: 0.5513
training Epoch: 50, train_Loss: 1.3270
training Epoch: 50, train_Loss: 0.2414
training Epoch: 50, train_Loss: 1.2572
training Epoch: 50, train_Loss: 0.6394
training Epoch: 50, train_Loss: 1.8815
training Epoch: 50, train_Loss: 0.4650
training Epoch: 50, train_Loss: 0.9567
training Epoch: 50, train_Loss: 0.6700
training Epoch: 50, train_Loss: 0.5383
training Epoch: 50, train_Loss: 1.4355
training Epoch: 50, train_Loss: 0.8325
training Epoch: 50, train_Loss: 1.5504
training Epoch: 50, train_Loss: 1.2965
training Epoch: 50, train_Loss: 0.8953
training Epoch: 50, train_Loss: 1.4185
training Epoch: 50, train_Loss: 1.4370
training Epoch: 50, train_Loss: 0.5906
training Epoch: 50, train_Loss: 0.6311
training Epoch: 50, train_Loss: 1.0646
training Epoch: 50, train_Loss: 1.1543
training Epoch: 50, train_Loss: 0.6593
training Epoch: 50, train_Loss: 1.5881
training Epoch: 50, train_Loss: 0.9610
training Epoch: 50, train_Loss: 1.2684
training Epoch: 50, train_Loss: 0.6088
training Epoch: 50, train_Loss: 0.9017
training Epoch: 50, train_Loss: 2.3001
fold,epoch,train_loss: 0 49 1.0843652
fold,epoch,train_loss: 0 50 1.0903788
fold,epoch,train_loss: 0 51 1.0927628
fold,epoch,train_loss: 0 52 1.084039
fold,epoch,train_loss: 0 53 1.0905061
fold,epoch,train_loss: 0 54 1.0840334
fold,epoch,train_loss: 0 55 1.089664
fold,epoch,train_loss: 0 56 1.0902134
fold,epoch,train_loss: 0 57 1.0836947
fold,epoch,train_loss: 0 58 1.09403
fold,epoch,train_loss: 0 59 1.0914572
fold,epoch,train_loss: 0 60 1.0889041
fold,epoch,train_loss: 0 61 1.0915552
fold,epoch,train_loss: 0 62 1.089415
fold,epoch,train_loss: 0 63 1.092942
fold,epoch,train_loss: 0 64 1.0907793
fold,epoch,train_loss: 0 65 1.0885088
fold,epoch,train_loss: 0 66 1.0868328
fold,epoch,train_loss: 0 67 1.089553
fold,epoch,train_loss: 0 68 1.0908829
fold,epoch,train_loss: 0 69 1.0905564
fold,epoch,train_loss: 0 70 1.0948168
fold,epoch,train_loss: 0 71 1.0852945
fold,epoch,train_loss: 0 72 1.0876297
fold,epoch,train_loss: 0 73 1.0928319
fold,epoch,train_loss: 0 74 1.0877656
fold,epoch,train_loss: 0 75 1.0911375
fold,epoch,train_loss: 0 76 1.088576
fold,epoch,train_loss: 0 77 1.0928406
fold,epoch,train_loss: 0 78 1.0975945
fold,epoch,train_loss: 0 79 1.0924202
fold,epoch,train_loss: 0 80 1.0923429
fold,epoch,train_loss: 0 81 1.0927821
fold,epoch,train_loss: 0 82 1.0912659
fold,epoch,train_loss: 0 83 1.091324
fold,epoch,train_loss: 0 84 773254100000.0
fold,epoch,train_loss: 0 85 62.034653
fold,epoch,train_loss: 0 86 46058372.0
fold,epoch,train_loss: 0 87 62.197906
fold,epoch,train_loss: 0 88 62.158573
fold,epoch,train_loss: 0 89 62.11843
fold,epoch,train_loss: 0 90 62.063145
fold,epoch,train_loss: 0 91 61.988514
fold,epoch,train_loss: 0 92 61.8878
fold,epoch,train_loss: 0 93 61.759743
fold,epoch,train_loss: 0 94 61.587227
fold,epoch,train_loss: 0 95 61.342228
fold,epoch,train_loss: 0 96 61.039627
fold,epoch,train_loss: 0 97 60.614952
fold,epoch,train_loss: 0 98 60.0791
training Epoch: 100, train_Loss: 61.8368
training Epoch: 100, train_Loss: 67.1589
training Epoch: 100, train_Loss: 60.7765
training Epoch: 100, train_Loss: 58.8253
training Epoch: 100, train_Loss: 51.3680
training Epoch: 100, train_Loss: 50.7215
training Epoch: 100, train_Loss: 55.0027
training Epoch: 100, train_Loss: 55.7728
training Epoch: 100, train_Loss: 56.8273
training Epoch: 100, train_Loss: 56.5323
training Epoch: 100, train_Loss: 58.7932
training Epoch: 100, train_Loss: 57.6708
training Epoch: 100, train_Loss: 58.5557
training Epoch: 100, train_Loss: 55.6021
training Epoch: 100, train_Loss: 66.7842
training Epoch: 100, train_Loss: 64.4335
training Epoch: 100, train_Loss: 62.8330
training Epoch: 100, train_Loss: 61.6687
training Epoch: 100, train_Loss: 67.6052
training Epoch: 100, train_Loss: 53.5348
training Epoch: 100, train_Loss: 60.0883
training Epoch: 100, train_Loss: 52.6510
training Epoch: 100, train_Loss: 65.4311
training Epoch: 100, train_Loss: 53.7509
training Epoch: 100, train_Loss: 63.1746
training Epoch: 100, train_Loss: 65.4063
training Epoch: 100, train_Loss: 65.7474
training Epoch: 100, train_Loss: 67.0224
training Epoch: 100, train_Loss: 56.8227
training Epoch: 100, train_Loss: 60.4299
training Epoch: 100, train_Loss: 52.3942
training Epoch: 100, train_Loss: 65.1344
training Epoch: 100, train_Loss: 63.1471
training Epoch: 100, train_Loss: 66.0277
training Epoch: 100, train_Loss: 61.0853
training Epoch: 100, train_Loss: 55.3398
training Epoch: 100, train_Loss: 56.1137
training Epoch: 100, train_Loss: 60.3661
training Epoch: 100, train_Loss: 61.7635
training Epoch: 100, train_Loss: 62.6882
training Epoch: 100, train_Loss: 57.7264
training Epoch: 100, train_Loss: 56.9744
training Epoch: 100, train_Loss: 46.7055
training Epoch: 100, train_Loss: 58.2707
training Epoch: 100, train_Loss: 60.9521
training Epoch: 100, train_Loss: 64.7042
training Epoch: 100, train_Loss: 66.8223
training Epoch: 100, train_Loss: 59.6838
training Epoch: 100, train_Loss: 59.2434
training Epoch: 100, train_Loss: 60.0353
training Epoch: 100, train_Loss: 65.0891
training Epoch: 100, train_Loss: 64.2205
training Epoch: 100, train_Loss: 56.4340
training Epoch: 100, train_Loss: 57.3536
training Epoch: 100, train_Loss: 59.8616
training Epoch: 100, train_Loss: 63.9045
training Epoch: 100, train_Loss: 65.7030
training Epoch: 100, train_Loss: 58.5676
training Epoch: 100, train_Loss: 61.2921
training Epoch: 100, train_Loss: 52.3491
training Epoch: 100, train_Loss: 53.4367
training Epoch: 100, train_Loss: 64.9334
training Epoch: 100, train_Loss: 61.3957
training Epoch: 100, train_Loss: 63.2774
training Epoch: 100, train_Loss: 62.1369
training Epoch: 100, train_Loss: 59.0769
training Epoch: 100, train_Loss: 62.9579
training Epoch: 100, train_Loss: 59.6073
training Epoch: 100, train_Loss: 62.9782
training Epoch: 100, train_Loss: 53.7974
training Epoch: 100, train_Loss: 58.8256
training Epoch: 100, train_Loss: 64.3141
training Epoch: 100, train_Loss: 54.0016
training Epoch: 100, train_Loss: 61.2795
training Epoch: 100, train_Loss: 55.4650
training Epoch: 100, train_Loss: 66.0828
training Epoch: 100, train_Loss: 54.0653
training Epoch: 100, train_Loss: 59.2584
training Epoch: 100, train_Loss: 59.3222
training Epoch: 100, train_Loss: 63.7252
training Epoch: 100, train_Loss: 67.2621
training Epoch: 100, train_Loss: 59.3245
training Epoch: 100, train_Loss: 58.9538
training Epoch: 100, train_Loss: 57.2619
training Epoch: 100, train_Loss: 59.4947
training Epoch: 100, train_Loss: 54.1952
training Epoch: 100, train_Loss: 48.4488
training Epoch: 100, train_Loss: 54.6508
training Epoch: 100, train_Loss: 63.1435
training Epoch: 100, train_Loss: 66.0135
training Epoch: 100, train_Loss: 60.4020
training Epoch: 100, train_Loss: 50.1281
training Epoch: 100, train_Loss: 60.7629
training Epoch: 100, train_Loss: 59.3472
training Epoch: 100, train_Loss: 59.4897
training Epoch: 100, train_Loss: 61.3315
training Epoch: 100, train_Loss: 66.3875
training Epoch: 100, train_Loss: 61.4122
training Epoch: 100, train_Loss: 61.8403
training Epoch: 100, train_Loss: 65.2166
training Epoch: 100, train_Loss: 68.5614
training Epoch: 100, train_Loss: 63.6473
training Epoch: 100, train_Loss: 58.3581
training Epoch: 100, train_Loss: 55.2268
training Epoch: 100, train_Loss: 59.5782
training Epoch: 100, train_Loss: 48.7615
training Epoch: 100, train_Loss: 54.5971
training Epoch: 100, train_Loss: 58.8872
training Epoch: 100, train_Loss: 57.5726
training Epoch: 100, train_Loss: 53.1523
training Epoch: 100, train_Loss: 52.3540
training Epoch: 100, train_Loss: 68.3664
training Epoch: 100, train_Loss: 62.3587
training Epoch: 100, train_Loss: 49.5061
training Epoch: 100, train_Loss: 69.0612
training Epoch: 100, train_Loss: 52.6103
training Epoch: 100, train_Loss: 65.3292
training Epoch: 100, train_Loss: 58.0054
training Epoch: 100, train_Loss: 65.8155
training Epoch: 100, train_Loss: 61.5604
training Epoch: 100, train_Loss: 60.6724
training Epoch: 100, train_Loss: 61.8848
training Epoch: 100, train_Loss: 60.8037
training Epoch: 100, train_Loss: 62.6762
training Epoch: 100, train_Loss: 69.0469
training Epoch: 100, train_Loss: 59.1106
training Epoch: 100, train_Loss: 65.3909
training Epoch: 100, train_Loss: 58.7864
training Epoch: 100, train_Loss: 55.0865
training Epoch: 100, train_Loss: 66.4120
training Epoch: 100, train_Loss: 54.3116
training Epoch: 100, train_Loss: 61.0392
training Epoch: 100, train_Loss: 65.2545
training Epoch: 100, train_Loss: 58.5968
training Epoch: 100, train_Loss: 58.8232
training Epoch: 100, train_Loss: 54.8114
training Epoch: 100, train_Loss: 54.4885
training Epoch: 100, train_Loss: 57.2921
training Epoch: 100, train_Loss: 65.2641
training Epoch: 100, train_Loss: 59.4639
training Epoch: 100, train_Loss: 63.8386
training Epoch: 100, train_Loss: 55.6106
training Epoch: 100, train_Loss: 60.3193
training Epoch: 100, train_Loss: 58.9073
training Epoch: 100, train_Loss: 62.1999
training Epoch: 100, train_Loss: 55.9489
training Epoch: 100, train_Loss: 62.7237
training Epoch: 100, train_Loss: 60.8933
training Epoch: 100, train_Loss: 61.8158
training Epoch: 100, train_Loss: 55.7001
training Epoch: 100, train_Loss: 57.9507
training Epoch: 100, train_Loss: 53.2732
training Epoch: 100, train_Loss: 63.7760
training Epoch: 100, train_Loss: 64.5887
training Epoch: 100, train_Loss: 55.2456
training Epoch: 100, train_Loss: 63.4735
training Epoch: 100, train_Loss: 60.1483
training Epoch: 100, train_Loss: 63.5286
training Epoch: 100, train_Loss: 60.1061
training Epoch: 100, train_Loss: 55.2920
training Epoch: 100, train_Loss: 53.7021
training Epoch: 100, train_Loss: 63.5739
training Epoch: 100, train_Loss: 52.5212
training Epoch: 100, train_Loss: 58.6236
training Epoch: 100, train_Loss: 61.3865
training Epoch: 100, train_Loss: 68.3067
training Epoch: 100, train_Loss: 66.6496
training Epoch: 100, train_Loss: 59.4828
training Epoch: 100, train_Loss: 66.1410
training Epoch: 100, train_Loss: 47.4293
training Epoch: 100, train_Loss: 68.9797
training Epoch: 100, train_Loss: 53.4816
training Epoch: 100, train_Loss: 57.1400
training Epoch: 100, train_Loss: 54.8292
training Epoch: 100, train_Loss: 56.0056
training Epoch: 100, train_Loss: 57.2746
training Epoch: 100, train_Loss: 57.6740
training Epoch: 100, train_Loss: 55.8872
training Epoch: 100, train_Loss: 58.5911
training Epoch: 100, train_Loss: 66.1976
training Epoch: 100, train_Loss: 62.4249
training Epoch: 100, train_Loss: 63.5652
training Epoch: 100, train_Loss: 56.7480
training Epoch: 100, train_Loss: 60.8579
training Epoch: 100, train_Loss: 65.4255
training Epoch: 100, train_Loss: 61.8676
training Epoch: 100, train_Loss: 67.3424
training Epoch: 100, train_Loss: 63.5982
training Epoch: 100, train_Loss: 61.4262
training Epoch: 100, train_Loss: 59.4409
training Epoch: 100, train_Loss: 66.7933
training Epoch: 100, train_Loss: 50.9551
training Epoch: 100, train_Loss: 62.3495
training Epoch: 100, train_Loss: 63.2440
training Epoch: 100, train_Loss: 62.2943
training Epoch: 100, train_Loss: 60.6049
training Epoch: 100, train_Loss: 57.4537
training Epoch: 100, train_Loss: 61.5135
training Epoch: 100, train_Loss: 54.4710
training Epoch: 100, train_Loss: 63.7417
training Epoch: 100, train_Loss: 64.7408
training Epoch: 100, train_Loss: 68.0927
training Epoch: 100, train_Loss: 62.8149
training Epoch: 100, train_Loss: 60.1607
training Epoch: 100, train_Loss: 61.3842
training Epoch: 100, train_Loss: 58.6272
training Epoch: 100, train_Loss: 59.2727
training Epoch: 100, train_Loss: 53.8688
training Epoch: 100, train_Loss: 53.6350
training Epoch: 100, train_Loss: 57.5025
training Epoch: 100, train_Loss: 59.5389
training Epoch: 100, train_Loss: 65.3332
training Epoch: 100, train_Loss: 53.6671
training Epoch: 100, train_Loss: 58.1743
training Epoch: 100, train_Loss: 59.1174
training Epoch: 100, train_Loss: 62.2398
training Epoch: 100, train_Loss: 63.8577
training Epoch: 100, train_Loss: 58.8912
training Epoch: 100, train_Loss: 61.6314
training Epoch: 100, train_Loss: 53.8979
training Epoch: 100, train_Loss: 58.3862
training Epoch: 100, train_Loss: 52.6422
training Epoch: 100, train_Loss: 62.1377
training Epoch: 100, train_Loss: 58.9583
training Epoch: 100, train_Loss: 57.0020
training Epoch: 100, train_Loss: 61.2820
training Epoch: 100, train_Loss: 56.1491
training Epoch: 100, train_Loss: 63.8550
training Epoch: 100, train_Loss: 60.1324
training Epoch: 100, train_Loss: 59.7587
training Epoch: 100, train_Loss: 62.6028
training Epoch: 100, train_Loss: 63.8894
training Epoch: 100, train_Loss: 64.9121
training Epoch: 100, train_Loss: 56.2876
training Epoch: 100, train_Loss: 61.7989
training Epoch: 100, train_Loss: 61.5944
training Epoch: 100, train_Loss: 62.9726
training Epoch: 100, train_Loss: 59.6619
training Epoch: 100, train_Loss: 64.5121
training Epoch: 100, train_Loss: 59.4049
training Epoch: 100, train_Loss: 60.6488
training Epoch: 100, train_Loss: 66.4843
training Epoch: 100, train_Loss: 57.9598
training Epoch: 100, train_Loss: 57.8606
training Epoch: 100, train_Loss: 48.0162
training Epoch: 100, train_Loss: 58.6253
training Epoch: 100, train_Loss: 57.8117
training Epoch: 100, train_Loss: 59.7851
training Epoch: 100, train_Loss: 56.1999
training Epoch: 100, train_Loss: 61.7639
training Epoch: 100, train_Loss: 63.3735
training Epoch: 100, train_Loss: 64.0724
training Epoch: 100, train_Loss: 61.4183
training Epoch: 100, train_Loss: 57.8551
training Epoch: 100, train_Loss: 63.1272
training Epoch: 100, train_Loss: 51.4846
training Epoch: 100, train_Loss: 52.7670
training Epoch: 100, train_Loss: 62.2117
training Epoch: 100, train_Loss: 59.4167
training Epoch: 100, train_Loss: 54.4593
training Epoch: 100, train_Loss: 63.9674
training Epoch: 100, train_Loss: 66.3860
training Epoch: 100, train_Loss: 56.8316
training Epoch: 100, train_Loss: 66.0449
training Epoch: 100, train_Loss: 60.0331
training Epoch: 100, train_Loss: 55.3833
training Epoch: 100, train_Loss: 56.4707
training Epoch: 100, train_Loss: 63.9613
training Epoch: 100, train_Loss: 60.1301
training Epoch: 100, train_Loss: 65.6510
training Epoch: 100, train_Loss: 61.3279
training Epoch: 100, train_Loss: 63.0906
training Epoch: 100, train_Loss: 64.7877
training Epoch: 100, train_Loss: 61.0364
training Epoch: 100, train_Loss: 64.9842
training Epoch: 100, train_Loss: 60.9836
training Epoch: 100, train_Loss: 58.4379
training Epoch: 100, train_Loss: 61.7897
training Epoch: 100, train_Loss: 60.2994
training Epoch: 100, train_Loss: 54.7085
training Epoch: 100, train_Loss: 52.5300
training Epoch: 100, train_Loss: 67.5544
training Epoch: 100, train_Loss: 62.6997
training Epoch: 100, train_Loss: 61.7172
training Epoch: 100, train_Loss: 56.3187
training Epoch: 100, train_Loss: 58.0127
training Epoch: 100, train_Loss: 59.8358
training Epoch: 100, train_Loss: 56.5605
training Epoch: 100, train_Loss: 52.4503
training Epoch: 100, train_Loss: 62.4125
training Epoch: 100, train_Loss: 62.3061
training Epoch: 100, train_Loss: 59.0469
training Epoch: 100, train_Loss: 44.1022
training Epoch: 100, train_Loss: 60.3687
training Epoch: 100, train_Loss: 57.5224
training Epoch: 100, train_Loss: 63.4487
training Epoch: 100, train_Loss: 54.8579
training Epoch: 100, train_Loss: 53.1746
training Epoch: 100, train_Loss: 58.2190
training Epoch: 100, train_Loss: 64.7895
training Epoch: 100, train_Loss: 62.5518
training Epoch: 100, train_Loss: 59.5046
training Epoch: 100, train_Loss: 52.7370
training Epoch: 100, train_Loss: 60.3673
training Epoch: 100, train_Loss: 54.0232
training Epoch: 100, train_Loss: 57.6524
training Epoch: 100, train_Loss: 60.8917
training Epoch: 100, train_Loss: 48.7187
training Epoch: 100, train_Loss: 59.0079
training Epoch: 100, train_Loss: 52.8967
training Epoch: 100, train_Loss: 61.6497
training Epoch: 100, train_Loss: 51.5011
training Epoch: 100, train_Loss: 54.3054
training Epoch: 100, train_Loss: 59.9399
training Epoch: 100, train_Loss: 59.3405
training Epoch: 100, train_Loss: 51.3261
training Epoch: 100, train_Loss: 60.0946
training Epoch: 100, train_Loss: 63.9456
training Epoch: 100, train_Loss: 53.3934
training Epoch: 100, train_Loss: 56.9515
training Epoch: 100, train_Loss: 58.9406
training Epoch: 100, train_Loss: 55.1127
training Epoch: 100, train_Loss: 54.7392
training Epoch: 100, train_Loss: 61.7046
training Epoch: 100, train_Loss: 62.2001
training Epoch: 100, train_Loss: 60.0834
training Epoch: 100, train_Loss: 60.4090
training Epoch: 100, train_Loss: 62.2833
training Epoch: 100, train_Loss: 54.7088
training Epoch: 100, train_Loss: 52.6207
training Epoch: 100, train_Loss: 52.2427
training Epoch: 100, train_Loss: 53.6426
training Epoch: 100, train_Loss: 55.3402
training Epoch: 100, train_Loss: 60.7434
training Epoch: 100, train_Loss: 56.1227
training Epoch: 100, train_Loss: 56.9904
training Epoch: 100, train_Loss: 65.1426
training Epoch: 100, train_Loss: 55.2147
training Epoch: 100, train_Loss: 64.0725
training Epoch: 100, train_Loss: 63.9547
training Epoch: 100, train_Loss: 62.4861
training Epoch: 100, train_Loss: 66.2973
training Epoch: 100, train_Loss: 55.1113
training Epoch: 100, train_Loss: 50.9106
training Epoch: 100, train_Loss: 60.8108
training Epoch: 100, train_Loss: 57.7220
training Epoch: 100, train_Loss: 58.6725
training Epoch: 100, train_Loss: 57.6354
training Epoch: 100, train_Loss: 61.8208
training Epoch: 100, train_Loss: 57.4849
training Epoch: 100, train_Loss: 66.4705
training Epoch: 100, train_Loss: 61.2375
training Epoch: 100, train_Loss: 66.1130
training Epoch: 100, train_Loss: 60.0366
training Epoch: 100, train_Loss: 61.0843
training Epoch: 100, train_Loss: 51.0525
training Epoch: 100, train_Loss: 65.2828
training Epoch: 100, train_Loss: 60.5823
training Epoch: 100, train_Loss: 58.8528
training Epoch: 100, train_Loss: 68.1713
training Epoch: 100, train_Loss: 61.3631
training Epoch: 100, train_Loss: 63.4172
training Epoch: 100, train_Loss: 51.3956
training Epoch: 100, train_Loss: 57.1964
training Epoch: 100, train_Loss: 60.2225
training Epoch: 100, train_Loss: 58.8722
training Epoch: 100, train_Loss: 52.0627
training Epoch: 100, train_Loss: 55.1528
training Epoch: 100, train_Loss: 59.6686
training Epoch: 100, train_Loss: 61.0252
training Epoch: 100, train_Loss: 61.3264
training Epoch: 100, train_Loss: 58.1491
training Epoch: 100, train_Loss: 57.9882
training Epoch: 100, train_Loss: 64.2070
training Epoch: 100, train_Loss: 59.3755
training Epoch: 100, train_Loss: 61.3328
training Epoch: 100, train_Loss: 54.4027
training Epoch: 100, train_Loss: 65.7541
training Epoch: 100, train_Loss: 52.4823
training Epoch: 100, train_Loss: 57.1468
training Epoch: 100, train_Loss: 61.3703
training Epoch: 100, train_Loss: 66.1867
training Epoch: 100, train_Loss: 55.9182
training Epoch: 100, train_Loss: 63.9900
training Epoch: 100, train_Loss: 59.5095
training Epoch: 100, train_Loss: 58.8117
training Epoch: 100, train_Loss: 59.4927
training Epoch: 100, train_Loss: 59.0805
training Epoch: 100, train_Loss: 61.5388
training Epoch: 100, train_Loss: 57.2424
training Epoch: 100, train_Loss: 56.5748
training Epoch: 100, train_Loss: 60.0453
training Epoch: 100, train_Loss: 57.9878
training Epoch: 100, train_Loss: 61.1610
training Epoch: 100, train_Loss: 53.4785
training Epoch: 100, train_Loss: 56.3121
training Epoch: 100, train_Loss: 56.2211
training Epoch: 100, train_Loss: 64.7342
training Epoch: 100, train_Loss: 51.2289
training Epoch: 100, train_Loss: 53.8600
training Epoch: 100, train_Loss: 56.0951
training Epoch: 100, train_Loss: 60.8917
training Epoch: 100, train_Loss: 64.1526
training Epoch: 100, train_Loss: 65.3327
training Epoch: 100, train_Loss: 58.2799
training Epoch: 100, train_Loss: 66.4512
training Epoch: 100, train_Loss: 59.6575
training Epoch: 100, train_Loss: 58.7784
training Epoch: 100, train_Loss: 62.4148
training Epoch: 100, train_Loss: 54.4051
training Epoch: 100, train_Loss: 60.0656
training Epoch: 100, train_Loss: 64.7995
training Epoch: 100, train_Loss: 55.1780
training Epoch: 100, train_Loss: 61.3409
training Epoch: 100, train_Loss: 61.7530
training Epoch: 100, train_Loss: 55.2451
training Epoch: 100, train_Loss: 60.0687
training Epoch: 100, train_Loss: 58.2735
training Epoch: 100, train_Loss: 59.4439
training Epoch: 100, train_Loss: 53.0988
training Epoch: 100, train_Loss: 61.9767
training Epoch: 100, train_Loss: 62.1333
training Epoch: 100, train_Loss: 65.0115
training Epoch: 100, train_Loss: 55.9628
training Epoch: 100, train_Loss: 55.7155
training Epoch: 100, train_Loss: 50.4750
training Epoch: 100, train_Loss: 67.5761
training Epoch: 100, train_Loss: 56.6656
training Epoch: 100, train_Loss: 56.5065
training Epoch: 100, train_Loss: 57.8251
training Epoch: 100, train_Loss: 66.6944
training Epoch: 100, train_Loss: 52.0755
training Epoch: 100, train_Loss: 57.1992
training Epoch: 100, train_Loss: 60.6797
training Epoch: 100, train_Loss: 54.0239
training Epoch: 100, train_Loss: 59.2581
training Epoch: 100, train_Loss: 62.7586
training Epoch: 100, train_Loss: 60.9747
training Epoch: 100, train_Loss: 56.3265
training Epoch: 100, train_Loss: 51.9079
training Epoch: 100, train_Loss: 64.7376
training Epoch: 100, train_Loss: 60.7333
training Epoch: 100, train_Loss: 58.6719
training Epoch: 100, train_Loss: 67.0564
training Epoch: 100, train_Loss: 62.5693
training Epoch: 100, train_Loss: 60.3872
training Epoch: 100, train_Loss: 66.0425
training Epoch: 100, train_Loss: 50.0128
training Epoch: 100, train_Loss: 53.9263
training Epoch: 100, train_Loss: 67.8455
training Epoch: 100, train_Loss: 64.2883
training Epoch: 100, train_Loss: 63.5447
training Epoch: 100, train_Loss: 65.3279
training Epoch: 100, train_Loss: 53.0197
training Epoch: 100, train_Loss: 60.7778
training Epoch: 100, train_Loss: 64.3578
training Epoch: 100, train_Loss: 60.9040
training Epoch: 100, train_Loss: 62.6200
training Epoch: 100, train_Loss: 54.2796
training Epoch: 100, train_Loss: 60.9840
training Epoch: 100, train_Loss: 63.0144
training Epoch: 100, train_Loss: 54.5398
training Epoch: 100, train_Loss: 61.1112
training Epoch: 100, train_Loss: 64.9665
training Epoch: 100, train_Loss: 52.8881
training Epoch: 100, train_Loss: 58.4187
training Epoch: 100, train_Loss: 55.0637
training Epoch: 100, train_Loss: 67.0870
training Epoch: 100, train_Loss: 66.5356
training Epoch: 100, train_Loss: 49.7485
training Epoch: 100, train_Loss: 59.2859
training Epoch: 100, train_Loss: 58.1931
training Epoch: 100, train_Loss: 50.7323
training Epoch: 100, train_Loss: 58.9776
training Epoch: 100, train_Loss: 60.2661
training Epoch: 100, train_Loss: 54.1784
training Epoch: 100, train_Loss: 65.3623
training Epoch: 100, train_Loss: 50.3687
training Epoch: 100, train_Loss: 51.5391
training Epoch: 100, train_Loss: 52.6609
training Epoch: 100, train_Loss: 60.7252
training Epoch: 100, train_Loss: 68.4875
training Epoch: 100, train_Loss: 63.1806
training Epoch: 100, train_Loss: 63.7079
training Epoch: 100, train_Loss: 55.7464
training Epoch: 100, train_Loss: 64.6577
training Epoch: 100, train_Loss: 54.6121
training Epoch: 100, train_Loss: 62.8633
training Epoch: 100, train_Loss: 60.8416
training Epoch: 100, train_Loss: 60.5990
training Epoch: 100, train_Loss: 63.2767
training Epoch: 100, train_Loss: 56.4194
training Epoch: 100, train_Loss: 62.7839
training Epoch: 100, train_Loss: 60.3563
training Epoch: 100, train_Loss: 56.9963
training Epoch: 100, train_Loss: 51.5413
training Epoch: 100, train_Loss: 47.1685
training Epoch: 100, train_Loss: 57.1685
training Epoch: 100, train_Loss: 56.8535
training Epoch: 100, train_Loss: 58.4145
training Epoch: 100, train_Loss: 57.3373
training Epoch: 100, train_Loss: 57.3942
training Epoch: 100, train_Loss: 65.4667
training Epoch: 100, train_Loss: 60.3909
training Epoch: 100, train_Loss: 54.6212
training Epoch: 100, train_Loss: 57.9434
training Epoch: 100, train_Loss: 59.9988
training Epoch: 100, train_Loss: 52.0353
training Epoch: 100, train_Loss: 63.3168
training Epoch: 100, train_Loss: 60.0116
training Epoch: 100, train_Loss: 59.9017
training Epoch: 100, train_Loss: 59.2802
training Epoch: 100, train_Loss: 56.9039
training Epoch: 100, train_Loss: 52.0048
training Epoch: 100, train_Loss: 57.7747
training Epoch: 100, train_Loss: 58.0339
training Epoch: 100, train_Loss: 58.2594
training Epoch: 100, train_Loss: 58.4352
training Epoch: 100, train_Loss: 56.6008
training Epoch: 100, train_Loss: 63.2860
training Epoch: 100, train_Loss: 61.4307
training Epoch: 100, train_Loss: 65.1408
training Epoch: 100, train_Loss: 61.6750
training Epoch: 100, train_Loss: 56.7140
training Epoch: 100, train_Loss: 66.1066
training Epoch: 100, train_Loss: 60.4270
training Epoch: 100, train_Loss: 58.9188
training Epoch: 100, train_Loss: 67.3640
training Epoch: 100, train_Loss: 62.1533
training Epoch: 100, train_Loss: 56.3697
training Epoch: 100, train_Loss: 56.1731
training Epoch: 100, train_Loss: 58.5233
training Epoch: 100, train_Loss: 58.8218
training Epoch: 100, train_Loss: 60.1462
training Epoch: 100, train_Loss: 53.0047
training Epoch: 100, train_Loss: 59.9724
training Epoch: 100, train_Loss: 54.5276
training Epoch: 100, train_Loss: 60.1594
training Epoch: 100, train_Loss: 59.5646
training Epoch: 100, train_Loss: 58.3844
training Epoch: 100, train_Loss: 65.6082
training Epoch: 100, train_Loss: 63.5511
training Epoch: 100, train_Loss: 55.0371
training Epoch: 100, train_Loss: 61.4719
training Epoch: 100, train_Loss: 58.4698
training Epoch: 100, train_Loss: 65.8948
training Epoch: 100, train_Loss: 57.8106
training Epoch: 100, train_Loss: 55.5471
training Epoch: 100, train_Loss: 65.6494
training Epoch: 100, train_Loss: 52.6452
training Epoch: 100, train_Loss: 56.3585
training Epoch: 100, train_Loss: 60.9416
training Epoch: 100, train_Loss: 50.1689
training Epoch: 100, train_Loss: 62.2104
training Epoch: 100, train_Loss: 55.8518
training Epoch: 100, train_Loss: 57.9385
training Epoch: 100, train_Loss: 51.5902
training Epoch: 100, train_Loss: 49.2297
training Epoch: 100, train_Loss: 51.7711
training Epoch: 100, train_Loss: 51.6084
training Epoch: 100, train_Loss: 61.9553
training Epoch: 100, train_Loss: 60.4348
training Epoch: 100, train_Loss: 55.0735
training Epoch: 100, train_Loss: 58.2912
training Epoch: 100, train_Loss: 63.4325
training Epoch: 100, train_Loss: 48.5995
training Epoch: 100, train_Loss: 56.1891
training Epoch: 100, train_Loss: 62.8433
training Epoch: 100, train_Loss: 46.8329
training Epoch: 100, train_Loss: 62.9269
training Epoch: 100, train_Loss: 59.1221
training Epoch: 100, train_Loss: 53.8685
training Epoch: 100, train_Loss: 52.5704
training Epoch: 100, train_Loss: 56.3063
training Epoch: 100, train_Loss: 68.1465
fold,epoch,train_loss: 0 99 59.362118
fold,epoch,train_loss: 0 100 58.405434
====Evaluation
fold:0, epoch:100,train:58.405434, valid:57.840435 

fold: 1
fold,epoch,train_loss: 1 0 57.17117
fold,epoch,train_loss: 1 1 55.563763
fold,epoch,train_loss: 1 2 53.489952
fold,epoch,train_loss: 1 3 50.84807
fold,epoch,train_loss: 1 4 47.52925
fold,epoch,train_loss: 1 5 43.450363
fold,epoch,train_loss: 1 6 38.56898
fold,epoch,train_loss: 1 7 32.924232
fold,epoch,train_loss: 1 8 26.701134
fold,epoch,train_loss: 1 9 20.256752
fold,epoch,train_loss: 1 10 14.124756
fold,epoch,train_loss: 1 11 8.888171
fold,epoch,train_loss: 1 12 5.027621
fold,epoch,train_loss: 1 13 2.6752179
fold,epoch,train_loss: 1 14 1.5573412
fold,epoch,train_loss: 1 15 1.172193
fold,epoch,train_loss: 1 16 1.0853938
fold,epoch,train_loss: 1 17 1.0742592
fold,epoch,train_loss: 1 18 1.0770637
fold,epoch,train_loss: 1 19 1.0739286
fold,epoch,train_loss: 1 20 1.074169
fold,epoch,train_loss: 1 21 1.0744035
fold,epoch,train_loss: 1 22 1.0746254
fold,epoch,train_loss: 1 23 1.0739847
fold,epoch,train_loss: 1 24 1.0761307
fold,epoch,train_loss: 1 25 1.0763954
fold,epoch,train_loss: 1 26 1.076414
fold,epoch,train_loss: 1 27 1.0749102
fold,epoch,train_loss: 1 28 1.0780481
fold,epoch,train_loss: 1 29 1.0785122
fold,epoch,train_loss: 1 30 1.0820823
fold,epoch,train_loss: 1 31 1.078331
fold,epoch,train_loss: 1 32 1.0829135
fold,epoch,train_loss: 1 33 1.0823424
fold,epoch,train_loss: 1 34 1.0855867
fold,epoch,train_loss: 1 35 1.0919752
fold,epoch,train_loss: 1 36 1.0859773
fold,epoch,train_loss: 1 37 1.094222
fold,epoch,train_loss: 1 38 1.0948898
fold,epoch,train_loss: 1 39 1.0896206
fold,epoch,train_loss: 1 40 1.0875226
fold,epoch,train_loss: 1 41 1.0894812
fold,epoch,train_loss: 1 42 1.0933334
fold,epoch,train_loss: 1 43 1.0925269
fold,epoch,train_loss: 1 44 1.0899875
fold,epoch,train_loss: 1 45 1.0872829
fold,epoch,train_loss: 1 46 1.0926123
fold,epoch,train_loss: 1 47 1.0822659
fold,epoch,train_loss: 1 48 1.0921235
training Epoch: 50, train_Loss: 1.1044
training Epoch: 50, train_Loss: 1.3459
training Epoch: 50, train_Loss: 0.9894
training Epoch: 50, train_Loss: 0.7554
training Epoch: 50, train_Loss: 4.4325
training Epoch: 50, train_Loss: 1.1044
training Epoch: 50, train_Loss: 0.8381
training Epoch: 50, train_Loss: 1.0337
training Epoch: 50, train_Loss: 3.0325
training Epoch: 50, train_Loss: 1.0684
training Epoch: 50, train_Loss: 0.8596
training Epoch: 50, train_Loss: 0.5855
training Epoch: 50, train_Loss: 0.8141
training Epoch: 50, train_Loss: 0.7876
training Epoch: 50, train_Loss: 1.4333
training Epoch: 50, train_Loss: 0.8556
training Epoch: 50, train_Loss: 1.7473
training Epoch: 50, train_Loss: 0.5964
training Epoch: 50, train_Loss: 2.4836
training Epoch: 50, train_Loss: 0.7072
training Epoch: 50, train_Loss: 0.5564
training Epoch: 50, train_Loss: 1.6385
training Epoch: 50, train_Loss: 1.7533
training Epoch: 50, train_Loss: 1.0209
training Epoch: 50, train_Loss: 0.7731
training Epoch: 50, train_Loss: 0.5833
training Epoch: 50, train_Loss: 1.2800
training Epoch: 50, train_Loss: 0.6116
training Epoch: 50, train_Loss: 0.9992
training Epoch: 50, train_Loss: 2.0585
training Epoch: 50, train_Loss: 0.5881
training Epoch: 50, train_Loss: 0.6686
training Epoch: 50, train_Loss: 0.6165
training Epoch: 50, train_Loss: 0.5046
training Epoch: 50, train_Loss: 3.0452
training Epoch: 50, train_Loss: 0.5454
training Epoch: 50, train_Loss: 0.4417
training Epoch: 50, train_Loss: 0.8584
training Epoch: 50, train_Loss: 1.1626
training Epoch: 50, train_Loss: 0.6297
training Epoch: 50, train_Loss: 2.8063
training Epoch: 50, train_Loss: 1.0507
training Epoch: 50, train_Loss: 0.7157
training Epoch: 50, train_Loss: 1.4373
training Epoch: 50, train_Loss: 0.7852
training Epoch: 50, train_Loss: 0.2838
training Epoch: 50, train_Loss: 0.3812
training Epoch: 50, train_Loss: 2.4072
training Epoch: 50, train_Loss: 0.9617
training Epoch: 50, train_Loss: 2.2878
training Epoch: 50, train_Loss: 1.1579
training Epoch: 50, train_Loss: 1.1892
training Epoch: 50, train_Loss: 2.0468
training Epoch: 50, train_Loss: 1.5101
training Epoch: 50, train_Loss: 1.1468
training Epoch: 50, train_Loss: 2.5505
training Epoch: 50, train_Loss: 1.8698
training Epoch: 50, train_Loss: 1.1238
training Epoch: 50, train_Loss: 1.1004
training Epoch: 50, train_Loss: 0.6574
training Epoch: 50, train_Loss: 1.8600
training Epoch: 50, train_Loss: 1.1482
training Epoch: 50, train_Loss: 0.7715
training Epoch: 50, train_Loss: 0.9477
training Epoch: 50, train_Loss: 0.6418
training Epoch: 50, train_Loss: 1.4194
training Epoch: 50, train_Loss: 0.8139
training Epoch: 50, train_Loss: 0.6940
training Epoch: 50, train_Loss: 0.8603
training Epoch: 50, train_Loss: 0.5877
training Epoch: 50, train_Loss: 3.0379
training Epoch: 50, train_Loss: 1.8773
training Epoch: 50, train_Loss: 0.3885
training Epoch: 50, train_Loss: 1.1823
training Epoch: 50, train_Loss: 1.2582
training Epoch: 50, train_Loss: 0.9348
training Epoch: 50, train_Loss: 0.5525
training Epoch: 50, train_Loss: 0.5497
training Epoch: 50, train_Loss: 0.2891
training Epoch: 50, train_Loss: 2.0703
training Epoch: 50, train_Loss: 0.3738
training Epoch: 50, train_Loss: 2.4479
training Epoch: 50, train_Loss: 1.0210
training Epoch: 50, train_Loss: 0.8044
training Epoch: 50, train_Loss: 1.3946
training Epoch: 50, train_Loss: 0.6691
training Epoch: 50, train_Loss: 0.5014
training Epoch: 50, train_Loss: 0.9653
training Epoch: 50, train_Loss: 0.8980
training Epoch: 50, train_Loss: 0.6000
training Epoch: 50, train_Loss: 1.6035
training Epoch: 50, train_Loss: 0.8180
training Epoch: 50, train_Loss: 0.8762
training Epoch: 50, train_Loss: 0.4935
training Epoch: 50, train_Loss: 2.1262
training Epoch: 50, train_Loss: 0.9398
training Epoch: 50, train_Loss: 2.4685
training Epoch: 50, train_Loss: 0.8637
training Epoch: 50, train_Loss: 0.6032
training Epoch: 50, train_Loss: 0.4763
training Epoch: 50, train_Loss: 0.8165
training Epoch: 50, train_Loss: 0.9393
training Epoch: 50, train_Loss: 2.3915
training Epoch: 50, train_Loss: 1.2416
training Epoch: 50, train_Loss: 1.3095
training Epoch: 50, train_Loss: 1.0082
training Epoch: 50, train_Loss: 0.3709
training Epoch: 50, train_Loss: 2.1375
training Epoch: 50, train_Loss: 0.5306
training Epoch: 50, train_Loss: 1.1624
training Epoch: 50, train_Loss: 0.9635
training Epoch: 50, train_Loss: 1.3224
training Epoch: 50, train_Loss: 0.6287
training Epoch: 50, train_Loss: 0.2749
training Epoch: 50, train_Loss: 1.4476
training Epoch: 50, train_Loss: 1.7475
training Epoch: 50, train_Loss: 1.4792
training Epoch: 50, train_Loss: 0.9569
training Epoch: 50, train_Loss: 0.7132
training Epoch: 50, train_Loss: 0.4638
training Epoch: 50, train_Loss: 1.2045
training Epoch: 50, train_Loss: 0.5600
training Epoch: 50, train_Loss: 1.3948
training Epoch: 50, train_Loss: 0.6378
training Epoch: 50, train_Loss: 2.3721
training Epoch: 50, train_Loss: 2.2520
training Epoch: 50, train_Loss: 0.6750
training Epoch: 50, train_Loss: 1.2502
training Epoch: 50, train_Loss: 1.4765
training Epoch: 50, train_Loss: 0.4625
training Epoch: 50, train_Loss: 1.5057
training Epoch: 50, train_Loss: 1.1113
training Epoch: 50, train_Loss: 0.7050
training Epoch: 50, train_Loss: 0.5752
training Epoch: 50, train_Loss: 1.1360
training Epoch: 50, train_Loss: 1.6059
training Epoch: 50, train_Loss: 0.9813
training Epoch: 50, train_Loss: 0.5369
training Epoch: 50, train_Loss: 1.5625
training Epoch: 50, train_Loss: 0.6312
training Epoch: 50, train_Loss: 0.5208
training Epoch: 50, train_Loss: 0.4389
training Epoch: 50, train_Loss: 1.1722
training Epoch: 50, train_Loss: 1.8826
training Epoch: 50, train_Loss: 0.5596
training Epoch: 50, train_Loss: 0.3886
training Epoch: 50, train_Loss: 0.7791
training Epoch: 50, train_Loss: 0.6590
training Epoch: 50, train_Loss: 0.6480
training Epoch: 50, train_Loss: 0.7524
training Epoch: 50, train_Loss: 2.3910
training Epoch: 50, train_Loss: 1.5394
training Epoch: 50, train_Loss: 0.2683
training Epoch: 50, train_Loss: 2.1319
training Epoch: 50, train_Loss: 0.4975
training Epoch: 50, train_Loss: 0.2495
training Epoch: 50, train_Loss: 1.5954
training Epoch: 50, train_Loss: 0.7531
training Epoch: 50, train_Loss: 0.5117
training Epoch: 50, train_Loss: 0.9104
training Epoch: 50, train_Loss: 1.1275
training Epoch: 50, train_Loss: 0.5025
training Epoch: 50, train_Loss: 1.1122
training Epoch: 50, train_Loss: 0.3678
training Epoch: 50, train_Loss: 0.7722
training Epoch: 50, train_Loss: 1.0875
training Epoch: 50, train_Loss: 0.6469
training Epoch: 50, train_Loss: 0.6899
training Epoch: 50, train_Loss: 0.3355
training Epoch: 50, train_Loss: 0.8099
training Epoch: 50, train_Loss: 0.7197
training Epoch: 50, train_Loss: 1.8748
training Epoch: 50, train_Loss: 0.5101
training Epoch: 50, train_Loss: 1.1377
training Epoch: 50, train_Loss: 1.4806
training Epoch: 50, train_Loss: 1.5331
training Epoch: 50, train_Loss: 1.7415
training Epoch: 50, train_Loss: 0.3125
training Epoch: 50, train_Loss: 1.1648
training Epoch: 50, train_Loss: 1.6909
training Epoch: 50, train_Loss: 0.6161
training Epoch: 50, train_Loss: 1.1249
training Epoch: 50, train_Loss: 0.9177
training Epoch: 50, train_Loss: 2.4327
training Epoch: 50, train_Loss: 0.8805
training Epoch: 50, train_Loss: 0.4692
training Epoch: 50, train_Loss: 0.5218
training Epoch: 50, train_Loss: 0.4345
training Epoch: 50, train_Loss: 1.5837
training Epoch: 50, train_Loss: 0.7166
training Epoch: 50, train_Loss: 0.6183
training Epoch: 50, train_Loss: 1.2864
training Epoch: 50, train_Loss: 1.0327
training Epoch: 50, train_Loss: 1.3247
training Epoch: 50, train_Loss: 0.4379
training Epoch: 50, train_Loss: 0.7741
training Epoch: 50, train_Loss: 0.3389
training Epoch: 50, train_Loss: 0.4878
training Epoch: 50, train_Loss: 1.4642
training Epoch: 50, train_Loss: 0.5163
training Epoch: 50, train_Loss: 0.9104
training Epoch: 50, train_Loss: 0.8098
training Epoch: 50, train_Loss: 0.6297
training Epoch: 50, train_Loss: 1.2014
training Epoch: 50, train_Loss: 1.6231
training Epoch: 50, train_Loss: 2.1815
training Epoch: 50, train_Loss: 0.7920
training Epoch: 50, train_Loss: 0.2654
training Epoch: 50, train_Loss: 1.1124
training Epoch: 50, train_Loss: 1.2741
training Epoch: 50, train_Loss: 0.2324
training Epoch: 50, train_Loss: 0.8457
training Epoch: 50, train_Loss: 0.4665
training Epoch: 50, train_Loss: 0.6947
training Epoch: 50, train_Loss: 1.2942
training Epoch: 50, train_Loss: 1.3907
training Epoch: 50, train_Loss: 1.2514
training Epoch: 50, train_Loss: 2.8188
training Epoch: 50, train_Loss: 0.3487
training Epoch: 50, train_Loss: 0.6747
training Epoch: 50, train_Loss: 0.3690
training Epoch: 50, train_Loss: 0.3755
training Epoch: 50, train_Loss: 1.2212
training Epoch: 50, train_Loss: 0.5958
training Epoch: 50, train_Loss: 1.8528
training Epoch: 50, train_Loss: 1.0655
training Epoch: 50, train_Loss: 1.9320
training Epoch: 50, train_Loss: 0.5647
training Epoch: 50, train_Loss: 0.3036
training Epoch: 50, train_Loss: 2.3124
training Epoch: 50, train_Loss: 0.9082
training Epoch: 50, train_Loss: 0.4562
training Epoch: 50, train_Loss: 0.9904
training Epoch: 50, train_Loss: 0.8178
training Epoch: 50, train_Loss: 0.6561
training Epoch: 50, train_Loss: 1.8951
training Epoch: 50, train_Loss: 1.6676
training Epoch: 50, train_Loss: 0.9797
training Epoch: 50, train_Loss: 1.9931
training Epoch: 50, train_Loss: 0.6991
training Epoch: 50, train_Loss: 1.0947
training Epoch: 50, train_Loss: 0.9958
training Epoch: 50, train_Loss: 0.7385
training Epoch: 50, train_Loss: 0.2896
training Epoch: 50, train_Loss: 1.2434
training Epoch: 50, train_Loss: 1.7406
training Epoch: 50, train_Loss: 2.7195
training Epoch: 50, train_Loss: 1.5094
training Epoch: 50, train_Loss: 0.4907
training Epoch: 50, train_Loss: 0.9543
training Epoch: 50, train_Loss: 1.6401
training Epoch: 50, train_Loss: 0.4556
training Epoch: 50, train_Loss: 3.6183
training Epoch: 50, train_Loss: 0.9800
training Epoch: 50, train_Loss: 0.8078
training Epoch: 50, train_Loss: 1.0917
training Epoch: 50, train_Loss: 0.6422
training Epoch: 50, train_Loss: 0.5243
training Epoch: 50, train_Loss: 0.7516
training Epoch: 50, train_Loss: 0.6202
training Epoch: 50, train_Loss: 0.5518
training Epoch: 50, train_Loss: 1.4685
training Epoch: 50, train_Loss: 1.1051
training Epoch: 50, train_Loss: 2.0963
training Epoch: 50, train_Loss: 1.6295
training Epoch: 50, train_Loss: 0.6702
training Epoch: 50, train_Loss: 0.5341
training Epoch: 50, train_Loss: 0.3560
training Epoch: 50, train_Loss: 2.3154
training Epoch: 50, train_Loss: 0.4522
training Epoch: 50, train_Loss: 0.8703
training Epoch: 50, train_Loss: 0.9979
training Epoch: 50, train_Loss: 0.5405
training Epoch: 50, train_Loss: 0.9457
training Epoch: 50, train_Loss: 0.2390
training Epoch: 50, train_Loss: 1.2128
training Epoch: 50, train_Loss: 0.3003
training Epoch: 50, train_Loss: 1.2719
training Epoch: 50, train_Loss: 1.7447
training Epoch: 50, train_Loss: 0.4450
training Epoch: 50, train_Loss: 1.0501
training Epoch: 50, train_Loss: 0.3006
training Epoch: 50, train_Loss: 0.8602
training Epoch: 50, train_Loss: 0.4899
training Epoch: 50, train_Loss: 1.5782
training Epoch: 50, train_Loss: 0.2758
training Epoch: 50, train_Loss: 0.8289
training Epoch: 50, train_Loss: 1.6174
training Epoch: 50, train_Loss: 1.1256
training Epoch: 50, train_Loss: 0.3482
training Epoch: 50, train_Loss: 1.5414
training Epoch: 50, train_Loss: 0.6874
training Epoch: 50, train_Loss: 0.4903
training Epoch: 50, train_Loss: 0.6146
training Epoch: 50, train_Loss: 0.7125
training Epoch: 50, train_Loss: 1.9056
training Epoch: 50, train_Loss: 0.9973
training Epoch: 50, train_Loss: 1.2255
training Epoch: 50, train_Loss: 1.0681
training Epoch: 50, train_Loss: 2.4566
training Epoch: 50, train_Loss: 0.8660
training Epoch: 50, train_Loss: 0.7600
training Epoch: 50, train_Loss: 0.5780
training Epoch: 50, train_Loss: 2.2696
training Epoch: 50, train_Loss: 0.7711
training Epoch: 50, train_Loss: 0.4703
training Epoch: 50, train_Loss: 0.6203
training Epoch: 50, train_Loss: 0.4980
training Epoch: 50, train_Loss: 0.8721
training Epoch: 50, train_Loss: 1.1880
training Epoch: 50, train_Loss: 1.1875
training Epoch: 50, train_Loss: 0.2970
training Epoch: 50, train_Loss: 0.6211
training Epoch: 50, train_Loss: 1.3154
training Epoch: 50, train_Loss: 0.8485
training Epoch: 50, train_Loss: 0.2530
training Epoch: 50, train_Loss: 1.8838
training Epoch: 50, train_Loss: 0.7643
training Epoch: 50, train_Loss: 0.9869
training Epoch: 50, train_Loss: 1.6561
training Epoch: 50, train_Loss: 3.0117
training Epoch: 50, train_Loss: 0.6000
training Epoch: 50, train_Loss: 1.1889
training Epoch: 50, train_Loss: 1.3797
training Epoch: 50, train_Loss: 0.4226
training Epoch: 50, train_Loss: 1.5079
training Epoch: 50, train_Loss: 0.5477
training Epoch: 50, train_Loss: 1.0064
training Epoch: 50, train_Loss: 0.5873
training Epoch: 50, train_Loss: 2.8415
training Epoch: 50, train_Loss: 0.4040
training Epoch: 50, train_Loss: 1.0403
training Epoch: 50, train_Loss: 0.3491
training Epoch: 50, train_Loss: 2.2054
training Epoch: 50, train_Loss: 0.5583
training Epoch: 50, train_Loss: 0.5121
training Epoch: 50, train_Loss: 1.2213
training Epoch: 50, train_Loss: 0.4712
training Epoch: 50, train_Loss: 1.3726
training Epoch: 50, train_Loss: 0.4515
training Epoch: 50, train_Loss: 1.2700
training Epoch: 50, train_Loss: 2.1862
training Epoch: 50, train_Loss: 1.1030
training Epoch: 50, train_Loss: 0.5314
training Epoch: 50, train_Loss: 0.5048
training Epoch: 50, train_Loss: 1.2924
training Epoch: 50, train_Loss: 0.6396
training Epoch: 50, train_Loss: 0.4202
training Epoch: 50, train_Loss: 0.5218
training Epoch: 50, train_Loss: 0.4877
training Epoch: 50, train_Loss: 1.4413
training Epoch: 50, train_Loss: 3.3772
training Epoch: 50, train_Loss: 1.2404
training Epoch: 50, train_Loss: 0.9427
training Epoch: 50, train_Loss: 2.1196
training Epoch: 50, train_Loss: 1.2281
training Epoch: 50, train_Loss: 0.7846
training Epoch: 50, train_Loss: 0.5360
training Epoch: 50, train_Loss: 1.8090
training Epoch: 50, train_Loss: 1.3164
training Epoch: 50, train_Loss: 0.9853
training Epoch: 50, train_Loss: 0.4981
training Epoch: 50, train_Loss: 0.9068
training Epoch: 50, train_Loss: 1.4804
training Epoch: 50, train_Loss: 0.9346
training Epoch: 50, train_Loss: 0.4838
training Epoch: 50, train_Loss: 1.2948
training Epoch: 50, train_Loss: 0.6061
training Epoch: 50, train_Loss: 2.1552
training Epoch: 50, train_Loss: 0.7744
training Epoch: 50, train_Loss: 0.3394
training Epoch: 50, train_Loss: 1.0652
training Epoch: 50, train_Loss: 1.7999
training Epoch: 50, train_Loss: 1.3568
training Epoch: 50, train_Loss: 3.2778
training Epoch: 50, train_Loss: 0.9008
training Epoch: 50, train_Loss: 1.0306
training Epoch: 50, train_Loss: 1.0419
training Epoch: 50, train_Loss: 1.6481
training Epoch: 50, train_Loss: 1.0961
training Epoch: 50, train_Loss: 0.8243
training Epoch: 50, train_Loss: 0.6320
training Epoch: 50, train_Loss: 1.0685
training Epoch: 50, train_Loss: 0.4912
training Epoch: 50, train_Loss: 1.2477
training Epoch: 50, train_Loss: 0.9777
training Epoch: 50, train_Loss: 0.5104
training Epoch: 50, train_Loss: 0.6818
training Epoch: 50, train_Loss: 1.8157
training Epoch: 50, train_Loss: 1.0892
training Epoch: 50, train_Loss: 1.5455
training Epoch: 50, train_Loss: 1.4865
training Epoch: 50, train_Loss: 1.4077
training Epoch: 50, train_Loss: 0.6700
training Epoch: 50, train_Loss: 1.1743
training Epoch: 50, train_Loss: 1.7707
training Epoch: 50, train_Loss: 0.9550
training Epoch: 50, train_Loss: 0.4580
training Epoch: 50, train_Loss: 0.6209
training Epoch: 50, train_Loss: 1.8557
training Epoch: 50, train_Loss: 0.5301
training Epoch: 50, train_Loss: 1.1733
training Epoch: 50, train_Loss: 0.4149
training Epoch: 50, train_Loss: 0.6537
training Epoch: 50, train_Loss: 1.4087
training Epoch: 50, train_Loss: 0.9925
training Epoch: 50, train_Loss: 0.3203
training Epoch: 50, train_Loss: 1.3901
training Epoch: 50, train_Loss: 0.7910
training Epoch: 50, train_Loss: 2.5166
training Epoch: 50, train_Loss: 1.4602
training Epoch: 50, train_Loss: 0.6412
training Epoch: 50, train_Loss: 0.4229
training Epoch: 50, train_Loss: 2.6171
training Epoch: 50, train_Loss: 0.6725
training Epoch: 50, train_Loss: 0.6628
training Epoch: 50, train_Loss: 0.5847
training Epoch: 50, train_Loss: 1.3307
training Epoch: 50, train_Loss: 0.4038
training Epoch: 50, train_Loss: 2.3788
training Epoch: 50, train_Loss: 0.4123
training Epoch: 50, train_Loss: 0.7866
training Epoch: 50, train_Loss: 0.7039
training Epoch: 50, train_Loss: 1.3546
training Epoch: 50, train_Loss: 0.6055
training Epoch: 50, train_Loss: 1.2573
training Epoch: 50, train_Loss: 0.8160
training Epoch: 50, train_Loss: 0.3387
training Epoch: 50, train_Loss: 0.7117
training Epoch: 50, train_Loss: 0.4221
training Epoch: 50, train_Loss: 2.0254
training Epoch: 50, train_Loss: 0.7054
training Epoch: 50, train_Loss: 0.5295
training Epoch: 50, train_Loss: 1.8657
training Epoch: 50, train_Loss: 0.8951
training Epoch: 50, train_Loss: 0.4608
training Epoch: 50, train_Loss: 1.1343
training Epoch: 50, train_Loss: 1.5008
training Epoch: 50, train_Loss: 1.1126
training Epoch: 50, train_Loss: 0.5113
training Epoch: 50, train_Loss: 1.1021
training Epoch: 50, train_Loss: 2.2165
training Epoch: 50, train_Loss: 1.4569
training Epoch: 50, train_Loss: 1.1232
training Epoch: 50, train_Loss: 1.5141
training Epoch: 50, train_Loss: 1.3508
training Epoch: 50, train_Loss: 0.6945
training Epoch: 50, train_Loss: 1.1795
training Epoch: 50, train_Loss: 1.1218
training Epoch: 50, train_Loss: 0.5499
training Epoch: 50, train_Loss: 1.4225
training Epoch: 50, train_Loss: 1.1847
training Epoch: 50, train_Loss: 1.1072
training Epoch: 50, train_Loss: 1.9292
training Epoch: 50, train_Loss: 1.5977
training Epoch: 50, train_Loss: 0.6799
training Epoch: 50, train_Loss: 0.7097
training Epoch: 50, train_Loss: 1.4389
training Epoch: 50, train_Loss: 0.4176
training Epoch: 50, train_Loss: 2.4824
training Epoch: 50, train_Loss: 0.5504
training Epoch: 50, train_Loss: 1.9663
training Epoch: 50, train_Loss: 1.3700
training Epoch: 50, train_Loss: 1.0214
training Epoch: 50, train_Loss: 1.7140
training Epoch: 50, train_Loss: 2.0806
training Epoch: 50, train_Loss: 2.0594
training Epoch: 50, train_Loss: 1.3482
training Epoch: 50, train_Loss: 1.8342
training Epoch: 50, train_Loss: 2.0596
training Epoch: 50, train_Loss: 0.6262
training Epoch: 50, train_Loss: 1.1147
training Epoch: 50, train_Loss: 0.8691
training Epoch: 50, train_Loss: 1.8737
training Epoch: 50, train_Loss: 0.7350
training Epoch: 50, train_Loss: 1.7088
training Epoch: 50, train_Loss: 0.8153
training Epoch: 50, train_Loss: 1.1716
training Epoch: 50, train_Loss: 0.9980
training Epoch: 50, train_Loss: 0.7071
training Epoch: 50, train_Loss: 0.5656
training Epoch: 50, train_Loss: 1.8231
training Epoch: 50, train_Loss: 0.5376
training Epoch: 50, train_Loss: 0.9789
training Epoch: 50, train_Loss: 1.6498
training Epoch: 50, train_Loss: 0.8061
training Epoch: 50, train_Loss: 0.9358
training Epoch: 50, train_Loss: 0.8352
training Epoch: 50, train_Loss: 1.7161
training Epoch: 50, train_Loss: 1.1923
training Epoch: 50, train_Loss: 0.8902
training Epoch: 50, train_Loss: 1.0581
training Epoch: 50, train_Loss: 0.7988
training Epoch: 50, train_Loss: 0.3815
training Epoch: 50, train_Loss: 0.7539
training Epoch: 50, train_Loss: 1.5669
training Epoch: 50, train_Loss: 1.4009
training Epoch: 50, train_Loss: 1.1519
training Epoch: 50, train_Loss: 0.7890
training Epoch: 50, train_Loss: 0.9435
training Epoch: 50, train_Loss: 0.3917
training Epoch: 50, train_Loss: 0.7245
training Epoch: 50, train_Loss: 1.7684
training Epoch: 50, train_Loss: 2.0922
training Epoch: 50, train_Loss: 1.2128
training Epoch: 50, train_Loss: 0.4643
training Epoch: 50, train_Loss: 1.4186
training Epoch: 50, train_Loss: 0.4920
training Epoch: 50, train_Loss: 1.2667
training Epoch: 50, train_Loss: 1.3474
training Epoch: 50, train_Loss: 1.3190
training Epoch: 50, train_Loss: 0.7562
training Epoch: 50, train_Loss: 2.7854
training Epoch: 50, train_Loss: 2.1343
training Epoch: 50, train_Loss: 1.1987
training Epoch: 50, train_Loss: 1.0158
training Epoch: 50, train_Loss: 1.2115
training Epoch: 50, train_Loss: 0.7332
training Epoch: 50, train_Loss: 2.1879
training Epoch: 50, train_Loss: 1.3052
training Epoch: 50, train_Loss: 2.0165
training Epoch: 50, train_Loss: 0.3990
training Epoch: 50, train_Loss: 0.5456
training Epoch: 50, train_Loss: 0.3975
training Epoch: 50, train_Loss: 0.5312
training Epoch: 50, train_Loss: 1.3412
training Epoch: 50, train_Loss: 1.6667
training Epoch: 50, train_Loss: 0.2902
training Epoch: 50, train_Loss: 1.4600
training Epoch: 50, train_Loss: 0.2932
training Epoch: 50, train_Loss: 0.9220
training Epoch: 50, train_Loss: 0.8764
training Epoch: 50, train_Loss: 2.3751
training Epoch: 50, train_Loss: 0.9997
training Epoch: 50, train_Loss: 0.8102
training Epoch: 50, train_Loss: 0.2691
training Epoch: 50, train_Loss: 2.3627
training Epoch: 50, train_Loss: 0.3093
training Epoch: 50, train_Loss: 0.2403
training Epoch: 50, train_Loss: 1.1444
training Epoch: 50, train_Loss: 3.0445
training Epoch: 50, train_Loss: 1.0997
training Epoch: 50, train_Loss: 2.1565
training Epoch: 50, train_Loss: 1.4865
training Epoch: 50, train_Loss: 0.7587
training Epoch: 50, train_Loss: 0.6142
training Epoch: 50, train_Loss: 0.5371
training Epoch: 50, train_Loss: 0.5687
training Epoch: 50, train_Loss: 0.6868
training Epoch: 50, train_Loss: 1.0608
training Epoch: 50, train_Loss: 0.7232
training Epoch: 50, train_Loss: 1.1581
training Epoch: 50, train_Loss: 1.0408
training Epoch: 50, train_Loss: 0.6255
training Epoch: 50, train_Loss: 1.5692
training Epoch: 50, train_Loss: 1.0218
training Epoch: 50, train_Loss: 0.4375
training Epoch: 50, train_Loss: 1.1213
training Epoch: 50, train_Loss: 0.6218
training Epoch: 50, train_Loss: 0.3072
training Epoch: 50, train_Loss: 1.5491
training Epoch: 50, train_Loss: 0.3082
training Epoch: 50, train_Loss: 0.4705
training Epoch: 50, train_Loss: 0.8829
training Epoch: 50, train_Loss: 0.9054
training Epoch: 50, train_Loss: 0.3403
training Epoch: 50, train_Loss: 1.0671
training Epoch: 50, train_Loss: 0.1959
training Epoch: 50, train_Loss: 0.2199
training Epoch: 50, train_Loss: 0.5409
training Epoch: 50, train_Loss: 0.8345
training Epoch: 50, train_Loss: 0.6874
training Epoch: 50, train_Loss: 0.7055
training Epoch: 50, train_Loss: 3.0521
training Epoch: 50, train_Loss: 0.6060
fold,epoch,train_loss: 1 49 1.0829122
fold,epoch,train_loss: 1 50 1.0897253
fold,epoch,train_loss: 1 51 1.090723
fold,epoch,train_loss: 1 52 1.0894623
fold,epoch,train_loss: 1 53 1.0880529
fold,epoch,train_loss: 1 54 1.0950803
fold,epoch,train_loss: 1 55 1.0891931
fold,epoch,train_loss: 1 56 1.0908127
fold,epoch,train_loss: 1 57 1.0890056
fold,epoch,train_loss: 1 58 1.0906541
fold,epoch,train_loss: 1 59 1.0889474
fold,epoch,train_loss: 1 60 1.0895402
fold,epoch,train_loss: 1 61 1.0897876
fold,epoch,train_loss: 1 62 1.0871319
fold,epoch,train_loss: 1 63 1.0857686
fold,epoch,train_loss: 1 64 1.0857354
fold,epoch,train_loss: 1 65 1.0891019
fold,epoch,train_loss: 1 66 1.0917511
fold,epoch,train_loss: 1 67 1.086898
fold,epoch,train_loss: 1 68 1.0943791
fold,epoch,train_loss: 1 69 1.083657
fold,epoch,train_loss: 1 70 1.0924447
fold,epoch,train_loss: 1 71 1.0908667
fold,epoch,train_loss: 1 72 1.087651
fold,epoch,train_loss: 1 73 1.09233
fold,epoch,train_loss: 1 74 1.0930917
fold,epoch,train_loss: 1 75 1.0888317
fold,epoch,train_loss: 1 76 1.0893859
fold,epoch,train_loss: 1 77 1.0915655
fold,epoch,train_loss: 1 78 1.0911762
fold,epoch,train_loss: 1 79 1.088081
fold,epoch,train_loss: 1 80 1.0921295
fold,epoch,train_loss: 1 81 1.090401
fold,epoch,train_loss: 1 82 1.0925174
fold,epoch,train_loss: 1 83 1.0864211
fold,epoch,train_loss: 1 84 1.0898409
fold,epoch,train_loss: 1 85 1.0926769
fold,epoch,train_loss: 1 86 1.0919192
fold,epoch,train_loss: 1 87 1.0883528
fold,epoch,train_loss: 1 88 1.0830766
fold,epoch,train_loss: 1 89 1.0900544
fold,epoch,train_loss: 1 90 1.0916364
fold,epoch,train_loss: 1 91 1.0860544
fold,epoch,train_loss: 1 92 1.0859473
fold,epoch,train_loss: 1 93 1.090419
fold,epoch,train_loss: 1 94 1.0818526
fold,epoch,train_loss: 1 95 1.0850859
fold,epoch,train_loss: 1 96 1.0887175
fold,epoch,train_loss: 1 97 1.0919107
fold,epoch,train_loss: 1 98 1.0895087
training Epoch: 100, train_Loss: 1.2189
training Epoch: 100, train_Loss: 0.6304
training Epoch: 100, train_Loss: 3.2193
training Epoch: 100, train_Loss: 2.6178
training Epoch: 100, train_Loss: 2.7525
training Epoch: 100, train_Loss: 1.7502
training Epoch: 100, train_Loss: 0.3294
training Epoch: 100, train_Loss: 1.2454
training Epoch: 100, train_Loss: 2.0797
training Epoch: 100, train_Loss: 0.6194
training Epoch: 100, train_Loss: 0.7295
training Epoch: 100, train_Loss: 1.5866
training Epoch: 100, train_Loss: 1.0168
training Epoch: 100, train_Loss: 0.7842
training Epoch: 100, train_Loss: 1.0837
training Epoch: 100, train_Loss: 0.8458
training Epoch: 100, train_Loss: 3.0594
training Epoch: 100, train_Loss: 1.8694
training Epoch: 100, train_Loss: 1.6818
training Epoch: 100, train_Loss: 0.7491
training Epoch: 100, train_Loss: 2.0498
training Epoch: 100, train_Loss: 2.8017
training Epoch: 100, train_Loss: 0.7384
training Epoch: 100, train_Loss: 0.7794
training Epoch: 100, train_Loss: 0.7826
training Epoch: 100, train_Loss: 1.0963
training Epoch: 100, train_Loss: 0.9223
training Epoch: 100, train_Loss: 0.6888
training Epoch: 100, train_Loss: 0.9201
training Epoch: 100, train_Loss: 2.9016
training Epoch: 100, train_Loss: 1.9862
training Epoch: 100, train_Loss: 0.7471
training Epoch: 100, train_Loss: 1.0535
training Epoch: 100, train_Loss: 1.1651
training Epoch: 100, train_Loss: 0.9071
training Epoch: 100, train_Loss: 0.7917
training Epoch: 100, train_Loss: 0.2999
training Epoch: 100, train_Loss: 1.0447
training Epoch: 100, train_Loss: 1.2619
training Epoch: 100, train_Loss: 0.5748
training Epoch: 100, train_Loss: 1.1159
training Epoch: 100, train_Loss: 3.1658
training Epoch: 100, train_Loss: 1.9488
training Epoch: 100, train_Loss: 0.5757
training Epoch: 100, train_Loss: 0.9960
training Epoch: 100, train_Loss: 0.7851
training Epoch: 100, train_Loss: 1.2795
training Epoch: 100, train_Loss: 1.4332
training Epoch: 100, train_Loss: 0.4815
training Epoch: 100, train_Loss: 0.2807
training Epoch: 100, train_Loss: 1.9186
training Epoch: 100, train_Loss: 1.4907
training Epoch: 100, train_Loss: 0.6868
training Epoch: 100, train_Loss: 1.7697
training Epoch: 100, train_Loss: 1.3840
training Epoch: 100, train_Loss: 0.3414
training Epoch: 100, train_Loss: 0.8934
training Epoch: 100, train_Loss: 2.0326
training Epoch: 100, train_Loss: 2.8174
training Epoch: 100, train_Loss: 0.4421
training Epoch: 100, train_Loss: 1.7739
training Epoch: 100, train_Loss: 1.2193
training Epoch: 100, train_Loss: 1.9074
training Epoch: 100, train_Loss: 0.8263
training Epoch: 100, train_Loss: 0.4948
training Epoch: 100, train_Loss: 0.9505
training Epoch: 100, train_Loss: 0.9819
training Epoch: 100, train_Loss: 1.0249
training Epoch: 100, train_Loss: 0.8279
training Epoch: 100, train_Loss: 0.4889
training Epoch: 100, train_Loss: 1.9165
training Epoch: 100, train_Loss: 0.9299
training Epoch: 100, train_Loss: 0.5261
training Epoch: 100, train_Loss: 2.4771
training Epoch: 100, train_Loss: 0.4183
training Epoch: 100, train_Loss: 0.8062
training Epoch: 100, train_Loss: 1.6145
training Epoch: 100, train_Loss: 1.2779
training Epoch: 100, train_Loss: 0.8347
training Epoch: 100, train_Loss: 0.7147
training Epoch: 100, train_Loss: 1.1675
training Epoch: 100, train_Loss: 1.5153
training Epoch: 100, train_Loss: 1.1257
training Epoch: 100, train_Loss: 1.1318
training Epoch: 100, train_Loss: 1.1299
training Epoch: 100, train_Loss: 0.3837
training Epoch: 100, train_Loss: 1.5962
training Epoch: 100, train_Loss: 1.4641
training Epoch: 100, train_Loss: 1.7111
training Epoch: 100, train_Loss: 0.5538
training Epoch: 100, train_Loss: 0.9072
training Epoch: 100, train_Loss: 0.9300
training Epoch: 100, train_Loss: 0.6087
training Epoch: 100, train_Loss: 1.6132
training Epoch: 100, train_Loss: 0.4710
training Epoch: 100, train_Loss: 0.4191
training Epoch: 100, train_Loss: 0.5054
training Epoch: 100, train_Loss: 0.9423
training Epoch: 100, train_Loss: 0.8331
training Epoch: 100, train_Loss: 1.8112
training Epoch: 100, train_Loss: 1.1816
training Epoch: 100, train_Loss: 1.0304
training Epoch: 100, train_Loss: 3.3617
training Epoch: 100, train_Loss: 1.7766
training Epoch: 100, train_Loss: 1.3588
training Epoch: 100, train_Loss: 0.6316
training Epoch: 100, train_Loss: 1.3043
training Epoch: 100, train_Loss: 1.7413
training Epoch: 100, train_Loss: 0.6228
training Epoch: 100, train_Loss: 0.5615
training Epoch: 100, train_Loss: 1.4501
training Epoch: 100, train_Loss: 0.7777
training Epoch: 100, train_Loss: 1.6838
training Epoch: 100, train_Loss: 0.8180
training Epoch: 100, train_Loss: 0.4711
training Epoch: 100, train_Loss: 0.8446
training Epoch: 100, train_Loss: 0.7044
training Epoch: 100, train_Loss: 0.4983
training Epoch: 100, train_Loss: 2.7082
training Epoch: 100, train_Loss: 0.4483
training Epoch: 100, train_Loss: 0.4309
training Epoch: 100, train_Loss: 0.9986
training Epoch: 100, train_Loss: 1.6060
training Epoch: 100, train_Loss: 1.2984
training Epoch: 100, train_Loss: 1.4326
training Epoch: 100, train_Loss: 0.5484
training Epoch: 100, train_Loss: 2.5813
training Epoch: 100, train_Loss: 1.2396
training Epoch: 100, train_Loss: 1.5568
training Epoch: 100, train_Loss: 0.4214
training Epoch: 100, train_Loss: 0.5988
training Epoch: 100, train_Loss: 1.4641
training Epoch: 100, train_Loss: 1.9867
training Epoch: 100, train_Loss: 0.9225
training Epoch: 100, train_Loss: 1.5075
training Epoch: 100, train_Loss: 2.5989
training Epoch: 100, train_Loss: 1.3798
training Epoch: 100, train_Loss: 0.8877
training Epoch: 100, train_Loss: 0.9301
training Epoch: 100, train_Loss: 1.5190
training Epoch: 100, train_Loss: 0.7628
training Epoch: 100, train_Loss: 1.0454
training Epoch: 100, train_Loss: 3.1458
training Epoch: 100, train_Loss: 0.6922
training Epoch: 100, train_Loss: 0.4145
training Epoch: 100, train_Loss: 0.5152
training Epoch: 100, train_Loss: 0.6255
training Epoch: 100, train_Loss: 0.9456
training Epoch: 100, train_Loss: 0.3255
training Epoch: 100, train_Loss: 2.8037
training Epoch: 100, train_Loss: 1.6283
training Epoch: 100, train_Loss: 1.4980
training Epoch: 100, train_Loss: 3.9750
training Epoch: 100, train_Loss: 1.3318
training Epoch: 100, train_Loss: 0.5537
training Epoch: 100, train_Loss: 1.2767
training Epoch: 100, train_Loss: 0.6901
training Epoch: 100, train_Loss: 1.1900
training Epoch: 100, train_Loss: 0.5755
training Epoch: 100, train_Loss: 1.7951
training Epoch: 100, train_Loss: 0.4226
training Epoch: 100, train_Loss: 0.8404
training Epoch: 100, train_Loss: 0.7169
training Epoch: 100, train_Loss: 1.5435
training Epoch: 100, train_Loss: 1.9726
training Epoch: 100, train_Loss: 0.5741
training Epoch: 100, train_Loss: 0.4207
training Epoch: 100, train_Loss: 1.4616
training Epoch: 100, train_Loss: 0.6789
training Epoch: 100, train_Loss: 1.4256
training Epoch: 100, train_Loss: 1.0612
training Epoch: 100, train_Loss: 0.6953
training Epoch: 100, train_Loss: 1.2419
training Epoch: 100, train_Loss: 0.9076
training Epoch: 100, train_Loss: 1.4721
training Epoch: 100, train_Loss: 0.8999
training Epoch: 100, train_Loss: 1.1463
training Epoch: 100, train_Loss: 0.9539
training Epoch: 100, train_Loss: 0.8683
training Epoch: 100, train_Loss: 0.5781
training Epoch: 100, train_Loss: 1.7897
training Epoch: 100, train_Loss: 0.5724
training Epoch: 100, train_Loss: 1.5736
training Epoch: 100, train_Loss: 1.6248
training Epoch: 100, train_Loss: 1.0686
training Epoch: 100, train_Loss: 0.5578
training Epoch: 100, train_Loss: 3.7346
training Epoch: 100, train_Loss: 0.5845
training Epoch: 100, train_Loss: 0.5013
training Epoch: 100, train_Loss: 2.5368
training Epoch: 100, train_Loss: 1.0634
training Epoch: 100, train_Loss: 0.4457
training Epoch: 100, train_Loss: 0.7882
training Epoch: 100, train_Loss: 0.5834
training Epoch: 100, train_Loss: 1.2636
training Epoch: 100, train_Loss: 0.5560
training Epoch: 100, train_Loss: 1.0194
training Epoch: 100, train_Loss: 1.9457
training Epoch: 100, train_Loss: 1.5034
training Epoch: 100, train_Loss: 0.6378
training Epoch: 100, train_Loss: 1.6158
training Epoch: 100, train_Loss: 1.3152
training Epoch: 100, train_Loss: 0.9463
training Epoch: 100, train_Loss: 0.7971
training Epoch: 100, train_Loss: 0.7247
training Epoch: 100, train_Loss: 1.5745
training Epoch: 100, train_Loss: 0.6692
training Epoch: 100, train_Loss: 0.4838
training Epoch: 100, train_Loss: 0.8719
training Epoch: 100, train_Loss: 0.4203
training Epoch: 100, train_Loss: 1.3679
training Epoch: 100, train_Loss: 0.5282
training Epoch: 100, train_Loss: 1.5354
training Epoch: 100, train_Loss: 0.2106
training Epoch: 100, train_Loss: 0.2945
training Epoch: 100, train_Loss: 0.4247
training Epoch: 100, train_Loss: 0.2211
training Epoch: 100, train_Loss: 0.7889
training Epoch: 100, train_Loss: 3.7079
training Epoch: 100, train_Loss: 0.1599
training Epoch: 100, train_Loss: 0.4270
training Epoch: 100, train_Loss: 0.5268
training Epoch: 100, train_Loss: 1.6341
training Epoch: 100, train_Loss: 0.7640
training Epoch: 100, train_Loss: 0.7807
training Epoch: 100, train_Loss: 0.2569
training Epoch: 100, train_Loss: 0.8514
training Epoch: 100, train_Loss: 1.2651
training Epoch: 100, train_Loss: 1.4120
training Epoch: 100, train_Loss: 1.9791
training Epoch: 100, train_Loss: 0.5393
training Epoch: 100, train_Loss: 1.6742
training Epoch: 100, train_Loss: 2.1696
training Epoch: 100, train_Loss: 0.6516
training Epoch: 100, train_Loss: 0.7518
training Epoch: 100, train_Loss: 0.7391
training Epoch: 100, train_Loss: 0.5115
training Epoch: 100, train_Loss: 0.3666
training Epoch: 100, train_Loss: 2.1067
training Epoch: 100, train_Loss: 1.1999
training Epoch: 100, train_Loss: 0.8916
training Epoch: 100, train_Loss: 1.2363
training Epoch: 100, train_Loss: 1.0596
training Epoch: 100, train_Loss: 2.1824
training Epoch: 100, train_Loss: 0.5179
training Epoch: 100, train_Loss: 0.9252
training Epoch: 100, train_Loss: 0.6840
training Epoch: 100, train_Loss: 0.7606
training Epoch: 100, train_Loss: 0.8714
training Epoch: 100, train_Loss: 1.0455
training Epoch: 100, train_Loss: 0.9491
training Epoch: 100, train_Loss: 0.7441
training Epoch: 100, train_Loss: 0.4006
training Epoch: 100, train_Loss: 1.2778
training Epoch: 100, train_Loss: 0.5946
training Epoch: 100, train_Loss: 0.5530
training Epoch: 100, train_Loss: 0.8598
training Epoch: 100, train_Loss: 1.3667
training Epoch: 100, train_Loss: 0.3465
training Epoch: 100, train_Loss: 1.0620
training Epoch: 100, train_Loss: 1.9209
training Epoch: 100, train_Loss: 0.8027
training Epoch: 100, train_Loss: 0.2506
training Epoch: 100, train_Loss: 0.4489
training Epoch: 100, train_Loss: 1.3007
training Epoch: 100, train_Loss: 2.0482
training Epoch: 100, train_Loss: 0.7715
training Epoch: 100, train_Loss: 0.8507
training Epoch: 100, train_Loss: 0.9449
training Epoch: 100, train_Loss: 0.3397
training Epoch: 100, train_Loss: 0.5949
training Epoch: 100, train_Loss: 0.5260
training Epoch: 100, train_Loss: 1.2430
training Epoch: 100, train_Loss: 1.0510
training Epoch: 100, train_Loss: 1.1986
training Epoch: 100, train_Loss: 1.1795
training Epoch: 100, train_Loss: 0.4375
training Epoch: 100, train_Loss: 0.6541
training Epoch: 100, train_Loss: 1.5761
training Epoch: 100, train_Loss: 1.0432
training Epoch: 100, train_Loss: 0.6836
training Epoch: 100, train_Loss: 0.7749
training Epoch: 100, train_Loss: 0.9119
training Epoch: 100, train_Loss: 0.7331
training Epoch: 100, train_Loss: 0.4700
training Epoch: 100, train_Loss: 0.8175
training Epoch: 100, train_Loss: 0.5853
training Epoch: 100, train_Loss: 0.7478
training Epoch: 100, train_Loss: 1.5908
training Epoch: 100, train_Loss: 0.9600
training Epoch: 100, train_Loss: 0.2927
training Epoch: 100, train_Loss: 1.9915
training Epoch: 100, train_Loss: 0.4721
training Epoch: 100, train_Loss: 1.2289
training Epoch: 100, train_Loss: 2.3450
training Epoch: 100, train_Loss: 0.3382
training Epoch: 100, train_Loss: 1.1961
training Epoch: 100, train_Loss: 1.2369
training Epoch: 100, train_Loss: 0.4741
training Epoch: 100, train_Loss: 0.6953
training Epoch: 100, train_Loss: 2.8404
training Epoch: 100, train_Loss: 1.2664
training Epoch: 100, train_Loss: 1.3461
training Epoch: 100, train_Loss: 0.8351
training Epoch: 100, train_Loss: 0.5324
training Epoch: 100, train_Loss: 1.9516
training Epoch: 100, train_Loss: 0.7541
training Epoch: 100, train_Loss: 0.9218
training Epoch: 100, train_Loss: 0.7846
training Epoch: 100, train_Loss: 0.9740
training Epoch: 100, train_Loss: 0.7049
training Epoch: 100, train_Loss: 1.3759
training Epoch: 100, train_Loss: 1.1297
training Epoch: 100, train_Loss: 0.6637
training Epoch: 100, train_Loss: 1.8344
training Epoch: 100, train_Loss: 0.5141
training Epoch: 100, train_Loss: 0.7608
training Epoch: 100, train_Loss: 2.2807
training Epoch: 100, train_Loss: 1.0943
training Epoch: 100, train_Loss: 0.4730
training Epoch: 100, train_Loss: 0.6299
training Epoch: 100, train_Loss: 1.6248
training Epoch: 100, train_Loss: 1.0561
training Epoch: 100, train_Loss: 0.4480
training Epoch: 100, train_Loss: 1.5378
training Epoch: 100, train_Loss: 0.8466
training Epoch: 100, train_Loss: 0.4919
training Epoch: 100, train_Loss: 0.5514
training Epoch: 100, train_Loss: 0.8024
training Epoch: 100, train_Loss: 1.6554
training Epoch: 100, train_Loss: 0.8591
training Epoch: 100, train_Loss: 1.4916
training Epoch: 100, train_Loss: 1.0948
training Epoch: 100, train_Loss: 0.6168
training Epoch: 100, train_Loss: 0.7433
training Epoch: 100, train_Loss: 0.4606
training Epoch: 100, train_Loss: 1.7638
training Epoch: 100, train_Loss: 1.4068
training Epoch: 100, train_Loss: 0.7920
training Epoch: 100, train_Loss: 1.3949
training Epoch: 100, train_Loss: 0.5702
training Epoch: 100, train_Loss: 0.7725
training Epoch: 100, train_Loss: 0.7108
training Epoch: 100, train_Loss: 0.7873
training Epoch: 100, train_Loss: 0.7234
training Epoch: 100, train_Loss: 2.2114
training Epoch: 100, train_Loss: 0.5139
training Epoch: 100, train_Loss: 0.4837
training Epoch: 100, train_Loss: 0.6015
training Epoch: 100, train_Loss: 0.7573
training Epoch: 100, train_Loss: 1.7776
training Epoch: 100, train_Loss: 1.4052
training Epoch: 100, train_Loss: 0.6676
training Epoch: 100, train_Loss: 2.2937
training Epoch: 100, train_Loss: 1.1724
training Epoch: 100, train_Loss: 0.4343
training Epoch: 100, train_Loss: 0.4281
training Epoch: 100, train_Loss: 1.1961
training Epoch: 100, train_Loss: 1.3765
training Epoch: 100, train_Loss: 0.5085
training Epoch: 100, train_Loss: 1.6957
training Epoch: 100, train_Loss: 0.4532
training Epoch: 100, train_Loss: 0.5448
training Epoch: 100, train_Loss: 0.6126
training Epoch: 100, train_Loss: 1.2344
training Epoch: 100, train_Loss: 0.5381
training Epoch: 100, train_Loss: 0.6049
training Epoch: 100, train_Loss: 0.5808
training Epoch: 100, train_Loss: 1.3905
training Epoch: 100, train_Loss: 0.4063
training Epoch: 100, train_Loss: 0.1953
training Epoch: 100, train_Loss: 0.3711
training Epoch: 100, train_Loss: 0.7652
training Epoch: 100, train_Loss: 1.0297
training Epoch: 100, train_Loss: 1.8176
training Epoch: 100, train_Loss: 2.1901
training Epoch: 100, train_Loss: 0.3178
training Epoch: 100, train_Loss: 1.2158
training Epoch: 100, train_Loss: 0.1975
training Epoch: 100, train_Loss: 1.3790
training Epoch: 100, train_Loss: 0.2622
training Epoch: 100, train_Loss: 0.5440
training Epoch: 100, train_Loss: 0.5295
training Epoch: 100, train_Loss: 3.1054
training Epoch: 100, train_Loss: 0.2905
training Epoch: 100, train_Loss: 1.4453
training Epoch: 100, train_Loss: 1.2764
training Epoch: 100, train_Loss: 0.9612
training Epoch: 100, train_Loss: 2.8278
training Epoch: 100, train_Loss: 0.6677
training Epoch: 100, train_Loss: 1.2814
training Epoch: 100, train_Loss: 0.9292
training Epoch: 100, train_Loss: 3.0103
training Epoch: 100, train_Loss: 0.6539
training Epoch: 100, train_Loss: 1.0146
training Epoch: 100, train_Loss: 2.2574
training Epoch: 100, train_Loss: 0.6470
training Epoch: 100, train_Loss: 0.9264
training Epoch: 100, train_Loss: 1.5381
training Epoch: 100, train_Loss: 1.0288
training Epoch: 100, train_Loss: 1.0886
training Epoch: 100, train_Loss: 0.5991
training Epoch: 100, train_Loss: 0.4741
training Epoch: 100, train_Loss: 1.0896
training Epoch: 100, train_Loss: 0.6986
training Epoch: 100, train_Loss: 1.2649
training Epoch: 100, train_Loss: 0.7482
training Epoch: 100, train_Loss: 0.8484
training Epoch: 100, train_Loss: 0.4377
training Epoch: 100, train_Loss: 0.3559
training Epoch: 100, train_Loss: 0.5666
training Epoch: 100, train_Loss: 0.4122
training Epoch: 100, train_Loss: 1.3312
training Epoch: 100, train_Loss: 1.0082
training Epoch: 100, train_Loss: 0.4942
training Epoch: 100, train_Loss: 3.1296
training Epoch: 100, train_Loss: 0.1035
training Epoch: 100, train_Loss: 1.0853
training Epoch: 100, train_Loss: 0.7798
training Epoch: 100, train_Loss: 0.5007
training Epoch: 100, train_Loss: 1.2147
training Epoch: 100, train_Loss: 0.3251
training Epoch: 100, train_Loss: 0.2363
training Epoch: 100, train_Loss: 1.9374
training Epoch: 100, train_Loss: 1.2175
training Epoch: 100, train_Loss: 0.4983
training Epoch: 100, train_Loss: 0.8222
training Epoch: 100, train_Loss: 0.3894
training Epoch: 100, train_Loss: 1.4474
training Epoch: 100, train_Loss: 0.2478
training Epoch: 100, train_Loss: 0.5405
training Epoch: 100, train_Loss: 1.0553
training Epoch: 100, train_Loss: 2.0127
training Epoch: 100, train_Loss: 0.3080
training Epoch: 100, train_Loss: 0.3348
training Epoch: 100, train_Loss: 0.5506
training Epoch: 100, train_Loss: 0.5483
training Epoch: 100, train_Loss: 1.4058
training Epoch: 100, train_Loss: 1.5799
training Epoch: 100, train_Loss: 1.8223
training Epoch: 100, train_Loss: 0.3634
training Epoch: 100, train_Loss: 1.8353
training Epoch: 100, train_Loss: 1.2895
training Epoch: 100, train_Loss: 2.5373
training Epoch: 100, train_Loss: 1.3449
training Epoch: 100, train_Loss: 0.3636
training Epoch: 100, train_Loss: 2.9679
training Epoch: 100, train_Loss: 0.8080
training Epoch: 100, train_Loss: 0.5955
training Epoch: 100, train_Loss: 0.9104
training Epoch: 100, train_Loss: 0.9332
training Epoch: 100, train_Loss: 1.8032
training Epoch: 100, train_Loss: 1.8629
training Epoch: 100, train_Loss: 0.8064
training Epoch: 100, train_Loss: 1.1053
training Epoch: 100, train_Loss: 0.8590
training Epoch: 100, train_Loss: 1.0023
training Epoch: 100, train_Loss: 0.7653
training Epoch: 100, train_Loss: 0.6477
training Epoch: 100, train_Loss: 2.3605
training Epoch: 100, train_Loss: 1.0401
training Epoch: 100, train_Loss: 1.0682
training Epoch: 100, train_Loss: 0.6848
training Epoch: 100, train_Loss: 0.6164
training Epoch: 100, train_Loss: 0.5767
training Epoch: 100, train_Loss: 1.8462
training Epoch: 100, train_Loss: 0.5445
training Epoch: 100, train_Loss: 1.8071
training Epoch: 100, train_Loss: 0.3952
training Epoch: 100, train_Loss: 0.6915
training Epoch: 100, train_Loss: 0.5642
training Epoch: 100, train_Loss: 1.7989
training Epoch: 100, train_Loss: 0.9417
training Epoch: 100, train_Loss: 1.0811
training Epoch: 100, train_Loss: 1.1495
training Epoch: 100, train_Loss: 0.7187
training Epoch: 100, train_Loss: 1.7701
training Epoch: 100, train_Loss: 0.6457
training Epoch: 100, train_Loss: 1.8954
training Epoch: 100, train_Loss: 0.8296
training Epoch: 100, train_Loss: 1.5074
training Epoch: 100, train_Loss: 0.5063
training Epoch: 100, train_Loss: 2.9091
training Epoch: 100, train_Loss: 0.8187
training Epoch: 100, train_Loss: 1.3185
training Epoch: 100, train_Loss: 1.1470
training Epoch: 100, train_Loss: 1.4117
training Epoch: 100, train_Loss: 0.4308
training Epoch: 100, train_Loss: 1.1850
training Epoch: 100, train_Loss: 0.5026
training Epoch: 100, train_Loss: 1.9632
training Epoch: 100, train_Loss: 1.7830
training Epoch: 100, train_Loss: 1.0929
training Epoch: 100, train_Loss: 0.5039
training Epoch: 100, train_Loss: 0.5552
training Epoch: 100, train_Loss: 0.4956
training Epoch: 100, train_Loss: 0.6635
training Epoch: 100, train_Loss: 0.8581
training Epoch: 100, train_Loss: 0.4866
training Epoch: 100, train_Loss: 0.8635
training Epoch: 100, train_Loss: 2.3087
training Epoch: 100, train_Loss: 0.7428
training Epoch: 100, train_Loss: 0.7129
training Epoch: 100, train_Loss: 0.4954
training Epoch: 100, train_Loss: 1.0034
training Epoch: 100, train_Loss: 0.8522
training Epoch: 100, train_Loss: 1.4405
training Epoch: 100, train_Loss: 2.5176
training Epoch: 100, train_Loss: 0.7420
training Epoch: 100, train_Loss: 1.6510
training Epoch: 100, train_Loss: 2.1707
training Epoch: 100, train_Loss: 0.5145
training Epoch: 100, train_Loss: 0.9298
training Epoch: 100, train_Loss: 0.3481
training Epoch: 100, train_Loss: 1.0399
training Epoch: 100, train_Loss: 1.4863
training Epoch: 100, train_Loss: 0.9632
training Epoch: 100, train_Loss: 0.7132
training Epoch: 100, train_Loss: 0.6447
training Epoch: 100, train_Loss: 0.5319
training Epoch: 100, train_Loss: 0.6589
training Epoch: 100, train_Loss: 1.1210
training Epoch: 100, train_Loss: 0.7474
training Epoch: 100, train_Loss: 0.4297
training Epoch: 100, train_Loss: 0.6638
training Epoch: 100, train_Loss: 0.8196
training Epoch: 100, train_Loss: 1.4330
training Epoch: 100, train_Loss: 1.1011
training Epoch: 100, train_Loss: 1.4453
training Epoch: 100, train_Loss: 1.1704
training Epoch: 100, train_Loss: 1.2667
training Epoch: 100, train_Loss: 0.7172
training Epoch: 100, train_Loss: 1.1643
training Epoch: 100, train_Loss: 1.2353
training Epoch: 100, train_Loss: 0.8962
training Epoch: 100, train_Loss: 1.0911
training Epoch: 100, train_Loss: 1.6237
training Epoch: 100, train_Loss: 1.7674
training Epoch: 100, train_Loss: 0.3672
training Epoch: 100, train_Loss: 1.0697
training Epoch: 100, train_Loss: 0.8076
training Epoch: 100, train_Loss: 0.7692
training Epoch: 100, train_Loss: 0.6654
training Epoch: 100, train_Loss: 1.2525
training Epoch: 100, train_Loss: 1.3449
training Epoch: 100, train_Loss: 1.4195
training Epoch: 100, train_Loss: 0.7238
training Epoch: 100, train_Loss: 1.5515
training Epoch: 100, train_Loss: 0.6742
training Epoch: 100, train_Loss: 0.4269
training Epoch: 100, train_Loss: 0.4363
training Epoch: 100, train_Loss: 1.2174
training Epoch: 100, train_Loss: 0.6217
training Epoch: 100, train_Loss: 1.6238
training Epoch: 100, train_Loss: 0.6239
training Epoch: 100, train_Loss: 0.6215
training Epoch: 100, train_Loss: 0.9722
training Epoch: 100, train_Loss: 0.6859
training Epoch: 100, train_Loss: 2.0641
training Epoch: 100, train_Loss: 2.1935
training Epoch: 100, train_Loss: 2.2725
training Epoch: 100, train_Loss: 0.8177
training Epoch: 100, train_Loss: 0.7804
training Epoch: 100, train_Loss: 0.9197
training Epoch: 100, train_Loss: 2.1130
training Epoch: 100, train_Loss: 0.5529
training Epoch: 100, train_Loss: 2.0011
training Epoch: 100, train_Loss: 1.1611
training Epoch: 100, train_Loss: 1.5686
training Epoch: 100, train_Loss: 0.5643
training Epoch: 100, train_Loss: 0.4647
training Epoch: 100, train_Loss: 1.4080
training Epoch: 100, train_Loss: 0.9199
training Epoch: 100, train_Loss: 0.7700
training Epoch: 100, train_Loss: 0.4727
fold,epoch,train_loss: 1 99 1.0871966
fold,epoch,train_loss: 1 100 1.088004
====Evaluation
fold:1, epoch:100,train:1.088004, valid:1.079758 

fold: 2
fold,epoch,train_loss: 2 0 1.0890704
fold,epoch,train_loss: 2 1 1.086987
fold,epoch,train_loss: 2 2 1.0909443
fold,epoch,train_loss: 2 3 1.0924777
fold,epoch,train_loss: 2 4 1.0913273
fold,epoch,train_loss: 2 5 1.0904427
fold,epoch,train_loss: 2 6 1.0906773
fold,epoch,train_loss: 2 7 1.0931993
fold,epoch,train_loss: 2 8 1.0898669
fold,epoch,train_loss: 2 9 1.0851091
fold,epoch,train_loss: 2 10 1.09017
fold,epoch,train_loss: 2 11 1.0978233
fold,epoch,train_loss: 2 12 1.0872735
fold,epoch,train_loss: 2 13 1.0904908
fold,epoch,train_loss: 2 14 1.0837755
fold,epoch,train_loss: 2 15 1.0903602
fold,epoch,train_loss: 2 16 1.0891396
fold,epoch,train_loss: 2 17 1.0874608
fold,epoch,train_loss: 2 18 1.0806553
fold,epoch,train_loss: 2 19 1.0852212
fold,epoch,train_loss: 2 20 1.0904816
fold,epoch,train_loss: 2 21 1.0936265
fold,epoch,train_loss: 2 22 1.0863949
fold,epoch,train_loss: 2 23 1.0894384
fold,epoch,train_loss: 2 24 1.0953342
fold,epoch,train_loss: 2 25 1.0945444
fold,epoch,train_loss: 2 26 1.0956082
fold,epoch,train_loss: 2 27 1.0895376
fold,epoch,train_loss: 2 28 1.0928348
fold,epoch,train_loss: 2 29 1.0964779
fold,epoch,train_loss: 2 30 1.0931456
fold,epoch,train_loss: 2 31 1.0962156
fold,epoch,train_loss: 2 32 1.088677
fold,epoch,train_loss: 2 33 1.0870442
fold,epoch,train_loss: 2 34 1.0892007
fold,epoch,train_loss: 2 35 1.0908641
fold,epoch,train_loss: 2 36 1.0886577
fold,epoch,train_loss: 2 37 1.0891899
fold,epoch,train_loss: 2 38 1.0966947
fold,epoch,train_loss: 2 39 1.0892013
fold,epoch,train_loss: 2 40 1.0907086
fold,epoch,train_loss: 2 41 1.0896674
fold,epoch,train_loss: 2 42 1.088591
fold,epoch,train_loss: 2 43 1.091329
fold,epoch,train_loss: 2 44 1.0872871
fold,epoch,train_loss: 2 45 1.0859307
fold,epoch,train_loss: 2 46 1.0827779
fold,epoch,train_loss: 2 47 1.0926805
fold,epoch,train_loss: 2 48 1.0917157
training Epoch: 50, train_Loss: 0.5443
training Epoch: 50, train_Loss: 1.3038
training Epoch: 50, train_Loss: 1.0011
training Epoch: 50, train_Loss: 0.7252
training Epoch: 50, train_Loss: 0.6693
training Epoch: 50, train_Loss: 1.0870
training Epoch: 50, train_Loss: 0.9496
training Epoch: 50, train_Loss: 0.5673
training Epoch: 50, train_Loss: 1.1924
training Epoch: 50, train_Loss: 0.3030
training Epoch: 50, train_Loss: 0.6193
training Epoch: 50, train_Loss: 2.3285
training Epoch: 50, train_Loss: 0.4772
training Epoch: 50, train_Loss: 2.6373
training Epoch: 50, train_Loss: 1.3460
training Epoch: 50, train_Loss: 0.3440
training Epoch: 50, train_Loss: 0.5326
training Epoch: 50, train_Loss: 0.3603
training Epoch: 50, train_Loss: 0.8195
training Epoch: 50, train_Loss: 0.3754
training Epoch: 50, train_Loss: 0.4729
training Epoch: 50, train_Loss: 0.2573
training Epoch: 50, train_Loss: 1.7955
training Epoch: 50, train_Loss: 1.6842
training Epoch: 50, train_Loss: 1.2370
training Epoch: 50, train_Loss: 1.1532
training Epoch: 50, train_Loss: 2.0731
training Epoch: 50, train_Loss: 0.4938
training Epoch: 50, train_Loss: 2.1611
training Epoch: 50, train_Loss: 4.1554
training Epoch: 50, train_Loss: 0.9703
training Epoch: 50, train_Loss: 0.5942
training Epoch: 50, train_Loss: 0.5314
training Epoch: 50, train_Loss: 2.1205
training Epoch: 50, train_Loss: 0.5002
training Epoch: 50, train_Loss: 0.7921
training Epoch: 50, train_Loss: 0.9976
training Epoch: 50, train_Loss: 0.7584
training Epoch: 50, train_Loss: 0.9122
training Epoch: 50, train_Loss: 0.8402
training Epoch: 50, train_Loss: 1.0884
training Epoch: 50, train_Loss: 0.6879
training Epoch: 50, train_Loss: 1.3988
training Epoch: 50, train_Loss: 1.6680
training Epoch: 50, train_Loss: 0.9168
training Epoch: 50, train_Loss: 0.5536
training Epoch: 50, train_Loss: 0.4960
training Epoch: 50, train_Loss: 1.3624
training Epoch: 50, train_Loss: 1.1311
training Epoch: 50, train_Loss: 1.2822
training Epoch: 50, train_Loss: 2.2462
training Epoch: 50, train_Loss: 0.8494
training Epoch: 50, train_Loss: 0.3428
training Epoch: 50, train_Loss: 0.3914
training Epoch: 50, train_Loss: 1.1267
training Epoch: 50, train_Loss: 0.6124
training Epoch: 50, train_Loss: 0.5658
training Epoch: 50, train_Loss: 0.5510
training Epoch: 50, train_Loss: 0.3158
training Epoch: 50, train_Loss: 0.2529
training Epoch: 50, train_Loss: 2.2030
training Epoch: 50, train_Loss: 0.6711
training Epoch: 50, train_Loss: 0.7080
training Epoch: 50, train_Loss: 1.4720
training Epoch: 50, train_Loss: 2.9689
training Epoch: 50, train_Loss: 1.3806
training Epoch: 50, train_Loss: 0.8280
training Epoch: 50, train_Loss: 2.0614
training Epoch: 50, train_Loss: 1.0031
training Epoch: 50, train_Loss: 0.5524
training Epoch: 50, train_Loss: 1.2632
training Epoch: 50, train_Loss: 0.8342
training Epoch: 50, train_Loss: 0.4890
training Epoch: 50, train_Loss: 0.5263
training Epoch: 50, train_Loss: 0.6954
training Epoch: 50, train_Loss: 0.5957
training Epoch: 50, train_Loss: 1.7410
training Epoch: 50, train_Loss: 0.6852
training Epoch: 50, train_Loss: 0.4473
training Epoch: 50, train_Loss: 0.7968
training Epoch: 50, train_Loss: 0.5856
training Epoch: 50, train_Loss: 1.1753
training Epoch: 50, train_Loss: 0.8000
training Epoch: 50, train_Loss: 1.8887
training Epoch: 50, train_Loss: 0.5232
training Epoch: 50, train_Loss: 0.8781
training Epoch: 50, train_Loss: 0.9624
training Epoch: 50, train_Loss: 0.7512
training Epoch: 50, train_Loss: 3.1498
training Epoch: 50, train_Loss: 2.1987
training Epoch: 50, train_Loss: 1.3030
training Epoch: 50, train_Loss: 0.8323
training Epoch: 50, train_Loss: 1.5065
training Epoch: 50, train_Loss: 1.6146
training Epoch: 50, train_Loss: 1.4088
training Epoch: 50, train_Loss: 1.1839
training Epoch: 50, train_Loss: 0.7224
training Epoch: 50, train_Loss: 0.7408
training Epoch: 50, train_Loss: 3.1585
training Epoch: 50, train_Loss: 1.7962
training Epoch: 50, train_Loss: 0.6825
training Epoch: 50, train_Loss: 0.8127
training Epoch: 50, train_Loss: 1.4324
training Epoch: 50, train_Loss: 1.4737
training Epoch: 50, train_Loss: 2.5286
training Epoch: 50, train_Loss: 1.6223
training Epoch: 50, train_Loss: 1.1421
training Epoch: 50, train_Loss: 2.0228
training Epoch: 50, train_Loss: 0.8855
training Epoch: 50, train_Loss: 1.0777
training Epoch: 50, train_Loss: 1.0154
training Epoch: 50, train_Loss: 0.6489
training Epoch: 50, train_Loss: 0.4806
training Epoch: 50, train_Loss: 1.0036
training Epoch: 50, train_Loss: 0.8836
training Epoch: 50, train_Loss: 1.0040
training Epoch: 50, train_Loss: 0.8046
training Epoch: 50, train_Loss: 1.3585
training Epoch: 50, train_Loss: 0.6194
training Epoch: 50, train_Loss: 1.0702
training Epoch: 50, train_Loss: 1.1588
training Epoch: 50, train_Loss: 0.5986
training Epoch: 50, train_Loss: 0.6583
training Epoch: 50, train_Loss: 0.6662
training Epoch: 50, train_Loss: 1.3003
training Epoch: 50, train_Loss: 0.8839
training Epoch: 50, train_Loss: 0.7628
training Epoch: 50, train_Loss: 1.9687
training Epoch: 50, train_Loss: 2.1339
training Epoch: 50, train_Loss: 0.6535
training Epoch: 50, train_Loss: 1.3763
training Epoch: 50, train_Loss: 0.4809
training Epoch: 50, train_Loss: 0.3574
training Epoch: 50, train_Loss: 1.4214
training Epoch: 50, train_Loss: 0.6285
training Epoch: 50, train_Loss: 0.5751
training Epoch: 50, train_Loss: 1.0021
training Epoch: 50, train_Loss: 0.5182
training Epoch: 50, train_Loss: 1.6171
training Epoch: 50, train_Loss: 0.8074
training Epoch: 50, train_Loss: 0.8997
training Epoch: 50, train_Loss: 1.2452
training Epoch: 50, train_Loss: 0.6886
training Epoch: 50, train_Loss: 1.2516
training Epoch: 50, train_Loss: 1.0579
training Epoch: 50, train_Loss: 0.4029
training Epoch: 50, train_Loss: 0.7835
training Epoch: 50, train_Loss: 0.3888
training Epoch: 50, train_Loss: 0.6407
training Epoch: 50, train_Loss: 0.8246
training Epoch: 50, train_Loss: 1.9817
training Epoch: 50, train_Loss: 0.3049
training Epoch: 50, train_Loss: 0.2523
training Epoch: 50, train_Loss: 0.8223
training Epoch: 50, train_Loss: 0.9309
training Epoch: 50, train_Loss: 0.7085
training Epoch: 50, train_Loss: 0.6766
training Epoch: 50, train_Loss: 0.8304
training Epoch: 50, train_Loss: 0.3994
training Epoch: 50, train_Loss: 0.1598
training Epoch: 50, train_Loss: 1.5076
training Epoch: 50, train_Loss: 1.3164
training Epoch: 50, train_Loss: 0.1253
training Epoch: 50, train_Loss: 0.5343
training Epoch: 50, train_Loss: 0.5040
training Epoch: 50, train_Loss: 0.2688
training Epoch: 50, train_Loss: 0.9954
training Epoch: 50, train_Loss: 0.2118
training Epoch: 50, train_Loss: 0.9845
training Epoch: 50, train_Loss: 0.7378
training Epoch: 50, train_Loss: 0.4428
training Epoch: 50, train_Loss: 3.7850
training Epoch: 50, train_Loss: 1.0113
training Epoch: 50, train_Loss: 0.4865
training Epoch: 50, train_Loss: 1.2307
training Epoch: 50, train_Loss: 0.5059
training Epoch: 50, train_Loss: 1.8492
training Epoch: 50, train_Loss: 2.0189
training Epoch: 50, train_Loss: 1.3570
training Epoch: 50, train_Loss: 1.3226
training Epoch: 50, train_Loss: 0.9456
training Epoch: 50, train_Loss: 0.7781
training Epoch: 50, train_Loss: 0.5989
training Epoch: 50, train_Loss: 1.2326
training Epoch: 50, train_Loss: 0.5258
training Epoch: 50, train_Loss: 1.1673
training Epoch: 50, train_Loss: 0.9672
training Epoch: 50, train_Loss: 0.8906
training Epoch: 50, train_Loss: 1.4657
training Epoch: 50, train_Loss: 1.7433
training Epoch: 50, train_Loss: 1.4549
training Epoch: 50, train_Loss: 1.1015
training Epoch: 50, train_Loss: 1.2849
training Epoch: 50, train_Loss: 2.9344
training Epoch: 50, train_Loss: 0.6239
training Epoch: 50, train_Loss: 0.7846
training Epoch: 50, train_Loss: 1.1413
training Epoch: 50, train_Loss: 2.6060
training Epoch: 50, train_Loss: 0.3581
training Epoch: 50, train_Loss: 0.7326
training Epoch: 50, train_Loss: 1.9487
training Epoch: 50, train_Loss: 0.5675
training Epoch: 50, train_Loss: 1.9734
training Epoch: 50, train_Loss: 1.0396
training Epoch: 50, train_Loss: 1.6959
training Epoch: 50, train_Loss: 1.1292
training Epoch: 50, train_Loss: 0.9884
training Epoch: 50, train_Loss: 0.3701
training Epoch: 50, train_Loss: 0.3611
training Epoch: 50, train_Loss: 0.5058
training Epoch: 50, train_Loss: 0.8933
training Epoch: 50, train_Loss: 0.3490
training Epoch: 50, train_Loss: 1.0803
training Epoch: 50, train_Loss: 0.5774
training Epoch: 50, train_Loss: 1.9739
training Epoch: 50, train_Loss: 0.9249
training Epoch: 50, train_Loss: 2.6452
training Epoch: 50, train_Loss: 0.8804
training Epoch: 50, train_Loss: 0.8526
training Epoch: 50, train_Loss: 0.3837
training Epoch: 50, train_Loss: 0.9830
training Epoch: 50, train_Loss: 0.7730
training Epoch: 50, train_Loss: 0.8515
training Epoch: 50, train_Loss: 0.8398
training Epoch: 50, train_Loss: 0.4296
training Epoch: 50, train_Loss: 0.8604
training Epoch: 50, train_Loss: 0.9052
training Epoch: 50, train_Loss: 0.4255
training Epoch: 50, train_Loss: 1.4437
training Epoch: 50, train_Loss: 1.4617
training Epoch: 50, train_Loss: 1.3702
training Epoch: 50, train_Loss: 0.7336
training Epoch: 50, train_Loss: 1.7413
training Epoch: 50, train_Loss: 0.2702
training Epoch: 50, train_Loss: 0.4267
training Epoch: 50, train_Loss: 2.2190
training Epoch: 50, train_Loss: 1.8621
training Epoch: 50, train_Loss: 0.4201
training Epoch: 50, train_Loss: 1.3434
training Epoch: 50, train_Loss: 0.8187
training Epoch: 50, train_Loss: 1.0902
training Epoch: 50, train_Loss: 0.4381
training Epoch: 50, train_Loss: 1.0824
training Epoch: 50, train_Loss: 1.2063
training Epoch: 50, train_Loss: 2.6138
training Epoch: 50, train_Loss: 0.5087
training Epoch: 50, train_Loss: 0.5857
training Epoch: 50, train_Loss: 1.0139
training Epoch: 50, train_Loss: 0.6217
training Epoch: 50, train_Loss: 0.2898
training Epoch: 50, train_Loss: 1.3294
training Epoch: 50, train_Loss: 1.3327
training Epoch: 50, train_Loss: 0.5741
training Epoch: 50, train_Loss: 0.3781
training Epoch: 50, train_Loss: 1.8717
training Epoch: 50, train_Loss: 0.3390
training Epoch: 50, train_Loss: 1.6505
training Epoch: 50, train_Loss: 1.1084
training Epoch: 50, train_Loss: 0.9456
training Epoch: 50, train_Loss: 2.2706
training Epoch: 50, train_Loss: 1.3806
training Epoch: 50, train_Loss: 1.1601
training Epoch: 50, train_Loss: 0.9440
training Epoch: 50, train_Loss: 0.9396
training Epoch: 50, train_Loss: 1.7575
training Epoch: 50, train_Loss: 0.9666
training Epoch: 50, train_Loss: 0.9262
training Epoch: 50, train_Loss: 0.8041
training Epoch: 50, train_Loss: 0.8720
training Epoch: 50, train_Loss: 0.8162
training Epoch: 50, train_Loss: 2.5051
training Epoch: 50, train_Loss: 1.0144
training Epoch: 50, train_Loss: 0.4743
training Epoch: 50, train_Loss: 1.2485
training Epoch: 50, train_Loss: 1.3591
training Epoch: 50, train_Loss: 0.6930
training Epoch: 50, train_Loss: 1.1127
training Epoch: 50, train_Loss: 2.4246
training Epoch: 50, train_Loss: 0.5953
training Epoch: 50, train_Loss: 1.5918
training Epoch: 50, train_Loss: 0.7656
training Epoch: 50, train_Loss: 0.3938
training Epoch: 50, train_Loss: 0.7473
training Epoch: 50, train_Loss: 0.3240
training Epoch: 50, train_Loss: 0.5367
training Epoch: 50, train_Loss: 0.8721
training Epoch: 50, train_Loss: 1.1245
training Epoch: 50, train_Loss: 0.5214
training Epoch: 50, train_Loss: 0.5409
training Epoch: 50, train_Loss: 0.1659
training Epoch: 50, train_Loss: 0.4301
training Epoch: 50, train_Loss: 3.3641
training Epoch: 50, train_Loss: 0.6091
training Epoch: 50, train_Loss: 1.4175
training Epoch: 50, train_Loss: 0.1464
training Epoch: 50, train_Loss: 1.8233
training Epoch: 50, train_Loss: 1.2670
training Epoch: 50, train_Loss: 2.5052
training Epoch: 50, train_Loss: 1.5516
training Epoch: 50, train_Loss: 0.2734
training Epoch: 50, train_Loss: 2.6086
training Epoch: 50, train_Loss: 0.5799
training Epoch: 50, train_Loss: 1.9226
training Epoch: 50, train_Loss: 0.8314
training Epoch: 50, train_Loss: 2.2741
training Epoch: 50, train_Loss: 0.5791
training Epoch: 50, train_Loss: 0.7885
training Epoch: 50, train_Loss: 1.8399
training Epoch: 50, train_Loss: 1.0592
training Epoch: 50, train_Loss: 0.7234
training Epoch: 50, train_Loss: 1.4585
training Epoch: 50, train_Loss: 1.0362
training Epoch: 50, train_Loss: 1.9853
training Epoch: 50, train_Loss: 0.8560
training Epoch: 50, train_Loss: 0.6283
training Epoch: 50, train_Loss: 1.7936
training Epoch: 50, train_Loss: 0.6071
training Epoch: 50, train_Loss: 1.4150
training Epoch: 50, train_Loss: 1.1964
training Epoch: 50, train_Loss: 1.4137
training Epoch: 50, train_Loss: 1.2544
training Epoch: 50, train_Loss: 0.6204
training Epoch: 50, train_Loss: 1.3789
training Epoch: 50, train_Loss: 0.9036
training Epoch: 50, train_Loss: 1.5867
training Epoch: 50, train_Loss: 0.4281
training Epoch: 50, train_Loss: 1.4694
training Epoch: 50, train_Loss: 1.6067
training Epoch: 50, train_Loss: 0.7930
training Epoch: 50, train_Loss: 1.2388
training Epoch: 50, train_Loss: 1.0289
training Epoch: 50, train_Loss: 1.3881
training Epoch: 50, train_Loss: 1.2772
training Epoch: 50, train_Loss: 0.7819
training Epoch: 50, train_Loss: 0.8279
training Epoch: 50, train_Loss: 2.1352
training Epoch: 50, train_Loss: 0.4257
training Epoch: 50, train_Loss: 0.4508
training Epoch: 50, train_Loss: 0.5536
training Epoch: 50, train_Loss: 2.3029
training Epoch: 50, train_Loss: 1.5304
training Epoch: 50, train_Loss: 0.3833
training Epoch: 50, train_Loss: 0.5996
training Epoch: 50, train_Loss: 0.9624
training Epoch: 50, train_Loss: 0.9349
training Epoch: 50, train_Loss: 1.1698
training Epoch: 50, train_Loss: 0.8840
training Epoch: 50, train_Loss: 0.4644
training Epoch: 50, train_Loss: 1.1005
training Epoch: 50, train_Loss: 0.3374
training Epoch: 50, train_Loss: 0.3047
training Epoch: 50, train_Loss: 1.2620
training Epoch: 50, train_Loss: 0.4494
training Epoch: 50, train_Loss: 2.3227
training Epoch: 50, train_Loss: 0.8793
training Epoch: 50, train_Loss: 0.5807
training Epoch: 50, train_Loss: 2.8974
training Epoch: 50, train_Loss: 1.0260
training Epoch: 50, train_Loss: 0.2684
training Epoch: 50, train_Loss: 0.4023
training Epoch: 50, train_Loss: 0.7810
training Epoch: 50, train_Loss: 1.2437
training Epoch: 50, train_Loss: 0.8717
training Epoch: 50, train_Loss: 1.2900
training Epoch: 50, train_Loss: 0.8820
training Epoch: 50, train_Loss: 0.9475
training Epoch: 50, train_Loss: 1.4110
training Epoch: 50, train_Loss: 2.0770
training Epoch: 50, train_Loss: 1.2220
training Epoch: 50, train_Loss: 0.6186
training Epoch: 50, train_Loss: 0.7904
training Epoch: 50, train_Loss: 0.5086
training Epoch: 50, train_Loss: 1.9348
training Epoch: 50, train_Loss: 1.3309
training Epoch: 50, train_Loss: 0.5941
training Epoch: 50, train_Loss: 1.4178
training Epoch: 50, train_Loss: 1.9862
training Epoch: 50, train_Loss: 0.5919
training Epoch: 50, train_Loss: 1.1556
training Epoch: 50, train_Loss: 1.7232
training Epoch: 50, train_Loss: 0.9919
training Epoch: 50, train_Loss: 1.7468
training Epoch: 50, train_Loss: 1.0687
training Epoch: 50, train_Loss: 0.7100
training Epoch: 50, train_Loss: 1.3746
training Epoch: 50, train_Loss: 0.5865
training Epoch: 50, train_Loss: 2.2879
training Epoch: 50, train_Loss: 1.4017
training Epoch: 50, train_Loss: 1.3851
training Epoch: 50, train_Loss: 0.5323
training Epoch: 50, train_Loss: 0.5392
training Epoch: 50, train_Loss: 0.3969
training Epoch: 50, train_Loss: 1.1735
training Epoch: 50, train_Loss: 2.5610
training Epoch: 50, train_Loss: 1.2179
training Epoch: 50, train_Loss: 1.8198
training Epoch: 50, train_Loss: 1.9134
training Epoch: 50, train_Loss: 1.3503
training Epoch: 50, train_Loss: 0.7826
training Epoch: 50, train_Loss: 0.5020
training Epoch: 50, train_Loss: 1.0308
training Epoch: 50, train_Loss: 1.5416
training Epoch: 50, train_Loss: 0.5981
training Epoch: 50, train_Loss: 0.7241
training Epoch: 50, train_Loss: 1.2277
training Epoch: 50, train_Loss: 1.0496
training Epoch: 50, train_Loss: 0.6452
training Epoch: 50, train_Loss: 0.6960
training Epoch: 50, train_Loss: 1.1377
training Epoch: 50, train_Loss: 1.1892
training Epoch: 50, train_Loss: 2.6766
training Epoch: 50, train_Loss: 2.2693
training Epoch: 50, train_Loss: 0.6181
training Epoch: 50, train_Loss: 0.8676
training Epoch: 50, train_Loss: 0.7129
training Epoch: 50, train_Loss: 1.1759
training Epoch: 50, train_Loss: 0.8531
training Epoch: 50, train_Loss: 0.7398
training Epoch: 50, train_Loss: 0.9296
training Epoch: 50, train_Loss: 0.5644
training Epoch: 50, train_Loss: 0.5795
training Epoch: 50, train_Loss: 0.8953
training Epoch: 50, train_Loss: 0.7806
training Epoch: 50, train_Loss: 0.3769
training Epoch: 50, train_Loss: 1.0171
training Epoch: 50, train_Loss: 0.3043
training Epoch: 50, train_Loss: 0.2524
training Epoch: 50, train_Loss: 0.8230
training Epoch: 50, train_Loss: 0.4197
training Epoch: 50, train_Loss: 0.1704
training Epoch: 50, train_Loss: 0.2371
training Epoch: 50, train_Loss: 1.7757
training Epoch: 50, train_Loss: 1.0678
training Epoch: 50, train_Loss: 0.1726
training Epoch: 50, train_Loss: 0.8566
training Epoch: 50, train_Loss: 3.9741
training Epoch: 50, train_Loss: 1.1749
training Epoch: 50, train_Loss: 1.1860
training Epoch: 50, train_Loss: 0.8566
training Epoch: 50, train_Loss: 0.6022
training Epoch: 50, train_Loss: 0.7791
training Epoch: 50, train_Loss: 0.2939
training Epoch: 50, train_Loss: 0.6182
training Epoch: 50, train_Loss: 1.3183
training Epoch: 50, train_Loss: 0.9710
training Epoch: 50, train_Loss: 1.7396
training Epoch: 50, train_Loss: 1.6376
training Epoch: 50, train_Loss: 0.7808
training Epoch: 50, train_Loss: 0.4874
training Epoch: 50, train_Loss: 2.3139
training Epoch: 50, train_Loss: 1.2163
training Epoch: 50, train_Loss: 1.9079
training Epoch: 50, train_Loss: 2.3233
training Epoch: 50, train_Loss: 0.7021
training Epoch: 50, train_Loss: 0.5200
training Epoch: 50, train_Loss: 0.5323
training Epoch: 50, train_Loss: 0.5152
training Epoch: 50, train_Loss: 0.5671
training Epoch: 50, train_Loss: 1.1271
training Epoch: 50, train_Loss: 0.9845
training Epoch: 50, train_Loss: 0.4455
training Epoch: 50, train_Loss: 2.5318
training Epoch: 50, train_Loss: 1.3646
training Epoch: 50, train_Loss: 0.9098
training Epoch: 50, train_Loss: 2.0792
training Epoch: 50, train_Loss: 0.7447
training Epoch: 50, train_Loss: 3.4144
training Epoch: 50, train_Loss: 1.5999
training Epoch: 50, train_Loss: 1.8958
training Epoch: 50, train_Loss: 0.7383
training Epoch: 50, train_Loss: 1.0718
training Epoch: 50, train_Loss: 0.6920
training Epoch: 50, train_Loss: 1.2880
training Epoch: 50, train_Loss: 1.8783
training Epoch: 50, train_Loss: 0.9406
training Epoch: 50, train_Loss: 0.6947
training Epoch: 50, train_Loss: 1.0120
training Epoch: 50, train_Loss: 1.6828
training Epoch: 50, train_Loss: 0.3998
training Epoch: 50, train_Loss: 2.8631
training Epoch: 50, train_Loss: 0.2889
training Epoch: 50, train_Loss: 0.7847
training Epoch: 50, train_Loss: 1.2207
training Epoch: 50, train_Loss: 1.4688
training Epoch: 50, train_Loss: 0.3413
training Epoch: 50, train_Loss: 0.5500
training Epoch: 50, train_Loss: 0.3619
training Epoch: 50, train_Loss: 0.8913
training Epoch: 50, train_Loss: 1.0278
training Epoch: 50, train_Loss: 3.6346
training Epoch: 50, train_Loss: 0.6861
training Epoch: 50, train_Loss: 2.5662
training Epoch: 50, train_Loss: 0.9433
training Epoch: 50, train_Loss: 0.8078
training Epoch: 50, train_Loss: 0.5341
training Epoch: 50, train_Loss: 0.7446
training Epoch: 50, train_Loss: 0.7594
training Epoch: 50, train_Loss: 2.0573
training Epoch: 50, train_Loss: 0.7384
training Epoch: 50, train_Loss: 0.4996
training Epoch: 50, train_Loss: 2.4023
training Epoch: 50, train_Loss: 0.4504
training Epoch: 50, train_Loss: 0.7463
training Epoch: 50, train_Loss: 0.4854
training Epoch: 50, train_Loss: 0.7408
training Epoch: 50, train_Loss: 1.0713
training Epoch: 50, train_Loss: 0.4847
training Epoch: 50, train_Loss: 0.6875
training Epoch: 50, train_Loss: 2.2010
training Epoch: 50, train_Loss: 0.3692
training Epoch: 50, train_Loss: 1.5670
training Epoch: 50, train_Loss: 1.1644
training Epoch: 50, train_Loss: 1.9044
training Epoch: 50, train_Loss: 0.3599
training Epoch: 50, train_Loss: 1.5122
training Epoch: 50, train_Loss: 2.0468
training Epoch: 50, train_Loss: 1.3552
training Epoch: 50, train_Loss: 0.3884
training Epoch: 50, train_Loss: 1.4149
training Epoch: 50, train_Loss: 0.4260
training Epoch: 50, train_Loss: 1.8463
training Epoch: 50, train_Loss: 0.5815
training Epoch: 50, train_Loss: 2.3518
training Epoch: 50, train_Loss: 0.5319
training Epoch: 50, train_Loss: 1.3924
training Epoch: 50, train_Loss: 2.0262
training Epoch: 50, train_Loss: 1.2657
training Epoch: 50, train_Loss: 0.8311
training Epoch: 50, train_Loss: 0.7517
training Epoch: 50, train_Loss: 0.6782
training Epoch: 50, train_Loss: 0.7365
training Epoch: 50, train_Loss: 2.0238
training Epoch: 50, train_Loss: 0.7625
training Epoch: 50, train_Loss: 2.6222
training Epoch: 50, train_Loss: 1.4371
training Epoch: 50, train_Loss: 1.0445
training Epoch: 50, train_Loss: 0.7332
training Epoch: 50, train_Loss: 1.3112
training Epoch: 50, train_Loss: 1.4872
training Epoch: 50, train_Loss: 1.2466
training Epoch: 50, train_Loss: 0.7244
training Epoch: 50, train_Loss: 0.3886
training Epoch: 50, train_Loss: 2.3288
training Epoch: 50, train_Loss: 0.2949
training Epoch: 50, train_Loss: 0.5746
training Epoch: 50, train_Loss: 0.4406
training Epoch: 50, train_Loss: 0.5878
training Epoch: 50, train_Loss: 0.8943
training Epoch: 50, train_Loss: 0.4595
training Epoch: 50, train_Loss: 0.2485
training Epoch: 50, train_Loss: 1.3679
training Epoch: 50, train_Loss: 0.6857
training Epoch: 50, train_Loss: 1.6918
training Epoch: 50, train_Loss: 0.5377
training Epoch: 50, train_Loss: 2.1692
training Epoch: 50, train_Loss: 0.2731
training Epoch: 50, train_Loss: 1.0521
training Epoch: 50, train_Loss: 1.2361
training Epoch: 50, train_Loss: 1.3965
training Epoch: 50, train_Loss: 0.6693
training Epoch: 50, train_Loss: 0.7445
training Epoch: 50, train_Loss: 1.1277
training Epoch: 50, train_Loss: 0.9195
training Epoch: 50, train_Loss: 2.7703
training Epoch: 50, train_Loss: 1.1202
training Epoch: 50, train_Loss: 1.1464
training Epoch: 50, train_Loss: 1.2451
training Epoch: 50, train_Loss: 0.7815
training Epoch: 50, train_Loss: 1.4150
training Epoch: 50, train_Loss: 1.7278
training Epoch: 50, train_Loss: 0.6548
training Epoch: 50, train_Loss: 0.8592
training Epoch: 50, train_Loss: 0.9178
training Epoch: 50, train_Loss: 0.8573
training Epoch: 50, train_Loss: 2.2001
fold,epoch,train_loss: 2 49 1.0866438
fold,epoch,train_loss: 2 50 1.0851407
fold,epoch,train_loss: 2 51 1.0904509
fold,epoch,train_loss: 2 52 1.085346
fold,epoch,train_loss: 2 53 1.0883008
fold,epoch,train_loss: 2 54 1.0964569
fold,epoch,train_loss: 2 55 1.0908251
fold,epoch,train_loss: 2 56 1.0841898
fold,epoch,train_loss: 2 57 1.0853813
fold,epoch,train_loss: 2 58 1.0875238
fold,epoch,train_loss: 2 59 1.0888895
fold,epoch,train_loss: 2 60 1.0987144
fold,epoch,train_loss: 2 61 1.0933182
fold,epoch,train_loss: 2 62 1.0859326
fold,epoch,train_loss: 2 63 1.0913832
fold,epoch,train_loss: 2 64 1.0907602
fold,epoch,train_loss: 2 65 1.0917438
fold,epoch,train_loss: 2 66 1.0880594
fold,epoch,train_loss: 2 67 1.0897222
fold,epoch,train_loss: 2 68 1.0943218
fold,epoch,train_loss: 2 69 1.0911525
fold,epoch,train_loss: 2 70 1.0882188
fold,epoch,train_loss: 2 71 1.0864551
fold,epoch,train_loss: 2 72 1.0885007
fold,epoch,train_loss: 2 73 1.0888152
fold,epoch,train_loss: 2 74 1.0898463
fold,epoch,train_loss: 2 75 1.0859318
fold,epoch,train_loss: 2 76 1.0921935
fold,epoch,train_loss: 2 77 1.0976744
fold,epoch,train_loss: 2 78 1.0868912
fold,epoch,train_loss: 2 79 1.0875143
fold,epoch,train_loss: 2 80 1.0926169
fold,epoch,train_loss: 2 81 1.0910878
fold,epoch,train_loss: 2 82 1.0890988
fold,epoch,train_loss: 2 83 1.0898125
fold,epoch,train_loss: 2 84 1.0838511
fold,epoch,train_loss: 2 85 1.091215
fold,epoch,train_loss: 2 86 1.0982286
fold,epoch,train_loss: 2 87 1.090448
fold,epoch,train_loss: 2 88 1.0889235
fold,epoch,train_loss: 2 89 1.0910751
fold,epoch,train_loss: 2 90 1.0888338
fold,epoch,train_loss: 2 91 1.0881575
fold,epoch,train_loss: 2 92 1.0879904
fold,epoch,train_loss: 2 93 1.0859717
fold,epoch,train_loss: 2 94 1.0919162
fold,epoch,train_loss: 2 95 1.088423
fold,epoch,train_loss: 2 96 1.0889333
fold,epoch,train_loss: 2 97 1.0905842
fold,epoch,train_loss: 2 98 1.0943584
training Epoch: 100, train_Loss: 0.1780
training Epoch: 100, train_Loss: 0.6102
training Epoch: 100, train_Loss: 1.9314
training Epoch: 100, train_Loss: 1.8905
training Epoch: 100, train_Loss: 0.2675
training Epoch: 100, train_Loss: 0.5649
training Epoch: 100, train_Loss: 1.4664
training Epoch: 100, train_Loss: 0.4659
training Epoch: 100, train_Loss: 1.7344
training Epoch: 100, train_Loss: 1.1866
training Epoch: 100, train_Loss: 1.1981
training Epoch: 100, train_Loss: 0.6856
training Epoch: 100, train_Loss: 0.6937
training Epoch: 100, train_Loss: 0.8569
training Epoch: 100, train_Loss: 0.5484
training Epoch: 100, train_Loss: 1.4264
training Epoch: 100, train_Loss: 0.6167
training Epoch: 100, train_Loss: 0.6630
training Epoch: 100, train_Loss: 1.0881
training Epoch: 100, train_Loss: 0.8315
training Epoch: 100, train_Loss: 1.0707
training Epoch: 100, train_Loss: 0.3020
training Epoch: 100, train_Loss: 2.4509
training Epoch: 100, train_Loss: 0.5603
training Epoch: 100, train_Loss: 1.8487
training Epoch: 100, train_Loss: 1.4627
training Epoch: 100, train_Loss: 1.8735
training Epoch: 100, train_Loss: 0.6626
training Epoch: 100, train_Loss: 0.7646
training Epoch: 100, train_Loss: 0.3117
training Epoch: 100, train_Loss: 1.8482
training Epoch: 100, train_Loss: 0.8914
training Epoch: 100, train_Loss: 2.7899
training Epoch: 100, train_Loss: 1.5874
training Epoch: 100, train_Loss: 1.1007
training Epoch: 100, train_Loss: 0.5016
training Epoch: 100, train_Loss: 0.4726
training Epoch: 100, train_Loss: 0.5384
training Epoch: 100, train_Loss: 0.9536
training Epoch: 100, train_Loss: 0.5821
training Epoch: 100, train_Loss: 1.1385
training Epoch: 100, train_Loss: 1.0375
training Epoch: 100, train_Loss: 0.5778
training Epoch: 100, train_Loss: 1.3126
training Epoch: 100, train_Loss: 3.0799
training Epoch: 100, train_Loss: 0.8855
training Epoch: 100, train_Loss: 0.7950
training Epoch: 100, train_Loss: 0.8961
training Epoch: 100, train_Loss: 0.7124
training Epoch: 100, train_Loss: 0.4420
training Epoch: 100, train_Loss: 0.6649
training Epoch: 100, train_Loss: 3.5401
training Epoch: 100, train_Loss: 0.3413
training Epoch: 100, train_Loss: 0.5647
training Epoch: 100, train_Loss: 1.0559
training Epoch: 100, train_Loss: 1.0309
training Epoch: 100, train_Loss: 0.5872
training Epoch: 100, train_Loss: 1.1935
training Epoch: 100, train_Loss: 0.6857
training Epoch: 100, train_Loss: 1.9347
training Epoch: 100, train_Loss: 0.7398
training Epoch: 100, train_Loss: 2.9293
training Epoch: 100, train_Loss: 1.0684
training Epoch: 100, train_Loss: 1.3201
training Epoch: 100, train_Loss: 0.9721
training Epoch: 100, train_Loss: 2.3668
training Epoch: 100, train_Loss: 0.3842
training Epoch: 100, train_Loss: 2.0353
training Epoch: 100, train_Loss: 1.5877
training Epoch: 100, train_Loss: 0.7534
training Epoch: 100, train_Loss: 1.6360
training Epoch: 100, train_Loss: 1.2193
training Epoch: 100, train_Loss: 2.8891
training Epoch: 100, train_Loss: 0.7542
training Epoch: 100, train_Loss: 1.2154
training Epoch: 100, train_Loss: 0.8178
training Epoch: 100, train_Loss: 2.2898
training Epoch: 100, train_Loss: 0.8404
training Epoch: 100, train_Loss: 0.6134
training Epoch: 100, train_Loss: 1.6026
training Epoch: 100, train_Loss: 1.7035
training Epoch: 100, train_Loss: 0.8644
training Epoch: 100, train_Loss: 1.0775
training Epoch: 100, train_Loss: 2.2536
training Epoch: 100, train_Loss: 0.5066
training Epoch: 100, train_Loss: 1.1374
training Epoch: 100, train_Loss: 1.9350
training Epoch: 100, train_Loss: 2.8769
training Epoch: 100, train_Loss: 0.8756
training Epoch: 100, train_Loss: 0.5563
training Epoch: 100, train_Loss: 1.3830
training Epoch: 100, train_Loss: 1.9453
training Epoch: 100, train_Loss: 1.2790
training Epoch: 100, train_Loss: 0.4181
training Epoch: 100, train_Loss: 0.9393
training Epoch: 100, train_Loss: 0.8974
training Epoch: 100, train_Loss: 0.8271
training Epoch: 100, train_Loss: 0.3364
training Epoch: 100, train_Loss: 0.5692
training Epoch: 100, train_Loss: 1.3245
training Epoch: 100, train_Loss: 0.3702
training Epoch: 100, train_Loss: 0.3540
training Epoch: 100, train_Loss: 2.3200
training Epoch: 100, train_Loss: 1.2021
training Epoch: 100, train_Loss: 1.1221
training Epoch: 100, train_Loss: 1.0382
training Epoch: 100, train_Loss: 1.4579
training Epoch: 100, train_Loss: 0.9047
training Epoch: 100, train_Loss: 1.8810
training Epoch: 100, train_Loss: 0.4889
training Epoch: 100, train_Loss: 1.6435
training Epoch: 100, train_Loss: 0.9581
training Epoch: 100, train_Loss: 1.9937
training Epoch: 100, train_Loss: 1.0498
training Epoch: 100, train_Loss: 0.7679
training Epoch: 100, train_Loss: 0.4474
training Epoch: 100, train_Loss: 0.5594
training Epoch: 100, train_Loss: 0.5084
training Epoch: 100, train_Loss: 0.6439
training Epoch: 100, train_Loss: 1.8664
training Epoch: 100, train_Loss: 1.3280
training Epoch: 100, train_Loss: 0.9999
training Epoch: 100, train_Loss: 0.6480
training Epoch: 100, train_Loss: 0.8153
training Epoch: 100, train_Loss: 1.0663
training Epoch: 100, train_Loss: 2.0999
training Epoch: 100, train_Loss: 1.5043
training Epoch: 100, train_Loss: 2.7739
training Epoch: 100, train_Loss: 1.3641
training Epoch: 100, train_Loss: 0.5802
training Epoch: 100, train_Loss: 0.4735
training Epoch: 100, train_Loss: 0.3916
training Epoch: 100, train_Loss: 0.7814
training Epoch: 100, train_Loss: 0.8787
training Epoch: 100, train_Loss: 0.6904
training Epoch: 100, train_Loss: 1.5971
training Epoch: 100, train_Loss: 1.3158
training Epoch: 100, train_Loss: 0.7327
training Epoch: 100, train_Loss: 1.4806
training Epoch: 100, train_Loss: 0.5865
training Epoch: 100, train_Loss: 1.3577
training Epoch: 100, train_Loss: 0.4315
training Epoch: 100, train_Loss: 1.0964
training Epoch: 100, train_Loss: 0.8519
training Epoch: 100, train_Loss: 0.4795
training Epoch: 100, train_Loss: 1.1299
training Epoch: 100, train_Loss: 0.3546
training Epoch: 100, train_Loss: 1.5386
training Epoch: 100, train_Loss: 1.3481
training Epoch: 100, train_Loss: 0.2227
training Epoch: 100, train_Loss: 0.2221
training Epoch: 100, train_Loss: 0.6005
training Epoch: 100, train_Loss: 0.4132
training Epoch: 100, train_Loss: 1.0562
training Epoch: 100, train_Loss: 0.2502
training Epoch: 100, train_Loss: 2.1663
training Epoch: 100, train_Loss: 1.1941
training Epoch: 100, train_Loss: 0.6907
training Epoch: 100, train_Loss: 2.3934
training Epoch: 100, train_Loss: 0.3270
training Epoch: 100, train_Loss: 1.5468
training Epoch: 100, train_Loss: 0.2270
training Epoch: 100, train_Loss: 1.4502
training Epoch: 100, train_Loss: 2.2549
training Epoch: 100, train_Loss: 0.4553
training Epoch: 100, train_Loss: 0.3135
training Epoch: 100, train_Loss: 0.4051
training Epoch: 100, train_Loss: 0.3907
training Epoch: 100, train_Loss: 1.3979
training Epoch: 100, train_Loss: 2.2992
training Epoch: 100, train_Loss: 0.5803
training Epoch: 100, train_Loss: 1.2372
training Epoch: 100, train_Loss: 0.5169
training Epoch: 100, train_Loss: 1.7429
training Epoch: 100, train_Loss: 0.8637
training Epoch: 100, train_Loss: 0.4516
training Epoch: 100, train_Loss: 1.0932
training Epoch: 100, train_Loss: 0.2783
training Epoch: 100, train_Loss: 1.3238
training Epoch: 100, train_Loss: 2.4541
training Epoch: 100, train_Loss: 1.0431
training Epoch: 100, train_Loss: 1.2161
training Epoch: 100, train_Loss: 0.7669
training Epoch: 100, train_Loss: 0.3603
training Epoch: 100, train_Loss: 0.8879
training Epoch: 100, train_Loss: 0.8108
training Epoch: 100, train_Loss: 0.5581
training Epoch: 100, train_Loss: 1.0976
training Epoch: 100, train_Loss: 2.5975
training Epoch: 100, train_Loss: 0.6847
training Epoch: 100, train_Loss: 2.0409
training Epoch: 100, train_Loss: 1.1058
training Epoch: 100, train_Loss: 0.4958
training Epoch: 100, train_Loss: 0.6755
training Epoch: 100, train_Loss: 1.1375
training Epoch: 100, train_Loss: 0.5922
training Epoch: 100, train_Loss: 1.0606
training Epoch: 100, train_Loss: 0.9500
training Epoch: 100, train_Loss: 0.9035
training Epoch: 100, train_Loss: 1.0172
training Epoch: 100, train_Loss: 1.2795
training Epoch: 100, train_Loss: 0.9268
training Epoch: 100, train_Loss: 0.4355
training Epoch: 100, train_Loss: 0.4256
training Epoch: 100, train_Loss: 0.5717
training Epoch: 100, train_Loss: 0.5061
training Epoch: 100, train_Loss: 1.4689
training Epoch: 100, train_Loss: 0.5010
training Epoch: 100, train_Loss: 1.2033
training Epoch: 100, train_Loss: 3.3465
training Epoch: 100, train_Loss: 0.8086
training Epoch: 100, train_Loss: 0.9570
training Epoch: 100, train_Loss: 1.7896
training Epoch: 100, train_Loss: 1.5269
training Epoch: 100, train_Loss: 1.6013
training Epoch: 100, train_Loss: 0.4140
training Epoch: 100, train_Loss: 1.6518
training Epoch: 100, train_Loss: 1.3011
training Epoch: 100, train_Loss: 0.6630
training Epoch: 100, train_Loss: 0.5835
training Epoch: 100, train_Loss: 0.5703
training Epoch: 100, train_Loss: 0.6502
training Epoch: 100, train_Loss: 1.6837
training Epoch: 100, train_Loss: 0.8958
training Epoch: 100, train_Loss: 0.8060
training Epoch: 100, train_Loss: 2.2889
training Epoch: 100, train_Loss: 0.8731
training Epoch: 100, train_Loss: 0.3901
training Epoch: 100, train_Loss: 0.8376
training Epoch: 100, train_Loss: 0.8612
training Epoch: 100, train_Loss: 1.8269
training Epoch: 100, train_Loss: 1.2391
training Epoch: 100, train_Loss: 0.7824
training Epoch: 100, train_Loss: 2.0206
training Epoch: 100, train_Loss: 3.0044
training Epoch: 100, train_Loss: 1.2334
training Epoch: 100, train_Loss: 1.9278
training Epoch: 100, train_Loss: 0.9290
training Epoch: 100, train_Loss: 0.9891
training Epoch: 100, train_Loss: 0.4353
training Epoch: 100, train_Loss: 0.9160
training Epoch: 100, train_Loss: 2.5474
training Epoch: 100, train_Loss: 1.4261
training Epoch: 100, train_Loss: 1.4063
training Epoch: 100, train_Loss: 0.6133
training Epoch: 100, train_Loss: 0.8431
training Epoch: 100, train_Loss: 2.2432
training Epoch: 100, train_Loss: 1.2632
training Epoch: 100, train_Loss: 2.0449
training Epoch: 100, train_Loss: 1.6879
training Epoch: 100, train_Loss: 1.4148
training Epoch: 100, train_Loss: 0.8163
training Epoch: 100, train_Loss: 1.1467
training Epoch: 100, train_Loss: 1.1273
training Epoch: 100, train_Loss: 1.1056
training Epoch: 100, train_Loss: 1.9546
training Epoch: 100, train_Loss: 1.0742
training Epoch: 100, train_Loss: 1.1564
training Epoch: 100, train_Loss: 1.5723
training Epoch: 100, train_Loss: 1.0038
training Epoch: 100, train_Loss: 1.3038
training Epoch: 100, train_Loss: 1.2034
training Epoch: 100, train_Loss: 0.7412
training Epoch: 100, train_Loss: 1.4861
training Epoch: 100, train_Loss: 0.8681
training Epoch: 100, train_Loss: 1.5208
training Epoch: 100, train_Loss: 1.7716
training Epoch: 100, train_Loss: 0.8517
training Epoch: 100, train_Loss: 1.7486
training Epoch: 100, train_Loss: 0.4792
training Epoch: 100, train_Loss: 0.7195
training Epoch: 100, train_Loss: 0.4965
training Epoch: 100, train_Loss: 0.6703
training Epoch: 100, train_Loss: 0.7529
training Epoch: 100, train_Loss: 1.1220
training Epoch: 100, train_Loss: 0.4729
training Epoch: 100, train_Loss: 1.5942
training Epoch: 100, train_Loss: 0.4820
training Epoch: 100, train_Loss: 0.8290
training Epoch: 100, train_Loss: 0.8914
training Epoch: 100, train_Loss: 1.6085
training Epoch: 100, train_Loss: 1.0362
training Epoch: 100, train_Loss: 0.5295
training Epoch: 100, train_Loss: 0.6566
training Epoch: 100, train_Loss: 1.6114
training Epoch: 100, train_Loss: 0.7250
training Epoch: 100, train_Loss: 1.0490
training Epoch: 100, train_Loss: 0.3918
training Epoch: 100, train_Loss: 0.2332
training Epoch: 100, train_Loss: 0.4483
training Epoch: 100, train_Loss: 0.8442
training Epoch: 100, train_Loss: 1.1003
training Epoch: 100, train_Loss: 0.8310
training Epoch: 100, train_Loss: 0.2357
training Epoch: 100, train_Loss: 0.3311
training Epoch: 100, train_Loss: 0.9471
training Epoch: 100, train_Loss: 2.9778
training Epoch: 100, train_Loss: 0.4311
training Epoch: 100, train_Loss: 0.3286
training Epoch: 100, train_Loss: 2.0965
training Epoch: 100, train_Loss: 1.0439
training Epoch: 100, train_Loss: 0.2876
training Epoch: 100, train_Loss: 0.3471
training Epoch: 100, train_Loss: 1.7965
training Epoch: 100, train_Loss: 1.0592
training Epoch: 100, train_Loss: 2.4602
training Epoch: 100, train_Loss: 0.4444
training Epoch: 100, train_Loss: 0.9036
training Epoch: 100, train_Loss: 0.4177
training Epoch: 100, train_Loss: 1.0107
training Epoch: 100, train_Loss: 0.4646
training Epoch: 100, train_Loss: 0.4299
training Epoch: 100, train_Loss: 0.7320
training Epoch: 100, train_Loss: 0.9671
training Epoch: 100, train_Loss: 0.4986
training Epoch: 100, train_Loss: 0.2938
training Epoch: 100, train_Loss: 0.6995
training Epoch: 100, train_Loss: 0.2777
training Epoch: 100, train_Loss: 0.5202
training Epoch: 100, train_Loss: 0.1597
training Epoch: 100, train_Loss: 1.1383
training Epoch: 100, train_Loss: 0.6913
training Epoch: 100, train_Loss: 1.4930
training Epoch: 100, train_Loss: 0.8584
training Epoch: 100, train_Loss: 1.2411
training Epoch: 100, train_Loss: 1.9027
training Epoch: 100, train_Loss: 1.1607
training Epoch: 100, train_Loss: 1.0451
training Epoch: 100, train_Loss: 1.6105
training Epoch: 100, train_Loss: 1.3851
training Epoch: 100, train_Loss: 1.8891
training Epoch: 100, train_Loss: 1.8876
training Epoch: 100, train_Loss: 1.8590
training Epoch: 100, train_Loss: 1.4067
training Epoch: 100, train_Loss: 3.2966
training Epoch: 100, train_Loss: 1.0821
training Epoch: 100, train_Loss: 0.5589
training Epoch: 100, train_Loss: 1.7546
training Epoch: 100, train_Loss: 0.9213
training Epoch: 100, train_Loss: 1.3646
training Epoch: 100, train_Loss: 0.9203
training Epoch: 100, train_Loss: 0.8356
training Epoch: 100, train_Loss: 2.0492
training Epoch: 100, train_Loss: 0.6780
training Epoch: 100, train_Loss: 0.7162
training Epoch: 100, train_Loss: 0.8155
training Epoch: 100, train_Loss: 2.8644
training Epoch: 100, train_Loss: 0.5343
training Epoch: 100, train_Loss: 0.9955
training Epoch: 100, train_Loss: 1.0632
training Epoch: 100, train_Loss: 0.8011
training Epoch: 100, train_Loss: 0.4865
training Epoch: 100, train_Loss: 0.7462
training Epoch: 100, train_Loss: 0.5118
training Epoch: 100, train_Loss: 0.6084
training Epoch: 100, train_Loss: 0.3233
training Epoch: 100, train_Loss: 0.6788
training Epoch: 100, train_Loss: 2.0615
training Epoch: 100, train_Loss: 1.8422
training Epoch: 100, train_Loss: 1.4049
training Epoch: 100, train_Loss: 0.6010
training Epoch: 100, train_Loss: 2.3181
training Epoch: 100, train_Loss: 0.2550
training Epoch: 100, train_Loss: 0.6902
training Epoch: 100, train_Loss: 1.2530
training Epoch: 100, train_Loss: 0.6545
training Epoch: 100, train_Loss: 0.7099
training Epoch: 100, train_Loss: 0.4324
training Epoch: 100, train_Loss: 0.3252
training Epoch: 100, train_Loss: 0.4544
training Epoch: 100, train_Loss: 1.4807
training Epoch: 100, train_Loss: 1.4772
training Epoch: 100, train_Loss: 0.3670
training Epoch: 100, train_Loss: 1.0706
training Epoch: 100, train_Loss: 0.4030
training Epoch: 100, train_Loss: 2.1507
training Epoch: 100, train_Loss: 0.7662
training Epoch: 100, train_Loss: 0.9810
training Epoch: 100, train_Loss: 0.7969
training Epoch: 100, train_Loss: 0.4786
training Epoch: 100, train_Loss: 0.2873
training Epoch: 100, train_Loss: 0.9494
training Epoch: 100, train_Loss: 1.3739
training Epoch: 100, train_Loss: 1.5030
training Epoch: 100, train_Loss: 1.4438
training Epoch: 100, train_Loss: 0.3030
training Epoch: 100, train_Loss: 0.8795
training Epoch: 100, train_Loss: 1.1527
training Epoch: 100, train_Loss: 0.3288
training Epoch: 100, train_Loss: 1.8216
training Epoch: 100, train_Loss: 0.8308
training Epoch: 100, train_Loss: 0.4755
training Epoch: 100, train_Loss: 1.8088
training Epoch: 100, train_Loss: 1.6909
training Epoch: 100, train_Loss: 0.8610
training Epoch: 100, train_Loss: 0.6661
training Epoch: 100, train_Loss: 0.8561
training Epoch: 100, train_Loss: 0.6119
training Epoch: 100, train_Loss: 0.8896
training Epoch: 100, train_Loss: 1.2745
training Epoch: 100, train_Loss: 1.5797
training Epoch: 100, train_Loss: 0.5505
training Epoch: 100, train_Loss: 0.7789
training Epoch: 100, train_Loss: 0.4791
training Epoch: 100, train_Loss: 2.2545
training Epoch: 100, train_Loss: 2.2815
training Epoch: 100, train_Loss: 0.4208
training Epoch: 100, train_Loss: 0.4873
training Epoch: 100, train_Loss: 0.2813
training Epoch: 100, train_Loss: 0.9856
training Epoch: 100, train_Loss: 0.3123
training Epoch: 100, train_Loss: 1.2078
training Epoch: 100, train_Loss: 0.9838
training Epoch: 100, train_Loss: 0.6960
training Epoch: 100, train_Loss: 0.3540
training Epoch: 100, train_Loss: 1.2572
training Epoch: 100, train_Loss: 0.8926
training Epoch: 100, train_Loss: 0.4032
training Epoch: 100, train_Loss: 0.5475
training Epoch: 100, train_Loss: 0.6921
training Epoch: 100, train_Loss: 4.2500
training Epoch: 100, train_Loss: 1.5594
training Epoch: 100, train_Loss: 1.0322
training Epoch: 100, train_Loss: 0.2816
training Epoch: 100, train_Loss: 4.5087
training Epoch: 100, train_Loss: 1.6254
training Epoch: 100, train_Loss: 1.3840
training Epoch: 100, train_Loss: 1.0860
training Epoch: 100, train_Loss: 0.7841
training Epoch: 100, train_Loss: 1.1174
training Epoch: 100, train_Loss: 0.9604
training Epoch: 100, train_Loss: 0.5088
training Epoch: 100, train_Loss: 1.7751
training Epoch: 100, train_Loss: 1.5661
training Epoch: 100, train_Loss: 1.2250
training Epoch: 100, train_Loss: 0.4025
training Epoch: 100, train_Loss: 1.0707
training Epoch: 100, train_Loss: 1.3270
training Epoch: 100, train_Loss: 0.6143
training Epoch: 100, train_Loss: 0.5885
training Epoch: 100, train_Loss: 0.4609
training Epoch: 100, train_Loss: 0.4870
training Epoch: 100, train_Loss: 0.9134
training Epoch: 100, train_Loss: 0.7311
training Epoch: 100, train_Loss: 1.0792
training Epoch: 100, train_Loss: 0.5572
training Epoch: 100, train_Loss: 1.0184
training Epoch: 100, train_Loss: 0.4263
training Epoch: 100, train_Loss: 1.2137
training Epoch: 100, train_Loss: 0.8667
training Epoch: 100, train_Loss: 0.1333
training Epoch: 100, train_Loss: 1.2632
training Epoch: 100, train_Loss: 0.2104
training Epoch: 100, train_Loss: 0.8299
training Epoch: 100, train_Loss: 0.1838
training Epoch: 100, train_Loss: 1.5008
training Epoch: 100, train_Loss: 0.6988
training Epoch: 100, train_Loss: 1.0356
training Epoch: 100, train_Loss: 0.9858
training Epoch: 100, train_Loss: 1.2085
training Epoch: 100, train_Loss: 0.9062
training Epoch: 100, train_Loss: 1.7730
training Epoch: 100, train_Loss: 1.8220
training Epoch: 100, train_Loss: 0.3229
training Epoch: 100, train_Loss: 3.1952
training Epoch: 100, train_Loss: 1.7243
training Epoch: 100, train_Loss: 0.9308
training Epoch: 100, train_Loss: 0.5183
training Epoch: 100, train_Loss: 0.4456
training Epoch: 100, train_Loss: 0.6133
training Epoch: 100, train_Loss: 1.1237
training Epoch: 100, train_Loss: 1.0558
training Epoch: 100, train_Loss: 1.0842
training Epoch: 100, train_Loss: 2.0656
training Epoch: 100, train_Loss: 0.9798
training Epoch: 100, train_Loss: 1.4685
training Epoch: 100, train_Loss: 1.4671
training Epoch: 100, train_Loss: 0.3325
training Epoch: 100, train_Loss: 1.4010
training Epoch: 100, train_Loss: 0.7623
training Epoch: 100, train_Loss: 1.4945
training Epoch: 100, train_Loss: 0.6553
training Epoch: 100, train_Loss: 1.0416
training Epoch: 100, train_Loss: 2.1455
training Epoch: 100, train_Loss: 0.9457
training Epoch: 100, train_Loss: 2.8222
training Epoch: 100, train_Loss: 1.0994
training Epoch: 100, train_Loss: 2.1295
training Epoch: 100, train_Loss: 2.3044
training Epoch: 100, train_Loss: 0.9081
training Epoch: 100, train_Loss: 0.5844
training Epoch: 100, train_Loss: 0.4422
training Epoch: 100, train_Loss: 1.4366
training Epoch: 100, train_Loss: 1.0357
training Epoch: 100, train_Loss: 0.7737
training Epoch: 100, train_Loss: 0.6804
training Epoch: 100, train_Loss: 2.5253
training Epoch: 100, train_Loss: 1.4249
training Epoch: 100, train_Loss: 0.8694
training Epoch: 100, train_Loss: 0.5867
training Epoch: 100, train_Loss: 1.4495
training Epoch: 100, train_Loss: 0.7604
training Epoch: 100, train_Loss: 1.2306
training Epoch: 100, train_Loss: 0.7944
training Epoch: 100, train_Loss: 0.8076
training Epoch: 100, train_Loss: 1.2109
training Epoch: 100, train_Loss: 0.7675
training Epoch: 100, train_Loss: 0.8084
training Epoch: 100, train_Loss: 1.8780
training Epoch: 100, train_Loss: 0.3900
training Epoch: 100, train_Loss: 1.1622
training Epoch: 100, train_Loss: 0.7425
training Epoch: 100, train_Loss: 1.4030
training Epoch: 100, train_Loss: 1.3759
training Epoch: 100, train_Loss: 2.2116
training Epoch: 100, train_Loss: 0.4915
training Epoch: 100, train_Loss: 1.8779
training Epoch: 100, train_Loss: 2.3142
training Epoch: 100, train_Loss: 0.5704
training Epoch: 100, train_Loss: 0.4516
training Epoch: 100, train_Loss: 1.4252
training Epoch: 100, train_Loss: 1.4013
training Epoch: 100, train_Loss: 1.1043
training Epoch: 100, train_Loss: 0.4523
training Epoch: 100, train_Loss: 1.6345
training Epoch: 100, train_Loss: 2.2010
training Epoch: 100, train_Loss: 0.5349
training Epoch: 100, train_Loss: 1.2375
training Epoch: 100, train_Loss: 0.7131
training Epoch: 100, train_Loss: 0.7816
training Epoch: 100, train_Loss: 1.2452
training Epoch: 100, train_Loss: 0.8790
training Epoch: 100, train_Loss: 2.1130
training Epoch: 100, train_Loss: 0.6077
training Epoch: 100, train_Loss: 1.0338
training Epoch: 100, train_Loss: 0.8893
training Epoch: 100, train_Loss: 0.6725
training Epoch: 100, train_Loss: 0.3804
training Epoch: 100, train_Loss: 2.1587
training Epoch: 100, train_Loss: 0.8744
training Epoch: 100, train_Loss: 0.4945
training Epoch: 100, train_Loss: 0.5989
training Epoch: 100, train_Loss: 0.9506
training Epoch: 100, train_Loss: 2.7704
training Epoch: 100, train_Loss: 1.1647
training Epoch: 100, train_Loss: 1.2391
training Epoch: 100, train_Loss: 0.5423
training Epoch: 100, train_Loss: 0.9999
training Epoch: 100, train_Loss: 1.9653
training Epoch: 100, train_Loss: 1.0379
training Epoch: 100, train_Loss: 1.6581
training Epoch: 100, train_Loss: 1.2077
training Epoch: 100, train_Loss: 1.2011
training Epoch: 100, train_Loss: 0.6522
training Epoch: 100, train_Loss: 0.6344
training Epoch: 100, train_Loss: 1.2578
training Epoch: 100, train_Loss: 2.0256
training Epoch: 100, train_Loss: 0.8522
training Epoch: 100, train_Loss: 0.7285
training Epoch: 100, train_Loss: 0.5918
training Epoch: 100, train_Loss: 1.2934
training Epoch: 100, train_Loss: 1.7230
training Epoch: 100, train_Loss: 1.8821
training Epoch: 100, train_Loss: 0.4151
training Epoch: 100, train_Loss: 1.8916
training Epoch: 100, train_Loss: 0.7973
training Epoch: 100, train_Loss: 0.4782
training Epoch: 100, train_Loss: 1.7083
training Epoch: 100, train_Loss: 0.7001
training Epoch: 100, train_Loss: 0.6442
training Epoch: 100, train_Loss: 0.5229
training Epoch: 100, train_Loss: 0.9499
training Epoch: 100, train_Loss: 0.3027
training Epoch: 100, train_Loss: 0.6824
training Epoch: 100, train_Loss: 0.2558
fold,epoch,train_loss: 2 99 1.0876915
fold,epoch,train_loss: 2 100 1.0870705
====Evaluation
fold:2, epoch:100,train:1.087070, valid:1.087131 

fold: 3
fold,epoch,train_loss: 3 0 1.0914674
fold,epoch,train_loss: 3 1 1.0872811
fold,epoch,train_loss: 3 2 1.0871425
fold,epoch,train_loss: 3 3 1.0882373
fold,epoch,train_loss: 3 4 1.0864947
fold,epoch,train_loss: 3 5 1.0888226
fold,epoch,train_loss: 3 6 1.0947295
fold,epoch,train_loss: 3 7 1.0864935
fold,epoch,train_loss: 3 8 1.0906823
fold,epoch,train_loss: 3 9 1.0920675
fold,epoch,train_loss: 3 10 1.0925326
fold,epoch,train_loss: 3 11 1.0941689
fold,epoch,train_loss: 3 12 1.0881014
fold,epoch,train_loss: 3 13 1.0941892
fold,epoch,train_loss: 3 14 1.089241
fold,epoch,train_loss: 3 15 1.0899049
fold,epoch,train_loss: 3 16 1.0837978
fold,epoch,train_loss: 3 17 1.0852938
fold,epoch,train_loss: 3 18 1.0966648
fold,epoch,train_loss: 3 19 1.084925
fold,epoch,train_loss: 3 20 1.0884773
fold,epoch,train_loss: 3 21 1.0882243
fold,epoch,train_loss: 3 22 1.0871476
fold,epoch,train_loss: 3 23 1.0946501
fold,epoch,train_loss: 3 24 1.0922397
fold,epoch,train_loss: 3 25 1.0891693
fold,epoch,train_loss: 3 26 1.0883609
fold,epoch,train_loss: 3 27 1.08442
fold,epoch,train_loss: 3 28 1.0874225
fold,epoch,train_loss: 3 29 1.0936558
fold,epoch,train_loss: 3 30 1.0956379
fold,epoch,train_loss: 3 31 1.088475
fold,epoch,train_loss: 3 32 1.0991194
fold,epoch,train_loss: 3 33 1.0916392
fold,epoch,train_loss: 3 34 1.0878963
fold,epoch,train_loss: 3 35 1.0938938
fold,epoch,train_loss: 3 36 1.0859132
fold,epoch,train_loss: 3 37 1.0857227
fold,epoch,train_loss: 3 38 1.0939918
fold,epoch,train_loss: 3 39 1.0925397
fold,epoch,train_loss: 3 40 1.0867162
fold,epoch,train_loss: 3 41 1.0854084
fold,epoch,train_loss: 3 42 1.0955567
fold,epoch,train_loss: 3 43 1.0917466
fold,epoch,train_loss: 3 44 1.0876794
fold,epoch,train_loss: 3 45 1.0886931
fold,epoch,train_loss: 3 46 1.0832747
fold,epoch,train_loss: 3 47 1.0897
fold,epoch,train_loss: 3 48 1.0970075
training Epoch: 50, train_Loss: 0.6759
training Epoch: 50, train_Loss: 0.4340
training Epoch: 50, train_Loss: 0.6844
training Epoch: 50, train_Loss: 0.2702
training Epoch: 50, train_Loss: 0.4703
training Epoch: 50, train_Loss: 0.5399
training Epoch: 50, train_Loss: 0.5414
training Epoch: 50, train_Loss: 0.2690
training Epoch: 50, train_Loss: 0.3718
training Epoch: 50, train_Loss: 0.7714
training Epoch: 50, train_Loss: 0.2281
training Epoch: 50, train_Loss: 2.0392
training Epoch: 50, train_Loss: 0.9925
training Epoch: 50, train_Loss: 1.4293
training Epoch: 50, train_Loss: 1.5248
training Epoch: 50, train_Loss: 1.2187
training Epoch: 50, train_Loss: 2.6996
training Epoch: 50, train_Loss: 0.8968
training Epoch: 50, train_Loss: 3.3828
training Epoch: 50, train_Loss: 4.8488
training Epoch: 50, train_Loss: 0.6304
training Epoch: 50, train_Loss: 0.9721
training Epoch: 50, train_Loss: 0.6366
training Epoch: 50, train_Loss: 0.8219
training Epoch: 50, train_Loss: 1.6217
training Epoch: 50, train_Loss: 0.9431
training Epoch: 50, train_Loss: 1.1393
training Epoch: 50, train_Loss: 1.2331
training Epoch: 50, train_Loss: 0.4214
training Epoch: 50, train_Loss: 0.9408
training Epoch: 50, train_Loss: 1.2627
training Epoch: 50, train_Loss: 1.3546
training Epoch: 50, train_Loss: 0.4839
training Epoch: 50, train_Loss: 2.6433
training Epoch: 50, train_Loss: 1.3171
training Epoch: 50, train_Loss: 1.8563
training Epoch: 50, train_Loss: 1.9402
training Epoch: 50, train_Loss: 0.9713
training Epoch: 50, train_Loss: 0.8551
training Epoch: 50, train_Loss: 1.0585
training Epoch: 50, train_Loss: 1.6855
training Epoch: 50, train_Loss: 1.0239
training Epoch: 50, train_Loss: 1.4730
training Epoch: 50, train_Loss: 0.7478
training Epoch: 50, train_Loss: 1.3989
training Epoch: 50, train_Loss: 2.2196
training Epoch: 50, train_Loss: 0.4143
training Epoch: 50, train_Loss: 0.4784
training Epoch: 50, train_Loss: 0.3127
training Epoch: 50, train_Loss: 0.2892
training Epoch: 50, train_Loss: 1.3408
training Epoch: 50, train_Loss: 1.3929
training Epoch: 50, train_Loss: 0.5822
training Epoch: 50, train_Loss: 0.2011
training Epoch: 50, train_Loss: 2.9968
training Epoch: 50, train_Loss: 1.6870
training Epoch: 50, train_Loss: 1.2209
training Epoch: 50, train_Loss: 2.1297
training Epoch: 50, train_Loss: 2.4669
training Epoch: 50, train_Loss: 0.2900
training Epoch: 50, train_Loss: 0.3565
training Epoch: 50, train_Loss: 1.8278
training Epoch: 50, train_Loss: 0.8082
training Epoch: 50, train_Loss: 0.5562
training Epoch: 50, train_Loss: 0.4673
training Epoch: 50, train_Loss: 0.6178
training Epoch: 50, train_Loss: 0.7607
training Epoch: 50, train_Loss: 0.8948
training Epoch: 50, train_Loss: 0.4442
training Epoch: 50, train_Loss: 0.6665
training Epoch: 50, train_Loss: 0.7376
training Epoch: 50, train_Loss: 1.1938
training Epoch: 50, train_Loss: 0.8652
training Epoch: 50, train_Loss: 0.4070
training Epoch: 50, train_Loss: 1.2991
training Epoch: 50, train_Loss: 1.4500
training Epoch: 50, train_Loss: 0.4042
training Epoch: 50, train_Loss: 1.1303
training Epoch: 50, train_Loss: 0.3388
training Epoch: 50, train_Loss: 0.2996
training Epoch: 50, train_Loss: 0.4135
training Epoch: 50, train_Loss: 0.2975
training Epoch: 50, train_Loss: 1.0082
training Epoch: 50, train_Loss: 0.5674
training Epoch: 50, train_Loss: 0.3497
training Epoch: 50, train_Loss: 0.4817
training Epoch: 50, train_Loss: 0.1508
training Epoch: 50, train_Loss: 1.2549
training Epoch: 50, train_Loss: 1.0070
training Epoch: 50, train_Loss: 1.7137
training Epoch: 50, train_Loss: 3.5059
training Epoch: 50, train_Loss: 0.9373
training Epoch: 50, train_Loss: 0.4978
training Epoch: 50, train_Loss: 2.3487
training Epoch: 50, train_Loss: 0.6315
training Epoch: 50, train_Loss: 1.2657
training Epoch: 50, train_Loss: 1.8614
training Epoch: 50, train_Loss: 1.2936
training Epoch: 50, train_Loss: 0.3562
training Epoch: 50, train_Loss: 1.4071
training Epoch: 50, train_Loss: 0.8291
training Epoch: 50, train_Loss: 0.5322
training Epoch: 50, train_Loss: 0.4660
training Epoch: 50, train_Loss: 0.7300
training Epoch: 50, train_Loss: 0.4445
training Epoch: 50, train_Loss: 1.0805
training Epoch: 50, train_Loss: 1.5108
training Epoch: 50, train_Loss: 1.4086
training Epoch: 50, train_Loss: 0.4113
training Epoch: 50, train_Loss: 0.4958
training Epoch: 50, train_Loss: 0.6460
training Epoch: 50, train_Loss: 0.4448
training Epoch: 50, train_Loss: 1.7092
training Epoch: 50, train_Loss: 0.9559
training Epoch: 50, train_Loss: 1.3472
training Epoch: 50, train_Loss: 1.0303
training Epoch: 50, train_Loss: 0.9682
training Epoch: 50, train_Loss: 0.3200
training Epoch: 50, train_Loss: 0.7938
training Epoch: 50, train_Loss: 0.9395
training Epoch: 50, train_Loss: 0.5769
training Epoch: 50, train_Loss: 0.4018
training Epoch: 50, train_Loss: 0.6690
training Epoch: 50, train_Loss: 0.9493
training Epoch: 50, train_Loss: 2.0802
training Epoch: 50, train_Loss: 0.2756
training Epoch: 50, train_Loss: 1.2432
training Epoch: 50, train_Loss: 0.3061
training Epoch: 50, train_Loss: 0.2837
training Epoch: 50, train_Loss: 0.8422
training Epoch: 50, train_Loss: 2.1846
training Epoch: 50, train_Loss: 1.8747
training Epoch: 50, train_Loss: 0.2854
training Epoch: 50, train_Loss: 0.7215
training Epoch: 50, train_Loss: 2.0013
training Epoch: 50, train_Loss: 0.9126
training Epoch: 50, train_Loss: 0.3720
training Epoch: 50, train_Loss: 1.4693
training Epoch: 50, train_Loss: 1.0881
training Epoch: 50, train_Loss: 0.7208
training Epoch: 50, train_Loss: 2.0913
training Epoch: 50, train_Loss: 2.2954
training Epoch: 50, train_Loss: 0.5981
training Epoch: 50, train_Loss: 0.7748
training Epoch: 50, train_Loss: 2.4280
training Epoch: 50, train_Loss: 0.6530
training Epoch: 50, train_Loss: 0.6573
training Epoch: 50, train_Loss: 2.0495
training Epoch: 50, train_Loss: 2.3942
training Epoch: 50, train_Loss: 1.4006
training Epoch: 50, train_Loss: 1.3550
training Epoch: 50, train_Loss: 0.9286
training Epoch: 50, train_Loss: 1.8315
training Epoch: 50, train_Loss: 1.7519
training Epoch: 50, train_Loss: 1.3126
training Epoch: 50, train_Loss: 1.5376
training Epoch: 50, train_Loss: 0.9606
training Epoch: 50, train_Loss: 0.9884
training Epoch: 50, train_Loss: 0.7534
training Epoch: 50, train_Loss: 1.3874
training Epoch: 50, train_Loss: 1.8033
training Epoch: 50, train_Loss: 1.0298
training Epoch: 50, train_Loss: 1.0246
training Epoch: 50, train_Loss: 1.4916
training Epoch: 50, train_Loss: 0.8866
training Epoch: 50, train_Loss: 1.2603
training Epoch: 50, train_Loss: 1.4055
training Epoch: 50, train_Loss: 3.3138
training Epoch: 50, train_Loss: 2.0395
training Epoch: 50, train_Loss: 0.8363
training Epoch: 50, train_Loss: 0.7285
training Epoch: 50, train_Loss: 0.9961
training Epoch: 50, train_Loss: 0.8107
training Epoch: 50, train_Loss: 0.9363
training Epoch: 50, train_Loss: 2.3643
training Epoch: 50, train_Loss: 1.1198
training Epoch: 50, train_Loss: 0.4986
training Epoch: 50, train_Loss: 0.7326
training Epoch: 50, train_Loss: 0.8878
training Epoch: 50, train_Loss: 0.8131
training Epoch: 50, train_Loss: 2.2218
training Epoch: 50, train_Loss: 0.4168
training Epoch: 50, train_Loss: 1.2046
training Epoch: 50, train_Loss: 2.6268
training Epoch: 50, train_Loss: 0.7045
training Epoch: 50, train_Loss: 1.1897
training Epoch: 50, train_Loss: 1.0863
training Epoch: 50, train_Loss: 1.0650
training Epoch: 50, train_Loss: 1.4190
training Epoch: 50, train_Loss: 0.8152
training Epoch: 50, train_Loss: 1.2886
training Epoch: 50, train_Loss: 0.6963
training Epoch: 50, train_Loss: 3.4579
training Epoch: 50, train_Loss: 0.6009
training Epoch: 50, train_Loss: 1.5839
training Epoch: 50, train_Loss: 1.2324
training Epoch: 50, train_Loss: 2.0363
training Epoch: 50, train_Loss: 0.4578
training Epoch: 50, train_Loss: 1.7847
training Epoch: 50, train_Loss: 0.8565
training Epoch: 50, train_Loss: 0.8801
training Epoch: 50, train_Loss: 0.8877
training Epoch: 50, train_Loss: 1.6537
training Epoch: 50, train_Loss: 1.9828
training Epoch: 50, train_Loss: 0.8793
training Epoch: 50, train_Loss: 1.6752
training Epoch: 50, train_Loss: 1.1599
training Epoch: 50, train_Loss: 0.9735
training Epoch: 50, train_Loss: 1.4569
training Epoch: 50, train_Loss: 0.5369
training Epoch: 50, train_Loss: 0.9790
training Epoch: 50, train_Loss: 0.3815
training Epoch: 50, train_Loss: 0.6603
training Epoch: 50, train_Loss: 1.1963
training Epoch: 50, train_Loss: 0.8496
training Epoch: 50, train_Loss: 1.8725
training Epoch: 50, train_Loss: 0.8047
training Epoch: 50, train_Loss: 0.6510
training Epoch: 50, train_Loss: 0.7956
training Epoch: 50, train_Loss: 0.3170
training Epoch: 50, train_Loss: 2.7207
training Epoch: 50, train_Loss: 2.0163
training Epoch: 50, train_Loss: 1.1033
training Epoch: 50, train_Loss: 1.6192
training Epoch: 50, train_Loss: 0.3812
training Epoch: 50, train_Loss: 1.1632
training Epoch: 50, train_Loss: 0.8779
training Epoch: 50, train_Loss: 0.4178
training Epoch: 50, train_Loss: 0.7072
training Epoch: 50, train_Loss: 1.1277
training Epoch: 50, train_Loss: 0.4973
training Epoch: 50, train_Loss: 1.0274
training Epoch: 50, train_Loss: 0.8203
training Epoch: 50, train_Loss: 0.5563
training Epoch: 50, train_Loss: 1.8290
training Epoch: 50, train_Loss: 1.0981
training Epoch: 50, train_Loss: 1.5893
training Epoch: 50, train_Loss: 2.1171
training Epoch: 50, train_Loss: 1.4258
training Epoch: 50, train_Loss: 0.8040
training Epoch: 50, train_Loss: 0.9284
training Epoch: 50, train_Loss: 1.1055
training Epoch: 50, train_Loss: 0.7132
training Epoch: 50, train_Loss: 1.3433
training Epoch: 50, train_Loss: 1.1226
training Epoch: 50, train_Loss: 1.6239
training Epoch: 50, train_Loss: 1.1101
training Epoch: 50, train_Loss: 1.0986
training Epoch: 50, train_Loss: 1.0129
training Epoch: 50, train_Loss: 0.6040
training Epoch: 50, train_Loss: 0.5421
training Epoch: 50, train_Loss: 2.1117
training Epoch: 50, train_Loss: 0.9366
training Epoch: 50, train_Loss: 0.5690
training Epoch: 50, train_Loss: 0.3166
training Epoch: 50, train_Loss: 1.1070
training Epoch: 50, train_Loss: 1.2954
training Epoch: 50, train_Loss: 0.8693
training Epoch: 50, train_Loss: 3.5324
training Epoch: 50, train_Loss: 0.2942
training Epoch: 50, train_Loss: 1.7449
training Epoch: 50, train_Loss: 0.7407
training Epoch: 50, train_Loss: 0.3307
training Epoch: 50, train_Loss: 1.0966
training Epoch: 50, train_Loss: 0.4999
training Epoch: 50, train_Loss: 0.2570
training Epoch: 50, train_Loss: 0.3095
training Epoch: 50, train_Loss: 0.8083
training Epoch: 50, train_Loss: 3.0438
training Epoch: 50, train_Loss: 0.4357
training Epoch: 50, train_Loss: 1.3908
training Epoch: 50, train_Loss: 0.9683
training Epoch: 50, train_Loss: 3.0557
training Epoch: 50, train_Loss: 0.7991
training Epoch: 50, train_Loss: 1.7182
training Epoch: 50, train_Loss: 2.3661
training Epoch: 50, train_Loss: 1.7125
training Epoch: 50, train_Loss: 4.2204
training Epoch: 50, train_Loss: 0.8912
training Epoch: 50, train_Loss: 0.8022
training Epoch: 50, train_Loss: 0.7964
training Epoch: 50, train_Loss: 0.8308
training Epoch: 50, train_Loss: 0.7639
training Epoch: 50, train_Loss: 1.2737
training Epoch: 50, train_Loss: 0.8747
training Epoch: 50, train_Loss: 0.8462
training Epoch: 50, train_Loss: 1.0698
training Epoch: 50, train_Loss: 2.0595
training Epoch: 50, train_Loss: 0.6978
training Epoch: 50, train_Loss: 1.3944
training Epoch: 50, train_Loss: 0.5561
training Epoch: 50, train_Loss: 1.1909
training Epoch: 50, train_Loss: 0.6534
training Epoch: 50, train_Loss: 0.3737
training Epoch: 50, train_Loss: 1.3627
training Epoch: 50, train_Loss: 2.2438
training Epoch: 50, train_Loss: 1.5243
training Epoch: 50, train_Loss: 0.2590
training Epoch: 50, train_Loss: 1.0813
training Epoch: 50, train_Loss: 2.2162
training Epoch: 50, train_Loss: 0.8704
training Epoch: 50, train_Loss: 0.5898
training Epoch: 50, train_Loss: 1.0115
training Epoch: 50, train_Loss: 2.0537
training Epoch: 50, train_Loss: 0.3394
training Epoch: 50, train_Loss: 0.7212
training Epoch: 50, train_Loss: 0.6095
training Epoch: 50, train_Loss: 0.7033
training Epoch: 50, train_Loss: 1.7064
training Epoch: 50, train_Loss: 0.5625
training Epoch: 50, train_Loss: 0.9540
training Epoch: 50, train_Loss: 0.7921
training Epoch: 50, train_Loss: 2.0265
training Epoch: 50, train_Loss: 1.6682
training Epoch: 50, train_Loss: 0.4720
training Epoch: 50, train_Loss: 0.9912
training Epoch: 50, train_Loss: 0.9738
training Epoch: 50, train_Loss: 0.8014
training Epoch: 50, train_Loss: 0.4395
training Epoch: 50, train_Loss: 2.2721
training Epoch: 50, train_Loss: 1.0770
training Epoch: 50, train_Loss: 0.4063
training Epoch: 50, train_Loss: 0.5256
training Epoch: 50, train_Loss: 1.5029
training Epoch: 50, train_Loss: 0.4604
training Epoch: 50, train_Loss: 2.9976
training Epoch: 50, train_Loss: 1.1581
training Epoch: 50, train_Loss: 0.5620
training Epoch: 50, train_Loss: 0.6025
training Epoch: 50, train_Loss: 0.5118
training Epoch: 50, train_Loss: 2.2022
training Epoch: 50, train_Loss: 0.4625
training Epoch: 50, train_Loss: 1.3800
training Epoch: 50, train_Loss: 0.9026
training Epoch: 50, train_Loss: 0.9621
training Epoch: 50, train_Loss: 1.0694
training Epoch: 50, train_Loss: 1.3106
training Epoch: 50, train_Loss: 0.4183
training Epoch: 50, train_Loss: 0.5499
training Epoch: 50, train_Loss: 0.6380
training Epoch: 50, train_Loss: 0.3489
training Epoch: 50, train_Loss: 0.4165
training Epoch: 50, train_Loss: 1.7754
training Epoch: 50, train_Loss: 0.1821
training Epoch: 50, train_Loss: 0.5213
training Epoch: 50, train_Loss: 2.4869
training Epoch: 50, train_Loss: 0.1945
training Epoch: 50, train_Loss: 0.9387
training Epoch: 50, train_Loss: 0.4377
training Epoch: 50, train_Loss: 0.1660
training Epoch: 50, train_Loss: 0.4265
training Epoch: 50, train_Loss: 0.6994
training Epoch: 50, train_Loss: 1.1616
training Epoch: 50, train_Loss: 1.4329
training Epoch: 50, train_Loss: 2.4555
training Epoch: 50, train_Loss: 1.7812
training Epoch: 50, train_Loss: 0.5883
training Epoch: 50, train_Loss: 1.0744
training Epoch: 50, train_Loss: 0.6508
training Epoch: 50, train_Loss: 1.6052
training Epoch: 50, train_Loss: 2.5487
training Epoch: 50, train_Loss: 0.6774
training Epoch: 50, train_Loss: 1.7196
training Epoch: 50, train_Loss: 0.7380
training Epoch: 50, train_Loss: 1.5259
training Epoch: 50, train_Loss: 0.8389
training Epoch: 50, train_Loss: 3.9221
training Epoch: 50, train_Loss: 0.9687
training Epoch: 50, train_Loss: 1.4986
training Epoch: 50, train_Loss: 0.9023
training Epoch: 50, train_Loss: 0.5662
training Epoch: 50, train_Loss: 0.8540
training Epoch: 50, train_Loss: 0.6665
training Epoch: 50, train_Loss: 0.8271
training Epoch: 50, train_Loss: 0.6495
training Epoch: 50, train_Loss: 1.5048
training Epoch: 50, train_Loss: 1.1493
training Epoch: 50, train_Loss: 0.8205
training Epoch: 50, train_Loss: 0.5705
training Epoch: 50, train_Loss: 0.8843
training Epoch: 50, train_Loss: 0.5511
training Epoch: 50, train_Loss: 0.6103
training Epoch: 50, train_Loss: 0.4825
training Epoch: 50, train_Loss: 0.3117
training Epoch: 50, train_Loss: 0.7680
training Epoch: 50, train_Loss: 1.7221
training Epoch: 50, train_Loss: 0.1870
training Epoch: 50, train_Loss: 0.2599
training Epoch: 50, train_Loss: 0.4714
training Epoch: 50, train_Loss: 3.0695
training Epoch: 50, train_Loss: 1.0431
training Epoch: 50, train_Loss: 0.5475
training Epoch: 50, train_Loss: 2.0367
training Epoch: 50, train_Loss: 0.1928
training Epoch: 50, train_Loss: 0.1176
training Epoch: 50, train_Loss: 1.4460
training Epoch: 50, train_Loss: 2.8436
training Epoch: 50, train_Loss: 0.2147
training Epoch: 50, train_Loss: 1.0051
training Epoch: 50, train_Loss: 1.6896
training Epoch: 50, train_Loss: 0.3957
training Epoch: 50, train_Loss: 0.7572
training Epoch: 50, train_Loss: 1.5517
training Epoch: 50, train_Loss: 1.0973
training Epoch: 50, train_Loss: 0.5218
training Epoch: 50, train_Loss: 0.4650
training Epoch: 50, train_Loss: 2.6765
training Epoch: 50, train_Loss: 1.2017
training Epoch: 50, train_Loss: 0.5531
training Epoch: 50, train_Loss: 1.2641
training Epoch: 50, train_Loss: 1.1474
training Epoch: 50, train_Loss: 1.6586
training Epoch: 50, train_Loss: 0.7290
training Epoch: 50, train_Loss: 1.2365
training Epoch: 50, train_Loss: 0.5660
training Epoch: 50, train_Loss: 2.5485
training Epoch: 50, train_Loss: 1.6960
training Epoch: 50, train_Loss: 1.0433
training Epoch: 50, train_Loss: 1.6897
training Epoch: 50, train_Loss: 1.5452
training Epoch: 50, train_Loss: 0.7856
training Epoch: 50, train_Loss: 1.1572
training Epoch: 50, train_Loss: 0.7332
training Epoch: 50, train_Loss: 0.6313
training Epoch: 50, train_Loss: 1.2042
training Epoch: 50, train_Loss: 0.9094
training Epoch: 50, train_Loss: 1.5782
training Epoch: 50, train_Loss: 1.4833
training Epoch: 50, train_Loss: 0.8929
training Epoch: 50, train_Loss: 1.5068
training Epoch: 50, train_Loss: 0.8812
training Epoch: 50, train_Loss: 0.7360
training Epoch: 50, train_Loss: 0.5227
training Epoch: 50, train_Loss: 1.9377
training Epoch: 50, train_Loss: 0.9175
training Epoch: 50, train_Loss: 0.9435
training Epoch: 50, train_Loss: 0.9756
training Epoch: 50, train_Loss: 1.4724
training Epoch: 50, train_Loss: 0.4179
training Epoch: 50, train_Loss: 0.6737
training Epoch: 50, train_Loss: 1.6341
training Epoch: 50, train_Loss: 0.8571
training Epoch: 50, train_Loss: 0.3421
training Epoch: 50, train_Loss: 2.6441
training Epoch: 50, train_Loss: 2.4577
training Epoch: 50, train_Loss: 1.1481
training Epoch: 50, train_Loss: 1.2030
training Epoch: 50, train_Loss: 0.8356
training Epoch: 50, train_Loss: 1.2477
training Epoch: 50, train_Loss: 0.8140
training Epoch: 50, train_Loss: 0.5963
training Epoch: 50, train_Loss: 0.4411
training Epoch: 50, train_Loss: 0.6301
training Epoch: 50, train_Loss: 1.4713
training Epoch: 50, train_Loss: 1.2956
training Epoch: 50, train_Loss: 0.3372
training Epoch: 50, train_Loss: 0.6384
training Epoch: 50, train_Loss: 1.7100
training Epoch: 50, train_Loss: 0.7722
training Epoch: 50, train_Loss: 1.2682
training Epoch: 50, train_Loss: 0.8101
training Epoch: 50, train_Loss: 0.6752
training Epoch: 50, train_Loss: 1.4084
training Epoch: 50, train_Loss: 1.0147
training Epoch: 50, train_Loss: 0.9820
training Epoch: 50, train_Loss: 0.5667
training Epoch: 50, train_Loss: 0.7285
training Epoch: 50, train_Loss: 0.9888
training Epoch: 50, train_Loss: 0.5213
training Epoch: 50, train_Loss: 1.2467
training Epoch: 50, train_Loss: 2.3247
training Epoch: 50, train_Loss: 0.5325
training Epoch: 50, train_Loss: 0.4567
training Epoch: 50, train_Loss: 1.7047
training Epoch: 50, train_Loss: 1.1552
training Epoch: 50, train_Loss: 0.8479
training Epoch: 50, train_Loss: 0.8182
training Epoch: 50, train_Loss: 1.4230
training Epoch: 50, train_Loss: 1.1963
training Epoch: 50, train_Loss: 0.9980
training Epoch: 50, train_Loss: 0.5795
training Epoch: 50, train_Loss: 1.0521
training Epoch: 50, train_Loss: 0.6430
training Epoch: 50, train_Loss: 0.8684
training Epoch: 50, train_Loss: 0.3867
training Epoch: 50, train_Loss: 1.1458
training Epoch: 50, train_Loss: 0.3792
training Epoch: 50, train_Loss: 0.4185
training Epoch: 50, train_Loss: 0.5324
training Epoch: 50, train_Loss: 1.3815
training Epoch: 50, train_Loss: 1.8301
training Epoch: 50, train_Loss: 0.6746
training Epoch: 50, train_Loss: 0.6392
training Epoch: 50, train_Loss: 0.5461
training Epoch: 50, train_Loss: 0.8591
training Epoch: 50, train_Loss: 0.8063
training Epoch: 50, train_Loss: 0.7954
training Epoch: 50, train_Loss: 1.0793
training Epoch: 50, train_Loss: 3.5839
training Epoch: 50, train_Loss: 0.9521
training Epoch: 50, train_Loss: 1.6784
training Epoch: 50, train_Loss: 1.4628
training Epoch: 50, train_Loss: 0.5338
training Epoch: 50, train_Loss: 2.2568
training Epoch: 50, train_Loss: 0.4706
training Epoch: 50, train_Loss: 0.9004
training Epoch: 50, train_Loss: 1.3134
training Epoch: 50, train_Loss: 1.9701
training Epoch: 50, train_Loss: 1.4507
training Epoch: 50, train_Loss: 0.5924
training Epoch: 50, train_Loss: 0.6017
training Epoch: 50, train_Loss: 1.5465
training Epoch: 50, train_Loss: 1.0489
training Epoch: 50, train_Loss: 0.5726
training Epoch: 50, train_Loss: 0.7404
training Epoch: 50, train_Loss: 1.7578
training Epoch: 50, train_Loss: 0.8587
training Epoch: 50, train_Loss: 1.2140
training Epoch: 50, train_Loss: 0.4750
training Epoch: 50, train_Loss: 0.7955
training Epoch: 50, train_Loss: 0.7605
training Epoch: 50, train_Loss: 1.4632
training Epoch: 50, train_Loss: 0.5863
training Epoch: 50, train_Loss: 1.0783
training Epoch: 50, train_Loss: 1.4679
training Epoch: 50, train_Loss: 0.7981
training Epoch: 50, train_Loss: 0.8589
training Epoch: 50, train_Loss: 0.9256
training Epoch: 50, train_Loss: 1.5445
training Epoch: 50, train_Loss: 2.5393
training Epoch: 50, train_Loss: 0.4072
training Epoch: 50, train_Loss: 0.5273
training Epoch: 50, train_Loss: 0.8839
training Epoch: 50, train_Loss: 1.3985
training Epoch: 50, train_Loss: 0.9531
training Epoch: 50, train_Loss: 1.0634
training Epoch: 50, train_Loss: 0.6052
training Epoch: 50, train_Loss: 1.9391
training Epoch: 50, train_Loss: 0.9737
training Epoch: 50, train_Loss: 0.6708
training Epoch: 50, train_Loss: 1.7158
training Epoch: 50, train_Loss: 0.4883
training Epoch: 50, train_Loss: 1.0952
training Epoch: 50, train_Loss: 0.5013
training Epoch: 50, train_Loss: 1.0934
training Epoch: 50, train_Loss: 0.4846
training Epoch: 50, train_Loss: 0.4257
training Epoch: 50, train_Loss: 0.3781
training Epoch: 50, train_Loss: 0.7002
training Epoch: 50, train_Loss: 0.8087
training Epoch: 50, train_Loss: 0.2920
training Epoch: 50, train_Loss: 1.6194
training Epoch: 50, train_Loss: 1.4446
training Epoch: 50, train_Loss: 0.6467
training Epoch: 50, train_Loss: 1.2146
training Epoch: 50, train_Loss: 0.5901
training Epoch: 50, train_Loss: 1.5631
training Epoch: 50, train_Loss: 0.8391
training Epoch: 50, train_Loss: 0.8022
training Epoch: 50, train_Loss: 2.4149
training Epoch: 50, train_Loss: 1.8235
training Epoch: 50, train_Loss: 1.0439
training Epoch: 50, train_Loss: 0.9064
training Epoch: 50, train_Loss: 0.6153
training Epoch: 50, train_Loss: 0.6701
training Epoch: 50, train_Loss: 0.5285
training Epoch: 50, train_Loss: 1.6210
training Epoch: 50, train_Loss: 1.0495
training Epoch: 50, train_Loss: 0.6249
training Epoch: 50, train_Loss: 0.6113
training Epoch: 50, train_Loss: 1.8295
training Epoch: 50, train_Loss: 0.3697
training Epoch: 50, train_Loss: 0.9467
training Epoch: 50, train_Loss: 1.0677
training Epoch: 50, train_Loss: 0.4491
fold,epoch,train_loss: 3 49 1.0910803
fold,epoch,train_loss: 3 50 1.0914155
fold,epoch,train_loss: 3 51 1.0855261
fold,epoch,train_loss: 3 52 1.087075
fold,epoch,train_loss: 3 53 1.0890217
fold,epoch,train_loss: 3 54 1.0859307
fold,epoch,train_loss: 3 55 1.0847216
fold,epoch,train_loss: 3 56 1.0871418
fold,epoch,train_loss: 3 57 1.0861502
fold,epoch,train_loss: 3 58 1.0865725
fold,epoch,train_loss: 3 59 1.091468
fold,epoch,train_loss: 3 60 1.0889176
fold,epoch,train_loss: 3 61 1.0886581
fold,epoch,train_loss: 3 62 1.0915116
fold,epoch,train_loss: 3 63 1.0881687
fold,epoch,train_loss: 3 64 1.088588
fold,epoch,train_loss: 3 65 1.0857955
fold,epoch,train_loss: 3 66 1.0918992
fold,epoch,train_loss: 3 67 1.0884567
fold,epoch,train_loss: 3 68 1.0917672
fold,epoch,train_loss: 3 69 1.087986
fold,epoch,train_loss: 3 70 1.0922251
fold,epoch,train_loss: 3 71 1.08985
fold,epoch,train_loss: 3 72 1.0839204
fold,epoch,train_loss: 3 73 1.0896667
fold,epoch,train_loss: 3 74 1.0883496
fold,epoch,train_loss: 3 75 1.0923709
fold,epoch,train_loss: 3 76 1.0893073
fold,epoch,train_loss: 3 77 1.0888697
fold,epoch,train_loss: 3 78 1.0832297
fold,epoch,train_loss: 3 79 1.0872748
fold,epoch,train_loss: 3 80 1.0866835
fold,epoch,train_loss: 3 81 1.0872653
fold,epoch,train_loss: 3 82 1.0897031
fold,epoch,train_loss: 3 83 1.0907278
fold,epoch,train_loss: 3 84 1.086579
fold,epoch,train_loss: 3 85 1.0938426
fold,epoch,train_loss: 3 86 1.0868719
fold,epoch,train_loss: 3 87 1.0876205
fold,epoch,train_loss: 3 88 1.0890822
fold,epoch,train_loss: 3 89 1.0875453
fold,epoch,train_loss: 3 90 1.0858405
fold,epoch,train_loss: 3 91 1.0978696
fold,epoch,train_loss: 3 92 1.0882337
fold,epoch,train_loss: 3 93 1.0862819
fold,epoch,train_loss: 3 94 1.0948906
fold,epoch,train_loss: 3 95 1.0885481
fold,epoch,train_loss: 3 96 1.0887965
fold,epoch,train_loss: 3 97 1.0871985
fold,epoch,train_loss: 3 98 1.0950955
training Epoch: 100, train_Loss: 0.9139
training Epoch: 100, train_Loss: 0.3388
training Epoch: 100, train_Loss: 1.5186
training Epoch: 100, train_Loss: 1.2212
training Epoch: 100, train_Loss: 0.9101
training Epoch: 100, train_Loss: 0.6281
training Epoch: 100, train_Loss: 0.9616
training Epoch: 100, train_Loss: 0.5112
training Epoch: 100, train_Loss: 1.5131
training Epoch: 100, train_Loss: 0.8502
training Epoch: 100, train_Loss: 0.6192
training Epoch: 100, train_Loss: 1.5503
training Epoch: 100, train_Loss: 1.8589
training Epoch: 100, train_Loss: 0.7680
training Epoch: 100, train_Loss: 0.4029
training Epoch: 100, train_Loss: 0.4303
training Epoch: 100, train_Loss: 2.3184
training Epoch: 100, train_Loss: 0.7395
training Epoch: 100, train_Loss: 0.7539
training Epoch: 100, train_Loss: 1.2239
training Epoch: 100, train_Loss: 0.6071
training Epoch: 100, train_Loss: 0.8355
training Epoch: 100, train_Loss: 0.6090
training Epoch: 100, train_Loss: 0.3533
training Epoch: 100, train_Loss: 0.3630
training Epoch: 100, train_Loss: 2.0735
training Epoch: 100, train_Loss: 0.8807
training Epoch: 100, train_Loss: 1.4787
training Epoch: 100, train_Loss: 0.2914
training Epoch: 100, train_Loss: 0.5577
training Epoch: 100, train_Loss: 0.5965
training Epoch: 100, train_Loss: 1.5188
training Epoch: 100, train_Loss: 1.6415
training Epoch: 100, train_Loss: 1.0977
training Epoch: 100, train_Loss: 0.5689
training Epoch: 100, train_Loss: 0.6820
training Epoch: 100, train_Loss: 0.2721
training Epoch: 100, train_Loss: 0.2178
training Epoch: 100, train_Loss: 1.2653
training Epoch: 100, train_Loss: 2.5123
training Epoch: 100, train_Loss: 0.8791
training Epoch: 100, train_Loss: 2.7823
training Epoch: 100, train_Loss: 1.7445
training Epoch: 100, train_Loss: 0.6953
training Epoch: 100, train_Loss: 0.4853
training Epoch: 100, train_Loss: 0.7097
training Epoch: 100, train_Loss: 0.3924
training Epoch: 100, train_Loss: 0.4187
training Epoch: 100, train_Loss: 1.2228
training Epoch: 100, train_Loss: 1.0727
training Epoch: 100, train_Loss: 1.7189
training Epoch: 100, train_Loss: 0.6015
training Epoch: 100, train_Loss: 0.8588
training Epoch: 100, train_Loss: 1.7847
training Epoch: 100, train_Loss: 1.0979
training Epoch: 100, train_Loss: 0.6723
training Epoch: 100, train_Loss: 2.0456
training Epoch: 100, train_Loss: 0.5618
training Epoch: 100, train_Loss: 0.4880
training Epoch: 100, train_Loss: 0.7731
training Epoch: 100, train_Loss: 1.1533
training Epoch: 100, train_Loss: 1.5946
training Epoch: 100, train_Loss: 1.8638
training Epoch: 100, train_Loss: 1.9097
training Epoch: 100, train_Loss: 0.9947
training Epoch: 100, train_Loss: 1.8732
training Epoch: 100, train_Loss: 1.3155
training Epoch: 100, train_Loss: 0.8122
training Epoch: 100, train_Loss: 0.9914
training Epoch: 100, train_Loss: 1.3338
training Epoch: 100, train_Loss: 1.2150
training Epoch: 100, train_Loss: 1.5093
training Epoch: 100, train_Loss: 0.5397
training Epoch: 100, train_Loss: 2.6190
training Epoch: 100, train_Loss: 1.0246
training Epoch: 100, train_Loss: 0.9113
training Epoch: 100, train_Loss: 0.4593
training Epoch: 100, train_Loss: 0.5580
training Epoch: 100, train_Loss: 0.7937
training Epoch: 100, train_Loss: 1.4665
training Epoch: 100, train_Loss: 0.8793
training Epoch: 100, train_Loss: 0.6586
training Epoch: 100, train_Loss: 2.0539
training Epoch: 100, train_Loss: 0.3281
training Epoch: 100, train_Loss: 1.9581
training Epoch: 100, train_Loss: 1.4360
training Epoch: 100, train_Loss: 0.3262
training Epoch: 100, train_Loss: 1.2484
training Epoch: 100, train_Loss: 1.4388
training Epoch: 100, train_Loss: 2.4158
training Epoch: 100, train_Loss: 0.3592
training Epoch: 100, train_Loss: 0.9637
training Epoch: 100, train_Loss: 2.2567
training Epoch: 100, train_Loss: 0.7643
training Epoch: 100, train_Loss: 1.6364
training Epoch: 100, train_Loss: 0.5626
training Epoch: 100, train_Loss: 0.8667
training Epoch: 100, train_Loss: 1.0720
training Epoch: 100, train_Loss: 0.7381
training Epoch: 100, train_Loss: 1.0917
training Epoch: 100, train_Loss: 0.4864
training Epoch: 100, train_Loss: 2.1685
training Epoch: 100, train_Loss: 1.0308
training Epoch: 100, train_Loss: 0.6810
training Epoch: 100, train_Loss: 0.3819
training Epoch: 100, train_Loss: 1.0320
training Epoch: 100, train_Loss: 1.5649
training Epoch: 100, train_Loss: 0.5074
training Epoch: 100, train_Loss: 1.6862
training Epoch: 100, train_Loss: 0.4821
training Epoch: 100, train_Loss: 3.3696
training Epoch: 100, train_Loss: 0.9122
training Epoch: 100, train_Loss: 0.7644
training Epoch: 100, train_Loss: 0.3366
training Epoch: 100, train_Loss: 0.3348
training Epoch: 100, train_Loss: 0.7755
training Epoch: 100, train_Loss: 1.5704
training Epoch: 100, train_Loss: 1.0895
training Epoch: 100, train_Loss: 3.0020
training Epoch: 100, train_Loss: 1.0337
training Epoch: 100, train_Loss: 0.8246
training Epoch: 100, train_Loss: 0.4860
training Epoch: 100, train_Loss: 0.6128
training Epoch: 100, train_Loss: 0.9678
training Epoch: 100, train_Loss: 0.3707
training Epoch: 100, train_Loss: 0.7898
training Epoch: 100, train_Loss: 0.5782
training Epoch: 100, train_Loss: 2.1172
training Epoch: 100, train_Loss: 0.8407
training Epoch: 100, train_Loss: 2.1392
training Epoch: 100, train_Loss: 0.7157
training Epoch: 100, train_Loss: 1.0919
training Epoch: 100, train_Loss: 1.0367
training Epoch: 100, train_Loss: 0.7439
training Epoch: 100, train_Loss: 2.2508
training Epoch: 100, train_Loss: 0.8821
training Epoch: 100, train_Loss: 0.5276
training Epoch: 100, train_Loss: 0.9652
training Epoch: 100, train_Loss: 1.1704
training Epoch: 100, train_Loss: 0.9134
training Epoch: 100, train_Loss: 0.6751
training Epoch: 100, train_Loss: 0.4886
training Epoch: 100, train_Loss: 1.1620
training Epoch: 100, train_Loss: 1.4205
training Epoch: 100, train_Loss: 1.5042
training Epoch: 100, train_Loss: 0.2766
training Epoch: 100, train_Loss: 1.0456
training Epoch: 100, train_Loss: 0.6137
training Epoch: 100, train_Loss: 0.3026
training Epoch: 100, train_Loss: 2.2478
training Epoch: 100, train_Loss: 0.3653
training Epoch: 100, train_Loss: 1.4440
training Epoch: 100, train_Loss: 2.0596
training Epoch: 100, train_Loss: 1.0115
training Epoch: 100, train_Loss: 1.3704
training Epoch: 100, train_Loss: 1.4705
training Epoch: 100, train_Loss: 1.3449
training Epoch: 100, train_Loss: 0.4426
training Epoch: 100, train_Loss: 1.3713
training Epoch: 100, train_Loss: 0.3264
training Epoch: 100, train_Loss: 0.7599
training Epoch: 100, train_Loss: 1.3950
training Epoch: 100, train_Loss: 0.8800
training Epoch: 100, train_Loss: 1.5740
training Epoch: 100, train_Loss: 1.9632
training Epoch: 100, train_Loss: 0.4857
training Epoch: 100, train_Loss: 1.2790
training Epoch: 100, train_Loss: 1.5013
training Epoch: 100, train_Loss: 0.4940
training Epoch: 100, train_Loss: 0.8387
training Epoch: 100, train_Loss: 0.6360
training Epoch: 100, train_Loss: 0.8706
training Epoch: 100, train_Loss: 0.4596
training Epoch: 100, train_Loss: 0.9149
training Epoch: 100, train_Loss: 0.8031
training Epoch: 100, train_Loss: 1.3631
training Epoch: 100, train_Loss: 0.8285
training Epoch: 100, train_Loss: 1.5273
training Epoch: 100, train_Loss: 1.1289
training Epoch: 100, train_Loss: 0.9672
training Epoch: 100, train_Loss: 0.6104
training Epoch: 100, train_Loss: 1.2930
training Epoch: 100, train_Loss: 0.6165
training Epoch: 100, train_Loss: 1.2479
training Epoch: 100, train_Loss: 1.2092
training Epoch: 100, train_Loss: 0.7413
training Epoch: 100, train_Loss: 0.7506
training Epoch: 100, train_Loss: 0.3452
training Epoch: 100, train_Loss: 0.8538
training Epoch: 100, train_Loss: 0.4874
training Epoch: 100, train_Loss: 1.2414
training Epoch: 100, train_Loss: 0.3720
training Epoch: 100, train_Loss: 0.9563
training Epoch: 100, train_Loss: 0.7159
training Epoch: 100, train_Loss: 0.7681
training Epoch: 100, train_Loss: 3.4968
training Epoch: 100, train_Loss: 0.9452
training Epoch: 100, train_Loss: 0.3132
training Epoch: 100, train_Loss: 2.9824
training Epoch: 100, train_Loss: 0.7003
training Epoch: 100, train_Loss: 1.1711
training Epoch: 100, train_Loss: 1.1969
training Epoch: 100, train_Loss: 1.1063
training Epoch: 100, train_Loss: 0.8987
training Epoch: 100, train_Loss: 0.6016
training Epoch: 100, train_Loss: 1.0714
training Epoch: 100, train_Loss: 1.4661
training Epoch: 100, train_Loss: 1.3900
training Epoch: 100, train_Loss: 1.3883
training Epoch: 100, train_Loss: 0.3459
training Epoch: 100, train_Loss: 1.4311
training Epoch: 100, train_Loss: 0.7222
training Epoch: 100, train_Loss: 0.5958
training Epoch: 100, train_Loss: 2.0622
training Epoch: 100, train_Loss: 0.4870
training Epoch: 100, train_Loss: 0.8634
training Epoch: 100, train_Loss: 0.6130
training Epoch: 100, train_Loss: 0.6384
training Epoch: 100, train_Loss: 3.9307
training Epoch: 100, train_Loss: 2.1654
training Epoch: 100, train_Loss: 0.5094
training Epoch: 100, train_Loss: 0.5042
training Epoch: 100, train_Loss: 1.1494
training Epoch: 100, train_Loss: 0.9393
training Epoch: 100, train_Loss: 1.0573
training Epoch: 100, train_Loss: 0.8000
training Epoch: 100, train_Loss: 0.5750
training Epoch: 100, train_Loss: 1.2203
training Epoch: 100, train_Loss: 0.6241
training Epoch: 100, train_Loss: 2.2829
training Epoch: 100, train_Loss: 1.1347
training Epoch: 100, train_Loss: 0.3688
training Epoch: 100, train_Loss: 1.8428
training Epoch: 100, train_Loss: 1.5154
training Epoch: 100, train_Loss: 0.7335
training Epoch: 100, train_Loss: 0.5212
training Epoch: 100, train_Loss: 1.4689
training Epoch: 100, train_Loss: 0.4361
training Epoch: 100, train_Loss: 1.2288
training Epoch: 100, train_Loss: 2.6389
training Epoch: 100, train_Loss: 0.5131
training Epoch: 100, train_Loss: 1.2770
training Epoch: 100, train_Loss: 0.4642
training Epoch: 100, train_Loss: 1.9162
training Epoch: 100, train_Loss: 0.2983
training Epoch: 100, train_Loss: 1.2558
training Epoch: 100, train_Loss: 0.4010
training Epoch: 100, train_Loss: 1.7343
training Epoch: 100, train_Loss: 2.2016
training Epoch: 100, train_Loss: 2.6262
training Epoch: 100, train_Loss: 0.7914
training Epoch: 100, train_Loss: 0.5239
training Epoch: 100, train_Loss: 1.0348
training Epoch: 100, train_Loss: 0.5215
training Epoch: 100, train_Loss: 0.5114
training Epoch: 100, train_Loss: 1.9915
training Epoch: 100, train_Loss: 0.5551
training Epoch: 100, train_Loss: 1.2021
training Epoch: 100, train_Loss: 1.9039
training Epoch: 100, train_Loss: 1.6125
training Epoch: 100, train_Loss: 1.2917
training Epoch: 100, train_Loss: 1.4634
training Epoch: 100, train_Loss: 0.6602
training Epoch: 100, train_Loss: 0.7628
training Epoch: 100, train_Loss: 0.6391
training Epoch: 100, train_Loss: 0.5062
training Epoch: 100, train_Loss: 0.5688
training Epoch: 100, train_Loss: 1.1219
training Epoch: 100, train_Loss: 1.5070
training Epoch: 100, train_Loss: 0.3473
training Epoch: 100, train_Loss: 0.7782
training Epoch: 100, train_Loss: 0.8102
training Epoch: 100, train_Loss: 1.5357
training Epoch: 100, train_Loss: 0.4858
training Epoch: 100, train_Loss: 0.7341
training Epoch: 100, train_Loss: 0.9028
training Epoch: 100, train_Loss: 1.4118
training Epoch: 100, train_Loss: 2.0291
training Epoch: 100, train_Loss: 0.3065
training Epoch: 100, train_Loss: 0.7099
training Epoch: 100, train_Loss: 1.7551
training Epoch: 100, train_Loss: 1.3325
training Epoch: 100, train_Loss: 2.1625
training Epoch: 100, train_Loss: 0.3893
training Epoch: 100, train_Loss: 0.5507
training Epoch: 100, train_Loss: 0.9200
training Epoch: 100, train_Loss: 0.6670
training Epoch: 100, train_Loss: 3.2243
training Epoch: 100, train_Loss: 1.6275
training Epoch: 100, train_Loss: 0.6683
training Epoch: 100, train_Loss: 0.4807
training Epoch: 100, train_Loss: 0.7113
training Epoch: 100, train_Loss: 0.4932
training Epoch: 100, train_Loss: 1.1477
training Epoch: 100, train_Loss: 1.6948
training Epoch: 100, train_Loss: 0.6915
training Epoch: 100, train_Loss: 0.6855
training Epoch: 100, train_Loss: 1.7824
training Epoch: 100, train_Loss: 0.8463
training Epoch: 100, train_Loss: 0.5175
training Epoch: 100, train_Loss: 0.7685
training Epoch: 100, train_Loss: 1.4295
training Epoch: 100, train_Loss: 0.9019
training Epoch: 100, train_Loss: 0.4714
training Epoch: 100, train_Loss: 0.4067
training Epoch: 100, train_Loss: 0.2994
training Epoch: 100, train_Loss: 0.7862
training Epoch: 100, train_Loss: 0.4903
training Epoch: 100, train_Loss: 0.6575
training Epoch: 100, train_Loss: 1.3894
training Epoch: 100, train_Loss: 0.1676
training Epoch: 100, train_Loss: 1.2054
training Epoch: 100, train_Loss: 2.5393
training Epoch: 100, train_Loss: 0.2301
training Epoch: 100, train_Loss: 2.2865
training Epoch: 100, train_Loss: 0.2540
training Epoch: 100, train_Loss: 2.4247
training Epoch: 100, train_Loss: 0.5183
training Epoch: 100, train_Loss: 1.4771
training Epoch: 100, train_Loss: 1.5232
training Epoch: 100, train_Loss: 2.1697
training Epoch: 100, train_Loss: 1.5898
training Epoch: 100, train_Loss: 0.4601
training Epoch: 100, train_Loss: 1.3494
training Epoch: 100, train_Loss: 0.8800
training Epoch: 100, train_Loss: 0.9533
training Epoch: 100, train_Loss: 0.5187
training Epoch: 100, train_Loss: 1.2311
training Epoch: 100, train_Loss: 1.0014
training Epoch: 100, train_Loss: 0.9877
training Epoch: 100, train_Loss: 0.4759
training Epoch: 100, train_Loss: 1.0822
training Epoch: 100, train_Loss: 3.4391
training Epoch: 100, train_Loss: 0.6193
training Epoch: 100, train_Loss: 0.4997
training Epoch: 100, train_Loss: 1.9969
training Epoch: 100, train_Loss: 1.9391
training Epoch: 100, train_Loss: 1.9568
training Epoch: 100, train_Loss: 1.0219
training Epoch: 100, train_Loss: 1.6542
training Epoch: 100, train_Loss: 0.7997
training Epoch: 100, train_Loss: 1.4898
training Epoch: 100, train_Loss: 1.0186
training Epoch: 100, train_Loss: 0.9085
training Epoch: 100, train_Loss: 1.1786
training Epoch: 100, train_Loss: 1.0288
training Epoch: 100, train_Loss: 0.6908
training Epoch: 100, train_Loss: 1.5701
training Epoch: 100, train_Loss: 0.5684
training Epoch: 100, train_Loss: 0.8137
training Epoch: 100, train_Loss: 0.5563
training Epoch: 100, train_Loss: 0.8717
training Epoch: 100, train_Loss: 0.6053
training Epoch: 100, train_Loss: 0.4924
training Epoch: 100, train_Loss: 0.6260
training Epoch: 100, train_Loss: 1.6905
training Epoch: 100, train_Loss: 1.1938
training Epoch: 100, train_Loss: 0.2652
training Epoch: 100, train_Loss: 1.4744
training Epoch: 100, train_Loss: 1.0513
training Epoch: 100, train_Loss: 1.7740
training Epoch: 100, train_Loss: 0.7111
training Epoch: 100, train_Loss: 0.8545
training Epoch: 100, train_Loss: 0.8502
training Epoch: 100, train_Loss: 2.4868
training Epoch: 100, train_Loss: 2.1508
training Epoch: 100, train_Loss: 1.5410
training Epoch: 100, train_Loss: 1.8724
training Epoch: 100, train_Loss: 1.0301
training Epoch: 100, train_Loss: 3.1563
training Epoch: 100, train_Loss: 0.3344
training Epoch: 100, train_Loss: 1.1440
training Epoch: 100, train_Loss: 0.4928
training Epoch: 100, train_Loss: 0.6002
training Epoch: 100, train_Loss: 0.7199
training Epoch: 100, train_Loss: 0.9899
training Epoch: 100, train_Loss: 0.6550
training Epoch: 100, train_Loss: 0.6072
training Epoch: 100, train_Loss: 1.3018
training Epoch: 100, train_Loss: 0.4864
training Epoch: 100, train_Loss: 0.9144
training Epoch: 100, train_Loss: 0.9556
training Epoch: 100, train_Loss: 1.7251
training Epoch: 100, train_Loss: 0.3247
training Epoch: 100, train_Loss: 2.4179
training Epoch: 100, train_Loss: 0.2795
training Epoch: 100, train_Loss: 0.7823
training Epoch: 100, train_Loss: 2.2916
training Epoch: 100, train_Loss: 0.8160
training Epoch: 100, train_Loss: 2.1774
training Epoch: 100, train_Loss: 0.2494
training Epoch: 100, train_Loss: 1.3984
training Epoch: 100, train_Loss: 0.9748
training Epoch: 100, train_Loss: 0.8654
training Epoch: 100, train_Loss: 0.8344
training Epoch: 100, train_Loss: 1.7197
training Epoch: 100, train_Loss: 0.9370
training Epoch: 100, train_Loss: 2.0023
training Epoch: 100, train_Loss: 0.6219
training Epoch: 100, train_Loss: 1.4943
training Epoch: 100, train_Loss: 0.4455
training Epoch: 100, train_Loss: 1.2210
training Epoch: 100, train_Loss: 0.6016
training Epoch: 100, train_Loss: 1.0663
training Epoch: 100, train_Loss: 0.7384
training Epoch: 100, train_Loss: 1.9314
training Epoch: 100, train_Loss: 0.6511
training Epoch: 100, train_Loss: 0.5737
training Epoch: 100, train_Loss: 0.6720
training Epoch: 100, train_Loss: 2.8410
training Epoch: 100, train_Loss: 0.9871
training Epoch: 100, train_Loss: 2.1675
training Epoch: 100, train_Loss: 0.8275
training Epoch: 100, train_Loss: 0.7498
training Epoch: 100, train_Loss: 1.1630
training Epoch: 100, train_Loss: 0.8595
training Epoch: 100, train_Loss: 2.1411
training Epoch: 100, train_Loss: 0.8091
training Epoch: 100, train_Loss: 0.7213
training Epoch: 100, train_Loss: 0.9790
training Epoch: 100, train_Loss: 1.4480
training Epoch: 100, train_Loss: 1.2298
training Epoch: 100, train_Loss: 0.5282
training Epoch: 100, train_Loss: 1.7481
training Epoch: 100, train_Loss: 0.7820
training Epoch: 100, train_Loss: 0.5331
training Epoch: 100, train_Loss: 0.7813
training Epoch: 100, train_Loss: 0.8749
training Epoch: 100, train_Loss: 1.1916
training Epoch: 100, train_Loss: 0.9415
training Epoch: 100, train_Loss: 1.4538
training Epoch: 100, train_Loss: 1.7590
training Epoch: 100, train_Loss: 0.4056
training Epoch: 100, train_Loss: 0.3912
training Epoch: 100, train_Loss: 4.0201
training Epoch: 100, train_Loss: 0.5535
training Epoch: 100, train_Loss: 1.5125
training Epoch: 100, train_Loss: 0.3912
training Epoch: 100, train_Loss: 1.9924
training Epoch: 100, train_Loss: 0.4819
training Epoch: 100, train_Loss: 2.0822
training Epoch: 100, train_Loss: 0.5473
training Epoch: 100, train_Loss: 0.7291
training Epoch: 100, train_Loss: 2.2745
training Epoch: 100, train_Loss: 0.3949
training Epoch: 100, train_Loss: 0.7938
training Epoch: 100, train_Loss: 2.3889
training Epoch: 100, train_Loss: 0.6721
training Epoch: 100, train_Loss: 0.5262
training Epoch: 100, train_Loss: 1.3025
training Epoch: 100, train_Loss: 0.3521
training Epoch: 100, train_Loss: 0.5440
training Epoch: 100, train_Loss: 1.1774
training Epoch: 100, train_Loss: 2.8585
training Epoch: 100, train_Loss: 1.2159
training Epoch: 100, train_Loss: 0.9603
training Epoch: 100, train_Loss: 0.3656
training Epoch: 100, train_Loss: 0.8331
training Epoch: 100, train_Loss: 1.7457
training Epoch: 100, train_Loss: 0.5076
training Epoch: 100, train_Loss: 1.0827
training Epoch: 100, train_Loss: 0.5042
training Epoch: 100, train_Loss: 0.5470
training Epoch: 100, train_Loss: 2.9549
training Epoch: 100, train_Loss: 0.4316
training Epoch: 100, train_Loss: 0.8018
training Epoch: 100, train_Loss: 0.7735
training Epoch: 100, train_Loss: 0.7640
training Epoch: 100, train_Loss: 0.3900
training Epoch: 100, train_Loss: 0.4361
training Epoch: 100, train_Loss: 1.2384
training Epoch: 100, train_Loss: 0.7815
training Epoch: 100, train_Loss: 0.5877
training Epoch: 100, train_Loss: 1.0630
training Epoch: 100, train_Loss: 3.2247
training Epoch: 100, train_Loss: 1.7509
training Epoch: 100, train_Loss: 2.0316
training Epoch: 100, train_Loss: 0.5445
training Epoch: 100, train_Loss: 1.0055
training Epoch: 100, train_Loss: 0.5756
training Epoch: 100, train_Loss: 0.5525
training Epoch: 100, train_Loss: 0.3878
training Epoch: 100, train_Loss: 1.3728
training Epoch: 100, train_Loss: 0.7971
training Epoch: 100, train_Loss: 0.7530
training Epoch: 100, train_Loss: 2.6643
training Epoch: 100, train_Loss: 0.3736
training Epoch: 100, train_Loss: 0.3759
training Epoch: 100, train_Loss: 0.6066
training Epoch: 100, train_Loss: 0.2759
training Epoch: 100, train_Loss: 0.4780
training Epoch: 100, train_Loss: 2.3086
training Epoch: 100, train_Loss: 2.1881
training Epoch: 100, train_Loss: 0.4241
training Epoch: 100, train_Loss: 0.6539
training Epoch: 100, train_Loss: 1.0645
training Epoch: 100, train_Loss: 0.2256
training Epoch: 100, train_Loss: 0.8789
training Epoch: 100, train_Loss: 2.1839
training Epoch: 100, train_Loss: 1.5545
training Epoch: 100, train_Loss: 0.3053
training Epoch: 100, train_Loss: 1.2390
training Epoch: 100, train_Loss: 2.3728
training Epoch: 100, train_Loss: 0.6659
training Epoch: 100, train_Loss: 1.7459
training Epoch: 100, train_Loss: 0.7912
training Epoch: 100, train_Loss: 0.4792
training Epoch: 100, train_Loss: 2.7641
training Epoch: 100, train_Loss: 0.3606
training Epoch: 100, train_Loss: 1.6602
training Epoch: 100, train_Loss: 1.2656
training Epoch: 100, train_Loss: 1.0683
training Epoch: 100, train_Loss: 0.5654
training Epoch: 100, train_Loss: 1.9785
training Epoch: 100, train_Loss: 0.7449
training Epoch: 100, train_Loss: 0.9486
training Epoch: 100, train_Loss: 1.1658
training Epoch: 100, train_Loss: 0.6266
training Epoch: 100, train_Loss: 1.2750
training Epoch: 100, train_Loss: 0.8118
training Epoch: 100, train_Loss: 0.6488
training Epoch: 100, train_Loss: 0.5418
training Epoch: 100, train_Loss: 0.8609
training Epoch: 100, train_Loss: 0.6558
training Epoch: 100, train_Loss: 1.0060
training Epoch: 100, train_Loss: 0.9124
training Epoch: 100, train_Loss: 0.4523
training Epoch: 100, train_Loss: 1.7874
training Epoch: 100, train_Loss: 0.9335
training Epoch: 100, train_Loss: 0.9456
training Epoch: 100, train_Loss: 0.7308
training Epoch: 100, train_Loss: 3.2252
training Epoch: 100, train_Loss: 2.3270
training Epoch: 100, train_Loss: 0.3039
training Epoch: 100, train_Loss: 0.7235
training Epoch: 100, train_Loss: 1.0728
training Epoch: 100, train_Loss: 0.3750
training Epoch: 100, train_Loss: 0.8226
training Epoch: 100, train_Loss: 0.6858
training Epoch: 100, train_Loss: 1.3665
training Epoch: 100, train_Loss: 2.0934
training Epoch: 100, train_Loss: 0.8515
training Epoch: 100, train_Loss: 0.5476
training Epoch: 100, train_Loss: 0.4747
training Epoch: 100, train_Loss: 0.6769
training Epoch: 100, train_Loss: 1.3481
training Epoch: 100, train_Loss: 2.5957
training Epoch: 100, train_Loss: 0.9472
training Epoch: 100, train_Loss: 0.4198
training Epoch: 100, train_Loss: 0.6838
training Epoch: 100, train_Loss: 0.7104
training Epoch: 100, train_Loss: 1.5875
training Epoch: 100, train_Loss: 1.9083
training Epoch: 100, train_Loss: 0.9179
training Epoch: 100, train_Loss: 0.6256
training Epoch: 100, train_Loss: 1.5892
training Epoch: 100, train_Loss: 1.1953
training Epoch: 100, train_Loss: 0.3850
training Epoch: 100, train_Loss: 1.3281
training Epoch: 100, train_Loss: 0.3732
training Epoch: 100, train_Loss: 1.8309
training Epoch: 100, train_Loss: 0.5526
training Epoch: 100, train_Loss: 1.4482
training Epoch: 100, train_Loss: 2.4261
training Epoch: 100, train_Loss: 0.6657
training Epoch: 100, train_Loss: 0.5813
training Epoch: 100, train_Loss: 0.7531
training Epoch: 100, train_Loss: 0.7270
training Epoch: 100, train_Loss: 0.5589
training Epoch: 100, train_Loss: 1.1052
training Epoch: 100, train_Loss: 1.0359
training Epoch: 100, train_Loss: 0.8296
training Epoch: 100, train_Loss: 1.9665
training Epoch: 100, train_Loss: 0.3994
training Epoch: 100, train_Loss: 0.4472
fold,epoch,train_loss: 3 99 1.0856268
fold,epoch,train_loss: 3 100 1.0861439
====Evaluation
fold:3, epoch:100,train:1.086144, valid:1.102617 

fold: 4
fold,epoch,train_loss: 4 0 1.0925543
fold,epoch,train_loss: 4 1 1.0972779
fold,epoch,train_loss: 4 2 1.0884141
fold,epoch,train_loss: 4 3 1.0946076
fold,epoch,train_loss: 4 4 1.088843
fold,epoch,train_loss: 4 5 1.0987747
fold,epoch,train_loss: 4 6 1.0857874
fold,epoch,train_loss: 4 7 1.0851504
fold,epoch,train_loss: 4 8 1.0902687
fold,epoch,train_loss: 4 9 1.0834469
fold,epoch,train_loss: 4 10 1.0868018
fold,epoch,train_loss: 4 11 1.0855376
fold,epoch,train_loss: 4 12 1.0901558
fold,epoch,train_loss: 4 13 1.0893823
fold,epoch,train_loss: 4 14 1.089079
fold,epoch,train_loss: 4 15 1.0860443
fold,epoch,train_loss: 4 16 1.0851339
fold,epoch,train_loss: 4 17 1.0891526
fold,epoch,train_loss: 4 18 1.0858508
fold,epoch,train_loss: 4 19 1.0929205
fold,epoch,train_loss: 4 20 1.0912697
fold,epoch,train_loss: 4 21 1.0902176
fold,epoch,train_loss: 4 22 1.0936179
fold,epoch,train_loss: 4 23 1.0932533
fold,epoch,train_loss: 4 24 1.0894767
fold,epoch,train_loss: 4 25 1.0908442
fold,epoch,train_loss: 4 26 1.0889406
fold,epoch,train_loss: 4 27 1.0904047
fold,epoch,train_loss: 4 28 1.0896646
fold,epoch,train_loss: 4 29 1.0893852
fold,epoch,train_loss: 4 30 1.0890094
fold,epoch,train_loss: 4 31 1.0877457
fold,epoch,train_loss: 4 32 1.091454
fold,epoch,train_loss: 4 33 1.0884522
fold,epoch,train_loss: 4 34 1.0960902
fold,epoch,train_loss: 4 35 1.0883482
fold,epoch,train_loss: 4 36 1.0889813
fold,epoch,train_loss: 4 37 1.086276
fold,epoch,train_loss: 4 38 1.0883944
fold,epoch,train_loss: 4 39 1.0888757
fold,epoch,train_loss: 4 40 1.0883628
fold,epoch,train_loss: 4 41 1.0896659
fold,epoch,train_loss: 4 42 1.0865821
fold,epoch,train_loss: 4 43 1.0877885
fold,epoch,train_loss: 4 44 1.0933205
fold,epoch,train_loss: 4 45 1.0873796
fold,epoch,train_loss: 4 46 1.0865047
fold,epoch,train_loss: 4 47 1.0935982
fold,epoch,train_loss: 4 48 1.08614
training Epoch: 50, train_Loss: 0.5418
training Epoch: 50, train_Loss: 0.6093
training Epoch: 50, train_Loss: 0.5342
training Epoch: 50, train_Loss: 0.5017
training Epoch: 50, train_Loss: 1.0360
training Epoch: 50, train_Loss: 2.1378
training Epoch: 50, train_Loss: 0.5479
training Epoch: 50, train_Loss: 0.5580
training Epoch: 50, train_Loss: 1.4718
training Epoch: 50, train_Loss: 1.5134
training Epoch: 50, train_Loss: 0.3084
training Epoch: 50, train_Loss: 0.3321
training Epoch: 50, train_Loss: 0.5667
training Epoch: 50, train_Loss: 1.6003
training Epoch: 50, train_Loss: 0.5539
training Epoch: 50, train_Loss: 0.7018
training Epoch: 50, train_Loss: 0.6684
training Epoch: 50, train_Loss: 1.0434
training Epoch: 50, train_Loss: 0.9458
training Epoch: 50, train_Loss: 0.8544
training Epoch: 50, train_Loss: 3.7834
training Epoch: 50, train_Loss: 1.3432
training Epoch: 50, train_Loss: 0.7038
training Epoch: 50, train_Loss: 2.1231
training Epoch: 50, train_Loss: 0.6892
training Epoch: 50, train_Loss: 1.0598
training Epoch: 50, train_Loss: 0.9644
training Epoch: 50, train_Loss: 2.9843
training Epoch: 50, train_Loss: 0.9821
training Epoch: 50, train_Loss: 1.9478
training Epoch: 50, train_Loss: 0.8989
training Epoch: 50, train_Loss: 1.7584
training Epoch: 50, train_Loss: 0.7906
training Epoch: 50, train_Loss: 0.6526
training Epoch: 50, train_Loss: 0.7086
training Epoch: 50, train_Loss: 0.6010
training Epoch: 50, train_Loss: 0.8284
training Epoch: 50, train_Loss: 1.5838
training Epoch: 50, train_Loss: 1.0255
training Epoch: 50, train_Loss: 0.7986
training Epoch: 50, train_Loss: 0.6670
training Epoch: 50, train_Loss: 2.1755
training Epoch: 50, train_Loss: 0.6150
training Epoch: 50, train_Loss: 1.4851
training Epoch: 50, train_Loss: 1.2608
training Epoch: 50, train_Loss: 0.9116
training Epoch: 50, train_Loss: 0.4397
training Epoch: 50, train_Loss: 1.1618
training Epoch: 50, train_Loss: 0.9138
training Epoch: 50, train_Loss: 0.7982
training Epoch: 50, train_Loss: 0.1975
training Epoch: 50, train_Loss: 0.7056
training Epoch: 50, train_Loss: 0.5018
training Epoch: 50, train_Loss: 2.0794
training Epoch: 50, train_Loss: 0.4079
training Epoch: 50, train_Loss: 1.6927
training Epoch: 50, train_Loss: 0.8718
training Epoch: 50, train_Loss: 1.4980
training Epoch: 50, train_Loss: 1.4251
training Epoch: 50, train_Loss: 0.6557
training Epoch: 50, train_Loss: 0.3847
training Epoch: 50, train_Loss: 1.4827
training Epoch: 50, train_Loss: 1.3144
training Epoch: 50, train_Loss: 1.9521
training Epoch: 50, train_Loss: 0.6914
training Epoch: 50, train_Loss: 0.6228
training Epoch: 50, train_Loss: 0.5104
training Epoch: 50, train_Loss: 0.6795
training Epoch: 50, train_Loss: 0.3465
training Epoch: 50, train_Loss: 3.5716
training Epoch: 50, train_Loss: 0.4285
training Epoch: 50, train_Loss: 1.3822
training Epoch: 50, train_Loss: 1.1069
training Epoch: 50, train_Loss: 1.9576
training Epoch: 50, train_Loss: 1.0322
training Epoch: 50, train_Loss: 0.7991
training Epoch: 50, train_Loss: 1.0052
training Epoch: 50, train_Loss: 0.4036
training Epoch: 50, train_Loss: 1.2600
training Epoch: 50, train_Loss: 1.6491
training Epoch: 50, train_Loss: 0.4339
training Epoch: 50, train_Loss: 0.3212
training Epoch: 50, train_Loss: 1.6058
training Epoch: 50, train_Loss: 0.2790
training Epoch: 50, train_Loss: 1.3957
training Epoch: 50, train_Loss: 1.2396
training Epoch: 50, train_Loss: 0.5871
training Epoch: 50, train_Loss: 1.1965
training Epoch: 50, train_Loss: 0.5018
training Epoch: 50, train_Loss: 1.2044
training Epoch: 50, train_Loss: 1.0632
training Epoch: 50, train_Loss: 1.2594
training Epoch: 50, train_Loss: 1.4655
training Epoch: 50, train_Loss: 1.3983
training Epoch: 50, train_Loss: 1.5515
training Epoch: 50, train_Loss: 1.0842
training Epoch: 50, train_Loss: 0.4604
training Epoch: 50, train_Loss: 1.0184
training Epoch: 50, train_Loss: 0.7889
training Epoch: 50, train_Loss: 0.4734
training Epoch: 50, train_Loss: 0.9205
training Epoch: 50, train_Loss: 1.0138
training Epoch: 50, train_Loss: 1.7664
training Epoch: 50, train_Loss: 1.0557
training Epoch: 50, train_Loss: 0.6844
training Epoch: 50, train_Loss: 1.3890
training Epoch: 50, train_Loss: 2.0030
training Epoch: 50, train_Loss: 2.1143
training Epoch: 50, train_Loss: 1.3480
training Epoch: 50, train_Loss: 0.9710
training Epoch: 50, train_Loss: 0.4790
training Epoch: 50, train_Loss: 1.2782
training Epoch: 50, train_Loss: 2.4319
training Epoch: 50, train_Loss: 1.0114
training Epoch: 50, train_Loss: 1.2104
training Epoch: 50, train_Loss: 0.5517
training Epoch: 50, train_Loss: 0.5473
training Epoch: 50, train_Loss: 0.6693
training Epoch: 50, train_Loss: 2.1807
training Epoch: 50, train_Loss: 1.1892
training Epoch: 50, train_Loss: 0.5122
training Epoch: 50, train_Loss: 0.8842
training Epoch: 50, train_Loss: 0.6329
training Epoch: 50, train_Loss: 0.3795
training Epoch: 50, train_Loss: 0.4172
training Epoch: 50, train_Loss: 1.3514
training Epoch: 50, train_Loss: 0.3857
training Epoch: 50, train_Loss: 1.2091
training Epoch: 50, train_Loss: 0.6458
training Epoch: 50, train_Loss: 0.4890
training Epoch: 50, train_Loss: 2.9865
training Epoch: 50, train_Loss: 1.4709
training Epoch: 50, train_Loss: 0.2869
training Epoch: 50, train_Loss: 1.1529
training Epoch: 50, train_Loss: 0.4085
training Epoch: 50, train_Loss: 0.7023
training Epoch: 50, train_Loss: 1.4047
training Epoch: 50, train_Loss: 0.7340
training Epoch: 50, train_Loss: 0.3856
training Epoch: 50, train_Loss: 1.2595
training Epoch: 50, train_Loss: 0.3187
training Epoch: 50, train_Loss: 0.6011
training Epoch: 50, train_Loss: 0.6733
training Epoch: 50, train_Loss: 2.8625
training Epoch: 50, train_Loss: 0.5223
training Epoch: 50, train_Loss: 2.1355
training Epoch: 50, train_Loss: 0.7171
training Epoch: 50, train_Loss: 0.5615
training Epoch: 50, train_Loss: 0.5515
training Epoch: 50, train_Loss: 1.5461
training Epoch: 50, train_Loss: 1.9898
training Epoch: 50, train_Loss: 0.8519
training Epoch: 50, train_Loss: 0.5503
training Epoch: 50, train_Loss: 0.9455
training Epoch: 50, train_Loss: 1.1570
training Epoch: 50, train_Loss: 0.4885
training Epoch: 50, train_Loss: 1.0864
training Epoch: 50, train_Loss: 1.0176
training Epoch: 50, train_Loss: 0.3347
training Epoch: 50, train_Loss: 1.1039
training Epoch: 50, train_Loss: 1.0414
training Epoch: 50, train_Loss: 0.2920
training Epoch: 50, train_Loss: 0.2258
training Epoch: 50, train_Loss: 1.2809
training Epoch: 50, train_Loss: 2.0215
training Epoch: 50, train_Loss: 0.1709
training Epoch: 50, train_Loss: 2.2859
training Epoch: 50, train_Loss: 0.1314
training Epoch: 50, train_Loss: 1.1399
training Epoch: 50, train_Loss: 0.4447
training Epoch: 50, train_Loss: 2.3421
training Epoch: 50, train_Loss: 2.7036
training Epoch: 50, train_Loss: 0.4914
training Epoch: 50, train_Loss: 0.5521
training Epoch: 50, train_Loss: 0.8393
training Epoch: 50, train_Loss: 1.3747
training Epoch: 50, train_Loss: 0.2707
training Epoch: 50, train_Loss: 1.8040
training Epoch: 50, train_Loss: 0.6406
training Epoch: 50, train_Loss: 2.3462
training Epoch: 50, train_Loss: 1.3650
training Epoch: 50, train_Loss: 1.0360
training Epoch: 50, train_Loss: 0.4409
training Epoch: 50, train_Loss: 1.6568
training Epoch: 50, train_Loss: 2.6546
training Epoch: 50, train_Loss: 0.7828
training Epoch: 50, train_Loss: 1.9795
training Epoch: 50, train_Loss: 1.0704
training Epoch: 50, train_Loss: 1.6378
training Epoch: 50, train_Loss: 0.8422
training Epoch: 50, train_Loss: 0.6553
training Epoch: 50, train_Loss: 1.9564
training Epoch: 50, train_Loss: 0.9687
training Epoch: 50, train_Loss: 0.7155
training Epoch: 50, train_Loss: 0.7465
training Epoch: 50, train_Loss: 1.7285
training Epoch: 50, train_Loss: 0.5654
training Epoch: 50, train_Loss: 1.8063
training Epoch: 50, train_Loss: 0.2980
training Epoch: 50, train_Loss: 1.3786
training Epoch: 50, train_Loss: 1.0132
training Epoch: 50, train_Loss: 1.3787
training Epoch: 50, train_Loss: 0.3820
training Epoch: 50, train_Loss: 2.0071
training Epoch: 50, train_Loss: 1.4512
training Epoch: 50, train_Loss: 1.2922
training Epoch: 50, train_Loss: 0.8599
training Epoch: 50, train_Loss: 0.3888
training Epoch: 50, train_Loss: 1.7667
training Epoch: 50, train_Loss: 1.9078
training Epoch: 50, train_Loss: 1.7622
training Epoch: 50, train_Loss: 0.4509
training Epoch: 50, train_Loss: 1.5665
training Epoch: 50, train_Loss: 1.1061
training Epoch: 50, train_Loss: 1.2851
training Epoch: 50, train_Loss: 0.8042
training Epoch: 50, train_Loss: 0.9473
training Epoch: 50, train_Loss: 0.9435
training Epoch: 50, train_Loss: 0.7281
training Epoch: 50, train_Loss: 0.5735
training Epoch: 50, train_Loss: 0.6639
training Epoch: 50, train_Loss: 1.1584
training Epoch: 50, train_Loss: 1.9734
training Epoch: 50, train_Loss: 1.0605
training Epoch: 50, train_Loss: 0.9406
training Epoch: 50, train_Loss: 0.4705
training Epoch: 50, train_Loss: 0.4012
training Epoch: 50, train_Loss: 1.2829
training Epoch: 50, train_Loss: 0.4932
training Epoch: 50, train_Loss: 0.5285
training Epoch: 50, train_Loss: 0.9963
training Epoch: 50, train_Loss: 1.1030
training Epoch: 50, train_Loss: 0.8927
training Epoch: 50, train_Loss: 0.8404
training Epoch: 50, train_Loss: 1.7864
training Epoch: 50, train_Loss: 0.5902
training Epoch: 50, train_Loss: 0.9126
training Epoch: 50, train_Loss: 2.1338
training Epoch: 50, train_Loss: 0.3171
training Epoch: 50, train_Loss: 1.3568
training Epoch: 50, train_Loss: 0.5166
training Epoch: 50, train_Loss: 0.9940
training Epoch: 50, train_Loss: 0.5153
training Epoch: 50, train_Loss: 0.8622
training Epoch: 50, train_Loss: 1.5011
training Epoch: 50, train_Loss: 1.9524
training Epoch: 50, train_Loss: 1.1721
training Epoch: 50, train_Loss: 1.0711
training Epoch: 50, train_Loss: 0.6928
training Epoch: 50, train_Loss: 0.6797
training Epoch: 50, train_Loss: 0.4900
training Epoch: 50, train_Loss: 0.6667
training Epoch: 50, train_Loss: 1.2340
training Epoch: 50, train_Loss: 1.1342
training Epoch: 50, train_Loss: 2.2696
training Epoch: 50, train_Loss: 1.3080
training Epoch: 50, train_Loss: 0.5808
training Epoch: 50, train_Loss: 0.8898
training Epoch: 50, train_Loss: 1.1633
training Epoch: 50, train_Loss: 0.9942
training Epoch: 50, train_Loss: 1.4404
training Epoch: 50, train_Loss: 1.2356
training Epoch: 50, train_Loss: 1.6516
training Epoch: 50, train_Loss: 0.9279
training Epoch: 50, train_Loss: 1.1296
training Epoch: 50, train_Loss: 0.9610
training Epoch: 50, train_Loss: 0.9843
training Epoch: 50, train_Loss: 0.4151
training Epoch: 50, train_Loss: 0.4952
training Epoch: 50, train_Loss: 1.0344
training Epoch: 50, train_Loss: 1.2925
training Epoch: 50, train_Loss: 1.8479
training Epoch: 50, train_Loss: 0.9145
training Epoch: 50, train_Loss: 0.7133
training Epoch: 50, train_Loss: 0.6212
training Epoch: 50, train_Loss: 2.7045
training Epoch: 50, train_Loss: 1.0713
training Epoch: 50, train_Loss: 0.5575
training Epoch: 50, train_Loss: 1.1990
training Epoch: 50, train_Loss: 2.6531
training Epoch: 50, train_Loss: 1.4995
training Epoch: 50, train_Loss: 0.7141
training Epoch: 50, train_Loss: 0.2337
training Epoch: 50, train_Loss: 0.5063
training Epoch: 50, train_Loss: 0.2673
training Epoch: 50, train_Loss: 1.6468
training Epoch: 50, train_Loss: 0.9721
training Epoch: 50, train_Loss: 0.7024
training Epoch: 50, train_Loss: 0.3372
training Epoch: 50, train_Loss: 0.6141
training Epoch: 50, train_Loss: 0.7083
training Epoch: 50, train_Loss: 1.2213
training Epoch: 50, train_Loss: 1.6411
training Epoch: 50, train_Loss: 0.4630
training Epoch: 50, train_Loss: 0.8037
training Epoch: 50, train_Loss: 1.1232
training Epoch: 50, train_Loss: 1.5378
training Epoch: 50, train_Loss: 0.5558
training Epoch: 50, train_Loss: 2.0205
training Epoch: 50, train_Loss: 0.2959
training Epoch: 50, train_Loss: 0.4631
training Epoch: 50, train_Loss: 0.7438
training Epoch: 50, train_Loss: 0.2859
training Epoch: 50, train_Loss: 1.6912
training Epoch: 50, train_Loss: 3.0064
training Epoch: 50, train_Loss: 1.8830
training Epoch: 50, train_Loss: 0.8949
training Epoch: 50, train_Loss: 3.4801
training Epoch: 50, train_Loss: 1.3692
training Epoch: 50, train_Loss: 0.5448
training Epoch: 50, train_Loss: 1.7897
training Epoch: 50, train_Loss: 1.5759
training Epoch: 50, train_Loss: 2.0698
training Epoch: 50, train_Loss: 1.1984
training Epoch: 50, train_Loss: 0.5557
training Epoch: 50, train_Loss: 1.3923
training Epoch: 50, train_Loss: 1.5139
training Epoch: 50, train_Loss: 0.6704
training Epoch: 50, train_Loss: 0.6790
training Epoch: 50, train_Loss: 0.6382
training Epoch: 50, train_Loss: 0.6039
training Epoch: 50, train_Loss: 0.5932
training Epoch: 50, train_Loss: 1.9709
training Epoch: 50, train_Loss: 0.6951
training Epoch: 50, train_Loss: 1.2916
training Epoch: 50, train_Loss: 1.0132
training Epoch: 50, train_Loss: 1.0919
training Epoch: 50, train_Loss: 0.6932
training Epoch: 50, train_Loss: 0.8146
training Epoch: 50, train_Loss: 0.6610
training Epoch: 50, train_Loss: 0.5025
training Epoch: 50, train_Loss: 0.2675
training Epoch: 50, train_Loss: 0.7478
training Epoch: 50, train_Loss: 0.8300
training Epoch: 50, train_Loss: 2.6652
training Epoch: 50, train_Loss: 0.5300
training Epoch: 50, train_Loss: 2.3576
training Epoch: 50, train_Loss: 1.8997
training Epoch: 50, train_Loss: 3.9555
training Epoch: 50, train_Loss: 0.8773
training Epoch: 50, train_Loss: 0.9444
training Epoch: 50, train_Loss: 0.8652
training Epoch: 50, train_Loss: 0.3450
training Epoch: 50, train_Loss: 0.3948
training Epoch: 50, train_Loss: 0.8094
training Epoch: 50, train_Loss: 0.6421
training Epoch: 50, train_Loss: 0.4545
training Epoch: 50, train_Loss: 0.7411
training Epoch: 50, train_Loss: 1.1838
training Epoch: 50, train_Loss: 0.8962
training Epoch: 50, train_Loss: 0.7288
training Epoch: 50, train_Loss: 0.6884
training Epoch: 50, train_Loss: 2.4268
training Epoch: 50, train_Loss: 1.1492
training Epoch: 50, train_Loss: 0.7484
training Epoch: 50, train_Loss: 0.4308
training Epoch: 50, train_Loss: 0.6409
training Epoch: 50, train_Loss: 1.1304
training Epoch: 50, train_Loss: 0.4644
training Epoch: 50, train_Loss: 0.3986
training Epoch: 50, train_Loss: 0.5314
training Epoch: 50, train_Loss: 0.5870
training Epoch: 50, train_Loss: 2.2304
training Epoch: 50, train_Loss: 1.0948
training Epoch: 50, train_Loss: 0.3923
training Epoch: 50, train_Loss: 0.2728
training Epoch: 50, train_Loss: 1.0199
training Epoch: 50, train_Loss: 1.1657
training Epoch: 50, train_Loss: 0.7813
training Epoch: 50, train_Loss: 1.5504
training Epoch: 50, train_Loss: 0.8116
training Epoch: 50, train_Loss: 0.5870
training Epoch: 50, train_Loss: 0.9739
training Epoch: 50, train_Loss: 0.2879
training Epoch: 50, train_Loss: 0.3190
training Epoch: 50, train_Loss: 1.8084
training Epoch: 50, train_Loss: 0.8619
training Epoch: 50, train_Loss: 0.5424
training Epoch: 50, train_Loss: 0.6044
training Epoch: 50, train_Loss: 1.1557
training Epoch: 50, train_Loss: 1.5227
training Epoch: 50, train_Loss: 1.4566
training Epoch: 50, train_Loss: 0.2685
training Epoch: 50, train_Loss: 0.6164
training Epoch: 50, train_Loss: 3.5731
training Epoch: 50, train_Loss: 1.2042
training Epoch: 50, train_Loss: 1.5647
training Epoch: 50, train_Loss: 0.9544
training Epoch: 50, train_Loss: 0.9980
training Epoch: 50, train_Loss: 0.6025
training Epoch: 50, train_Loss: 0.9811
training Epoch: 50, train_Loss: 0.3626
training Epoch: 50, train_Loss: 0.6692
training Epoch: 50, train_Loss: 1.0546
training Epoch: 50, train_Loss: 1.5643
training Epoch: 50, train_Loss: 0.4075
training Epoch: 50, train_Loss: 0.6458
training Epoch: 50, train_Loss: 0.5918
training Epoch: 50, train_Loss: 0.6772
training Epoch: 50, train_Loss: 1.6662
training Epoch: 50, train_Loss: 2.5560
training Epoch: 50, train_Loss: 0.4391
training Epoch: 50, train_Loss: 0.8906
training Epoch: 50, train_Loss: 0.6100
training Epoch: 50, train_Loss: 0.8668
training Epoch: 50, train_Loss: 0.7351
training Epoch: 50, train_Loss: 0.5174
training Epoch: 50, train_Loss: 0.5976
training Epoch: 50, train_Loss: 2.5512
training Epoch: 50, train_Loss: 0.4927
training Epoch: 50, train_Loss: 0.3097
training Epoch: 50, train_Loss: 0.4694
training Epoch: 50, train_Loss: 0.8105
training Epoch: 50, train_Loss: 0.7022
training Epoch: 50, train_Loss: 1.4814
training Epoch: 50, train_Loss: 2.6973
training Epoch: 50, train_Loss: 0.6719
training Epoch: 50, train_Loss: 1.6307
training Epoch: 50, train_Loss: 2.2092
training Epoch: 50, train_Loss: 1.9526
training Epoch: 50, train_Loss: 0.7556
training Epoch: 50, train_Loss: 0.5949
training Epoch: 50, train_Loss: 2.1886
training Epoch: 50, train_Loss: 0.8779
training Epoch: 50, train_Loss: 0.7743
training Epoch: 50, train_Loss: 0.9460
training Epoch: 50, train_Loss: 1.2462
training Epoch: 50, train_Loss: 2.7280
training Epoch: 50, train_Loss: 0.5343
training Epoch: 50, train_Loss: 1.6316
training Epoch: 50, train_Loss: 1.1766
training Epoch: 50, train_Loss: 2.0224
training Epoch: 50, train_Loss: 1.1109
training Epoch: 50, train_Loss: 0.8000
training Epoch: 50, train_Loss: 0.9544
training Epoch: 50, train_Loss: 0.4261
training Epoch: 50, train_Loss: 0.9128
training Epoch: 50, train_Loss: 1.9184
training Epoch: 50, train_Loss: 0.8500
training Epoch: 50, train_Loss: 2.3318
training Epoch: 50, train_Loss: 1.0843
training Epoch: 50, train_Loss: 1.0556
training Epoch: 50, train_Loss: 0.4397
training Epoch: 50, train_Loss: 1.1531
training Epoch: 50, train_Loss: 0.6102
training Epoch: 50, train_Loss: 0.4181
training Epoch: 50, train_Loss: 0.6396
training Epoch: 50, train_Loss: 0.7992
training Epoch: 50, train_Loss: 1.2595
training Epoch: 50, train_Loss: 0.7025
training Epoch: 50, train_Loss: 1.8553
training Epoch: 50, train_Loss: 1.0664
training Epoch: 50, train_Loss: 2.8040
training Epoch: 50, train_Loss: 0.3938
training Epoch: 50, train_Loss: 0.8144
training Epoch: 50, train_Loss: 1.1551
training Epoch: 50, train_Loss: 0.7054
training Epoch: 50, train_Loss: 0.5885
training Epoch: 50, train_Loss: 0.6468
training Epoch: 50, train_Loss: 0.9021
training Epoch: 50, train_Loss: 2.2182
training Epoch: 50, train_Loss: 1.4805
training Epoch: 50, train_Loss: 1.0578
training Epoch: 50, train_Loss: 0.8591
training Epoch: 50, train_Loss: 1.0481
training Epoch: 50, train_Loss: 1.0814
training Epoch: 50, train_Loss: 0.6629
training Epoch: 50, train_Loss: 0.6191
training Epoch: 50, train_Loss: 1.2681
training Epoch: 50, train_Loss: 0.5122
training Epoch: 50, train_Loss: 0.4669
training Epoch: 50, train_Loss: 0.5319
training Epoch: 50, train_Loss: 0.5262
training Epoch: 50, train_Loss: 0.7567
training Epoch: 50, train_Loss: 0.4632
training Epoch: 50, train_Loss: 1.7986
training Epoch: 50, train_Loss: 1.0385
training Epoch: 50, train_Loss: 2.4476
training Epoch: 50, train_Loss: 0.6662
training Epoch: 50, train_Loss: 1.5855
training Epoch: 50, train_Loss: 1.3413
training Epoch: 50, train_Loss: 0.2331
training Epoch: 50, train_Loss: 0.4539
training Epoch: 50, train_Loss: 1.7355
training Epoch: 50, train_Loss: 1.6293
training Epoch: 50, train_Loss: 2.2699
training Epoch: 50, train_Loss: 0.8255
training Epoch: 50, train_Loss: 1.5933
training Epoch: 50, train_Loss: 0.8175
training Epoch: 50, train_Loss: 1.0169
training Epoch: 50, train_Loss: 0.8373
training Epoch: 50, train_Loss: 0.7789
training Epoch: 50, train_Loss: 2.0985
training Epoch: 50, train_Loss: 1.2820
training Epoch: 50, train_Loss: 0.4280
training Epoch: 50, train_Loss: 1.0231
training Epoch: 50, train_Loss: 0.9999
training Epoch: 50, train_Loss: 0.6228
training Epoch: 50, train_Loss: 0.7910
training Epoch: 50, train_Loss: 0.8283
training Epoch: 50, train_Loss: 0.4091
training Epoch: 50, train_Loss: 1.3362
training Epoch: 50, train_Loss: 1.4152
training Epoch: 50, train_Loss: 2.1874
training Epoch: 50, train_Loss: 2.2026
training Epoch: 50, train_Loss: 0.8517
training Epoch: 50, train_Loss: 1.2086
training Epoch: 50, train_Loss: 0.6622
training Epoch: 50, train_Loss: 2.2955
training Epoch: 50, train_Loss: 1.5652
training Epoch: 50, train_Loss: 1.3324
training Epoch: 50, train_Loss: 1.0308
training Epoch: 50, train_Loss: 1.0913
training Epoch: 50, train_Loss: 0.4573
training Epoch: 50, train_Loss: 1.8570
training Epoch: 50, train_Loss: 0.6143
training Epoch: 50, train_Loss: 1.7058
training Epoch: 50, train_Loss: 2.0558
training Epoch: 50, train_Loss: 0.7667
training Epoch: 50, train_Loss: 1.3147
training Epoch: 50, train_Loss: 0.9209
training Epoch: 50, train_Loss: 1.7966
training Epoch: 50, train_Loss: 0.8537
training Epoch: 50, train_Loss: 1.0417
training Epoch: 50, train_Loss: 0.8514
training Epoch: 50, train_Loss: 0.7095
training Epoch: 50, train_Loss: 0.5941
training Epoch: 50, train_Loss: 1.1228
training Epoch: 50, train_Loss: 1.0704
training Epoch: 50, train_Loss: 0.8260
training Epoch: 50, train_Loss: 0.9376
training Epoch: 50, train_Loss: 3.5595
training Epoch: 50, train_Loss: 1.8390
training Epoch: 50, train_Loss: 1.0323
training Epoch: 50, train_Loss: 1.1944
training Epoch: 50, train_Loss: 0.2650
training Epoch: 50, train_Loss: 1.5274
training Epoch: 50, train_Loss: 0.3467
training Epoch: 50, train_Loss: 3.3617
training Epoch: 50, train_Loss: 1.2716
training Epoch: 50, train_Loss: 1.5709
training Epoch: 50, train_Loss: 3.6637
training Epoch: 50, train_Loss: 1.6816
training Epoch: 50, train_Loss: 0.8199
training Epoch: 50, train_Loss: 0.6470
training Epoch: 50, train_Loss: 0.7037
training Epoch: 50, train_Loss: 1.3061
training Epoch: 50, train_Loss: 0.8816
training Epoch: 50, train_Loss: 4.1317
training Epoch: 50, train_Loss: 2.1388
training Epoch: 50, train_Loss: 1.0430
training Epoch: 50, train_Loss: 1.2874
training Epoch: 50, train_Loss: 0.8228
training Epoch: 50, train_Loss: 0.8763
training Epoch: 50, train_Loss: 0.9964
training Epoch: 50, train_Loss: 1.0527
training Epoch: 50, train_Loss: 0.5559
training Epoch: 50, train_Loss: 0.5979
training Epoch: 50, train_Loss: 0.7495
training Epoch: 50, train_Loss: 0.4502
training Epoch: 50, train_Loss: 1.2581
training Epoch: 50, train_Loss: 0.7165
training Epoch: 50, train_Loss: 0.5141
training Epoch: 50, train_Loss: 1.5381
training Epoch: 50, train_Loss: 0.8740
training Epoch: 50, train_Loss: 1.0649
training Epoch: 50, train_Loss: 0.4332
training Epoch: 50, train_Loss: 1.1346
training Epoch: 50, train_Loss: 0.4466
training Epoch: 50, train_Loss: 0.7449
training Epoch: 50, train_Loss: 1.1372
training Epoch: 50, train_Loss: 1.8962
training Epoch: 50, train_Loss: 1.5223
training Epoch: 50, train_Loss: 1.9857
training Epoch: 50, train_Loss: 0.3311
fold,epoch,train_loss: 4 49 1.0923952
fold,epoch,train_loss: 4 50 1.0888726
fold,epoch,train_loss: 4 51 1.0932205
fold,epoch,train_loss: 4 52 1.0924565
fold,epoch,train_loss: 4 53 1.0901089
fold,epoch,train_loss: 4 54 1.085534
fold,epoch,train_loss: 4 55 1.0951416
fold,epoch,train_loss: 4 56 1.0862166
fold,epoch,train_loss: 4 57 1.0947009
fold,epoch,train_loss: 4 58 1.0869076
fold,epoch,train_loss: 4 59 1.0855968
fold,epoch,train_loss: 4 60 1.0857679
fold,epoch,train_loss: 4 61 1.0906284
fold,epoch,train_loss: 4 62 1.0859728
fold,epoch,train_loss: 4 63 1.0896704
fold,epoch,train_loss: 4 64 1.0879362
fold,epoch,train_loss: 4 65 1.0869098
fold,epoch,train_loss: 4 66 1.0881032
fold,epoch,train_loss: 4 67 1.0915723
fold,epoch,train_loss: 4 68 1.0860823
fold,epoch,train_loss: 4 69 1.0917331
fold,epoch,train_loss: 4 70 1.0883509
fold,epoch,train_loss: 4 71 1.0886236
fold,epoch,train_loss: 4 72 1.0894734
fold,epoch,train_loss: 4 73 1.0943899
fold,epoch,train_loss: 4 74 1.0845715
fold,epoch,train_loss: 4 75 1.0878307
fold,epoch,train_loss: 4 76 1.0922879
fold,epoch,train_loss: 4 77 1.0931203
fold,epoch,train_loss: 4 78 1.0893075
fold,epoch,train_loss: 4 79 1.0880649
fold,epoch,train_loss: 4 80 1.083139
fold,epoch,train_loss: 4 81 1.0887696
fold,epoch,train_loss: 4 82 1.0886062
fold,epoch,train_loss: 4 83 1.0948076
fold,epoch,train_loss: 4 84 1.0925752
fold,epoch,train_loss: 4 85 1.0878088
fold,epoch,train_loss: 4 86 1.0925858
fold,epoch,train_loss: 4 87 1.0950556
fold,epoch,train_loss: 4 88 1.08575
fold,epoch,train_loss: 4 89 1.0911419
fold,epoch,train_loss: 4 90 1.0865588
fold,epoch,train_loss: 4 91 1.0936162
fold,epoch,train_loss: 4 92 1.0897244
fold,epoch,train_loss: 4 93 1.0886209
fold,epoch,train_loss: 4 94 1.0971025
fold,epoch,train_loss: 4 95 1.0864391
fold,epoch,train_loss: 4 96 1.0899022
fold,epoch,train_loss: 4 97 1.0886078
fold,epoch,train_loss: 4 98 1.0913295
training Epoch: 100, train_Loss: 0.2650
training Epoch: 100, train_Loss: 0.3706
training Epoch: 100, train_Loss: 0.5779
training Epoch: 100, train_Loss: 0.4009
training Epoch: 100, train_Loss: 1.3890
training Epoch: 100, train_Loss: 0.4115
training Epoch: 100, train_Loss: 0.3315
training Epoch: 100, train_Loss: 3.3196
training Epoch: 100, train_Loss: 0.6853
training Epoch: 100, train_Loss: 1.6115
training Epoch: 100, train_Loss: 0.5528
training Epoch: 100, train_Loss: 0.7975
training Epoch: 100, train_Loss: 0.4955
training Epoch: 100, train_Loss: 0.8253
training Epoch: 100, train_Loss: 0.5754
training Epoch: 100, train_Loss: 0.6319
training Epoch: 100, train_Loss: 0.3954
training Epoch: 100, train_Loss: 3.0106
training Epoch: 100, train_Loss: 1.7739
training Epoch: 100, train_Loss: 0.6060
training Epoch: 100, train_Loss: 1.8424
training Epoch: 100, train_Loss: 1.0799
training Epoch: 100, train_Loss: 0.3569
training Epoch: 100, train_Loss: 1.3059
training Epoch: 100, train_Loss: 0.3693
training Epoch: 100, train_Loss: 0.9615
training Epoch: 100, train_Loss: 0.5737
training Epoch: 100, train_Loss: 0.9485
training Epoch: 100, train_Loss: 1.7698
training Epoch: 100, train_Loss: 1.4623
training Epoch: 100, train_Loss: 1.4564
training Epoch: 100, train_Loss: 0.8358
training Epoch: 100, train_Loss: 0.5745
training Epoch: 100, train_Loss: 0.4456
training Epoch: 100, train_Loss: 0.8964
training Epoch: 100, train_Loss: 0.7922
training Epoch: 100, train_Loss: 1.8770
training Epoch: 100, train_Loss: 0.9941
training Epoch: 100, train_Loss: 0.4881
training Epoch: 100, train_Loss: 2.2064
training Epoch: 100, train_Loss: 1.8141
training Epoch: 100, train_Loss: 0.8526
training Epoch: 100, train_Loss: 0.3719
training Epoch: 100, train_Loss: 0.8315
training Epoch: 100, train_Loss: 0.5806
training Epoch: 100, train_Loss: 1.4469
training Epoch: 100, train_Loss: 0.7723
training Epoch: 100, train_Loss: 0.7783
training Epoch: 100, train_Loss: 1.5261
training Epoch: 100, train_Loss: 0.3559
training Epoch: 100, train_Loss: 1.0342
training Epoch: 100, train_Loss: 0.5165
training Epoch: 100, train_Loss: 1.5913
training Epoch: 100, train_Loss: 2.5085
training Epoch: 100, train_Loss: 0.7617
training Epoch: 100, train_Loss: 0.3927
training Epoch: 100, train_Loss: 1.5593
training Epoch: 100, train_Loss: 0.3935
training Epoch: 100, train_Loss: 1.3882
training Epoch: 100, train_Loss: 1.3983
training Epoch: 100, train_Loss: 0.5905
training Epoch: 100, train_Loss: 1.1942
training Epoch: 100, train_Loss: 0.7677
training Epoch: 100, train_Loss: 1.4457
training Epoch: 100, train_Loss: 0.7394
training Epoch: 100, train_Loss: 1.0246
training Epoch: 100, train_Loss: 0.5057
training Epoch: 100, train_Loss: 0.7182
training Epoch: 100, train_Loss: 0.8308
training Epoch: 100, train_Loss: 0.5746
training Epoch: 100, train_Loss: 0.7580
training Epoch: 100, train_Loss: 0.8112
training Epoch: 100, train_Loss: 0.4283
training Epoch: 100, train_Loss: 0.2780
training Epoch: 100, train_Loss: 1.0717
training Epoch: 100, train_Loss: 0.2944
training Epoch: 100, train_Loss: 0.4884
training Epoch: 100, train_Loss: 2.8382
training Epoch: 100, train_Loss: 1.4130
training Epoch: 100, train_Loss: 0.8567
training Epoch: 100, train_Loss: 0.5125
training Epoch: 100, train_Loss: 1.4443
training Epoch: 100, train_Loss: 1.8913
training Epoch: 100, train_Loss: 1.3329
training Epoch: 100, train_Loss: 0.9004
training Epoch: 100, train_Loss: 0.4001
training Epoch: 100, train_Loss: 1.2007
training Epoch: 100, train_Loss: 2.5329
training Epoch: 100, train_Loss: 0.8715
training Epoch: 100, train_Loss: 0.7249
training Epoch: 100, train_Loss: 1.1802
training Epoch: 100, train_Loss: 1.5942
training Epoch: 100, train_Loss: 1.8852
training Epoch: 100, train_Loss: 1.8441
training Epoch: 100, train_Loss: 1.4859
training Epoch: 100, train_Loss: 1.1868
training Epoch: 100, train_Loss: 1.1795
training Epoch: 100, train_Loss: 0.5558
training Epoch: 100, train_Loss: 0.8048
training Epoch: 100, train_Loss: 0.6299
training Epoch: 100, train_Loss: 1.6137
training Epoch: 100, train_Loss: 1.1153
training Epoch: 100, train_Loss: 0.7204
training Epoch: 100, train_Loss: 0.5569
training Epoch: 100, train_Loss: 0.9205
training Epoch: 100, train_Loss: 0.6746
training Epoch: 100, train_Loss: 1.6348
training Epoch: 100, train_Loss: 0.8914
training Epoch: 100, train_Loss: 2.0237
training Epoch: 100, train_Loss: 1.3530
training Epoch: 100, train_Loss: 0.6906
training Epoch: 100, train_Loss: 1.9967
training Epoch: 100, train_Loss: 0.2707
training Epoch: 100, train_Loss: 1.3132
training Epoch: 100, train_Loss: 0.2888
training Epoch: 100, train_Loss: 0.5266
training Epoch: 100, train_Loss: 1.2159
training Epoch: 100, train_Loss: 1.9910
training Epoch: 100, train_Loss: 2.9803
training Epoch: 100, train_Loss: 0.5621
training Epoch: 100, train_Loss: 0.9393
training Epoch: 100, train_Loss: 0.8845
training Epoch: 100, train_Loss: 0.9673
training Epoch: 100, train_Loss: 4.4289
training Epoch: 100, train_Loss: 1.7518
training Epoch: 100, train_Loss: 0.5030
training Epoch: 100, train_Loss: 0.4883
training Epoch: 100, train_Loss: 0.8759
training Epoch: 100, train_Loss: 1.5978
training Epoch: 100, train_Loss: 1.1321
training Epoch: 100, train_Loss: 0.8004
training Epoch: 100, train_Loss: 0.7649
training Epoch: 100, train_Loss: 1.7430
training Epoch: 100, train_Loss: 0.7993
training Epoch: 100, train_Loss: 2.3606
training Epoch: 100, train_Loss: 1.7613
training Epoch: 100, train_Loss: 1.2248
training Epoch: 100, train_Loss: 1.2757
training Epoch: 100, train_Loss: 0.9651
training Epoch: 100, train_Loss: 1.1477
training Epoch: 100, train_Loss: 0.6292
training Epoch: 100, train_Loss: 1.2166
training Epoch: 100, train_Loss: 0.7399
training Epoch: 100, train_Loss: 2.0445
training Epoch: 100, train_Loss: 2.3055
training Epoch: 100, train_Loss: 0.5478
training Epoch: 100, train_Loss: 0.7945
training Epoch: 100, train_Loss: 0.6784
training Epoch: 100, train_Loss: 0.4509
training Epoch: 100, train_Loss: 1.2183
training Epoch: 100, train_Loss: 0.7708
training Epoch: 100, train_Loss: 3.8763
training Epoch: 100, train_Loss: 0.6672
training Epoch: 100, train_Loss: 0.4165
training Epoch: 100, train_Loss: 3.6704
training Epoch: 100, train_Loss: 0.3427
training Epoch: 100, train_Loss: 0.8030
training Epoch: 100, train_Loss: 0.8601
training Epoch: 100, train_Loss: 0.5626
training Epoch: 100, train_Loss: 0.8310
training Epoch: 100, train_Loss: 0.7090
training Epoch: 100, train_Loss: 0.2784
training Epoch: 100, train_Loss: 0.3520
training Epoch: 100, train_Loss: 0.3332
training Epoch: 100, train_Loss: 1.6373
training Epoch: 100, train_Loss: 0.6641
training Epoch: 100, train_Loss: 0.4911
training Epoch: 100, train_Loss: 0.7237
training Epoch: 100, train_Loss: 0.3011
training Epoch: 100, train_Loss: 1.0460
training Epoch: 100, train_Loss: 1.2871
training Epoch: 100, train_Loss: 1.3571
training Epoch: 100, train_Loss: 2.0676
training Epoch: 100, train_Loss: 2.2693
training Epoch: 100, train_Loss: 1.1827
training Epoch: 100, train_Loss: 2.5173
training Epoch: 100, train_Loss: 1.2078
training Epoch: 100, train_Loss: 1.1173
training Epoch: 100, train_Loss: 1.1012
training Epoch: 100, train_Loss: 1.7230
training Epoch: 100, train_Loss: 1.2326
training Epoch: 100, train_Loss: 1.5821
training Epoch: 100, train_Loss: 0.7416
training Epoch: 100, train_Loss: 0.7135
training Epoch: 100, train_Loss: 1.2756
training Epoch: 100, train_Loss: 0.4881
training Epoch: 100, train_Loss: 0.8535
training Epoch: 100, train_Loss: 0.9814
training Epoch: 100, train_Loss: 1.0883
training Epoch: 100, train_Loss: 1.9419
training Epoch: 100, train_Loss: 0.6153
training Epoch: 100, train_Loss: 0.7182
training Epoch: 100, train_Loss: 1.4442
training Epoch: 100, train_Loss: 1.4854
training Epoch: 100, train_Loss: 2.1309
training Epoch: 100, train_Loss: 0.7056
training Epoch: 100, train_Loss: 0.5121
training Epoch: 100, train_Loss: 0.9118
training Epoch: 100, train_Loss: 1.3388
training Epoch: 100, train_Loss: 1.2064
training Epoch: 100, train_Loss: 0.6465
training Epoch: 100, train_Loss: 1.0067
training Epoch: 100, train_Loss: 0.3965
training Epoch: 100, train_Loss: 0.4393
training Epoch: 100, train_Loss: 0.5581
training Epoch: 100, train_Loss: 2.0575
training Epoch: 100, train_Loss: 0.2737
training Epoch: 100, train_Loss: 0.5288
training Epoch: 100, train_Loss: 1.1747
training Epoch: 100, train_Loss: 0.4493
training Epoch: 100, train_Loss: 0.2608
training Epoch: 100, train_Loss: 1.8809
training Epoch: 100, train_Loss: 0.7060
training Epoch: 100, train_Loss: 1.3700
training Epoch: 100, train_Loss: 0.4999
training Epoch: 100, train_Loss: 0.4719
training Epoch: 100, train_Loss: 0.7720
training Epoch: 100, train_Loss: 0.3023
training Epoch: 100, train_Loss: 1.7737
training Epoch: 100, train_Loss: 0.5620
training Epoch: 100, train_Loss: 0.4367
training Epoch: 100, train_Loss: 1.4913
training Epoch: 100, train_Loss: 0.4587
training Epoch: 100, train_Loss: 0.6161
training Epoch: 100, train_Loss: 1.2789
training Epoch: 100, train_Loss: 1.6463
training Epoch: 100, train_Loss: 0.5138
training Epoch: 100, train_Loss: 0.5546
training Epoch: 100, train_Loss: 1.2666
training Epoch: 100, train_Loss: 0.9474
training Epoch: 100, train_Loss: 1.2945
training Epoch: 100, train_Loss: 0.8740
training Epoch: 100, train_Loss: 0.4664
training Epoch: 100, train_Loss: 1.4377
training Epoch: 100, train_Loss: 1.8274
training Epoch: 100, train_Loss: 1.9496
training Epoch: 100, train_Loss: 0.5116
training Epoch: 100, train_Loss: 0.4546
training Epoch: 100, train_Loss: 0.4630
training Epoch: 100, train_Loss: 1.1277
training Epoch: 100, train_Loss: 0.5391
training Epoch: 100, train_Loss: 0.8844
training Epoch: 100, train_Loss: 0.5826
training Epoch: 100, train_Loss: 1.0669
training Epoch: 100, train_Loss: 2.6792
training Epoch: 100, train_Loss: 0.9583
training Epoch: 100, train_Loss: 0.4196
training Epoch: 100, train_Loss: 2.0885
training Epoch: 100, train_Loss: 1.7293
training Epoch: 100, train_Loss: 0.4079
training Epoch: 100, train_Loss: 0.5866
training Epoch: 100, train_Loss: 1.2957
training Epoch: 100, train_Loss: 0.4381
training Epoch: 100, train_Loss: 1.5852
training Epoch: 100, train_Loss: 0.4225
training Epoch: 100, train_Loss: 0.6188
training Epoch: 100, train_Loss: 1.9657
training Epoch: 100, train_Loss: 1.2018
training Epoch: 100, train_Loss: 0.7843
training Epoch: 100, train_Loss: 0.3103
training Epoch: 100, train_Loss: 2.3521
training Epoch: 100, train_Loss: 1.4741
training Epoch: 100, train_Loss: 1.2230
training Epoch: 100, train_Loss: 1.5941
training Epoch: 100, train_Loss: 0.8596
training Epoch: 100, train_Loss: 0.6617
training Epoch: 100, train_Loss: 2.6314
training Epoch: 100, train_Loss: 0.6806
training Epoch: 100, train_Loss: 2.0615
training Epoch: 100, train_Loss: 1.1541
training Epoch: 100, train_Loss: 2.0038
training Epoch: 100, train_Loss: 1.0433
training Epoch: 100, train_Loss: 1.4218
training Epoch: 100, train_Loss: 1.7040
training Epoch: 100, train_Loss: 0.6535
training Epoch: 100, train_Loss: 1.5052
training Epoch: 100, train_Loss: 1.4813
training Epoch: 100, train_Loss: 0.9178
training Epoch: 100, train_Loss: 2.2737
training Epoch: 100, train_Loss: 0.7669
training Epoch: 100, train_Loss: 1.0790
training Epoch: 100, train_Loss: 1.0588
training Epoch: 100, train_Loss: 0.5280
training Epoch: 100, train_Loss: 1.3187
training Epoch: 100, train_Loss: 0.5386
training Epoch: 100, train_Loss: 0.3795
training Epoch: 100, train_Loss: 2.0579
training Epoch: 100, train_Loss: 0.2676
training Epoch: 100, train_Loss: 0.3555
training Epoch: 100, train_Loss: 2.1573
training Epoch: 100, train_Loss: 1.1117
training Epoch: 100, train_Loss: 0.5397
training Epoch: 100, train_Loss: 0.2580
training Epoch: 100, train_Loss: 0.8411
training Epoch: 100, train_Loss: 3.8204
training Epoch: 100, train_Loss: 1.4870
training Epoch: 100, train_Loss: 1.8539
training Epoch: 100, train_Loss: 0.5300
training Epoch: 100, train_Loss: 0.6389
training Epoch: 100, train_Loss: 1.8382
training Epoch: 100, train_Loss: 0.4877
training Epoch: 100, train_Loss: 1.0432
training Epoch: 100, train_Loss: 1.0918
training Epoch: 100, train_Loss: 0.4845
training Epoch: 100, train_Loss: 1.0112
training Epoch: 100, train_Loss: 0.4501
training Epoch: 100, train_Loss: 2.5054
training Epoch: 100, train_Loss: 0.9016
training Epoch: 100, train_Loss: 0.7276
training Epoch: 100, train_Loss: 2.7486
training Epoch: 100, train_Loss: 0.9952
training Epoch: 100, train_Loss: 0.4437
training Epoch: 100, train_Loss: 0.8555
training Epoch: 100, train_Loss: 0.6379
training Epoch: 100, train_Loss: 1.5387
training Epoch: 100, train_Loss: 0.4501
training Epoch: 100, train_Loss: 2.0946
training Epoch: 100, train_Loss: 0.8119
training Epoch: 100, train_Loss: 1.7365
training Epoch: 100, train_Loss: 1.2441
training Epoch: 100, train_Loss: 0.4355
training Epoch: 100, train_Loss: 0.6005
training Epoch: 100, train_Loss: 1.3021
training Epoch: 100, train_Loss: 1.8874
training Epoch: 100, train_Loss: 1.1404
training Epoch: 100, train_Loss: 0.7159
training Epoch: 100, train_Loss: 0.4493
training Epoch: 100, train_Loss: 0.7044
training Epoch: 100, train_Loss: 0.4228
training Epoch: 100, train_Loss: 1.3194
training Epoch: 100, train_Loss: 1.1673
training Epoch: 100, train_Loss: 0.9596
training Epoch: 100, train_Loss: 0.7926
training Epoch: 100, train_Loss: 2.3124
training Epoch: 100, train_Loss: 1.0182
training Epoch: 100, train_Loss: 0.6542
training Epoch: 100, train_Loss: 1.5200
training Epoch: 100, train_Loss: 0.8538
training Epoch: 100, train_Loss: 0.5363
training Epoch: 100, train_Loss: 1.4509
training Epoch: 100, train_Loss: 0.2582
training Epoch: 100, train_Loss: 0.4947
training Epoch: 100, train_Loss: 0.6387
training Epoch: 100, train_Loss: 1.1905
training Epoch: 100, train_Loss: 1.3960
training Epoch: 100, train_Loss: 2.3761
training Epoch: 100, train_Loss: 0.3306
training Epoch: 100, train_Loss: 0.5333
training Epoch: 100, train_Loss: 1.2537
training Epoch: 100, train_Loss: 1.8745
training Epoch: 100, train_Loss: 1.0468
training Epoch: 100, train_Loss: 1.9331
training Epoch: 100, train_Loss: 1.7077
training Epoch: 100, train_Loss: 0.3982
training Epoch: 100, train_Loss: 0.8666
training Epoch: 100, train_Loss: 1.0063
training Epoch: 100, train_Loss: 1.0862
training Epoch: 100, train_Loss: 2.9004
training Epoch: 100, train_Loss: 0.8621
training Epoch: 100, train_Loss: 0.8625
training Epoch: 100, train_Loss: 1.2305
training Epoch: 100, train_Loss: 0.7684
training Epoch: 100, train_Loss: 0.7455
training Epoch: 100, train_Loss: 0.6515
training Epoch: 100, train_Loss: 1.3465
training Epoch: 100, train_Loss: 0.8587
training Epoch: 100, train_Loss: 0.6227
training Epoch: 100, train_Loss: 1.0082
training Epoch: 100, train_Loss: 1.6145
training Epoch: 100, train_Loss: 0.7593
training Epoch: 100, train_Loss: 1.7842
training Epoch: 100, train_Loss: 0.7315
training Epoch: 100, train_Loss: 0.6177
training Epoch: 100, train_Loss: 1.5446
training Epoch: 100, train_Loss: 0.1684
training Epoch: 100, train_Loss: 0.4664
training Epoch: 100, train_Loss: 2.1266
training Epoch: 100, train_Loss: 0.8097
training Epoch: 100, train_Loss: 1.0837
training Epoch: 100, train_Loss: 1.2523
training Epoch: 100, train_Loss: 3.3917
training Epoch: 100, train_Loss: 0.6611
training Epoch: 100, train_Loss: 1.2514
training Epoch: 100, train_Loss: 3.1784
training Epoch: 100, train_Loss: 0.6089
training Epoch: 100, train_Loss: 0.6320
training Epoch: 100, train_Loss: 0.7894
training Epoch: 100, train_Loss: 1.2786
training Epoch: 100, train_Loss: 0.8545
training Epoch: 100, train_Loss: 0.5827
training Epoch: 100, train_Loss: 1.6691
training Epoch: 100, train_Loss: 0.8459
training Epoch: 100, train_Loss: 1.0875
training Epoch: 100, train_Loss: 0.7358
training Epoch: 100, train_Loss: 0.9666
training Epoch: 100, train_Loss: 1.5133
training Epoch: 100, train_Loss: 0.9935
training Epoch: 100, train_Loss: 0.7342
training Epoch: 100, train_Loss: 0.8746
training Epoch: 100, train_Loss: 1.5890
training Epoch: 100, train_Loss: 2.1535
training Epoch: 100, train_Loss: 0.6511
training Epoch: 100, train_Loss: 0.9528
training Epoch: 100, train_Loss: 0.7951
training Epoch: 100, train_Loss: 0.6038
training Epoch: 100, train_Loss: 0.6481
training Epoch: 100, train_Loss: 0.7959
training Epoch: 100, train_Loss: 1.5037
training Epoch: 100, train_Loss: 1.6386
training Epoch: 100, train_Loss: 2.0167
training Epoch: 100, train_Loss: 0.8777
training Epoch: 100, train_Loss: 0.8018
training Epoch: 100, train_Loss: 1.5756
training Epoch: 100, train_Loss: 0.9542
training Epoch: 100, train_Loss: 0.9263
training Epoch: 100, train_Loss: 1.9286
training Epoch: 100, train_Loss: 1.3769
training Epoch: 100, train_Loss: 0.6717
training Epoch: 100, train_Loss: 0.5546
training Epoch: 100, train_Loss: 0.7720
training Epoch: 100, train_Loss: 0.4548
training Epoch: 100, train_Loss: 0.7300
training Epoch: 100, train_Loss: 1.6985
training Epoch: 100, train_Loss: 1.0833
training Epoch: 100, train_Loss: 0.5398
training Epoch: 100, train_Loss: 0.3724
training Epoch: 100, train_Loss: 0.6675
training Epoch: 100, train_Loss: 0.9770
training Epoch: 100, train_Loss: 0.7051
training Epoch: 100, train_Loss: 0.6451
training Epoch: 100, train_Loss: 0.3122
training Epoch: 100, train_Loss: 1.2858
training Epoch: 100, train_Loss: 0.4776
training Epoch: 100, train_Loss: 1.3607
training Epoch: 100, train_Loss: 0.1760
training Epoch: 100, train_Loss: 0.6488
training Epoch: 100, train_Loss: 1.2768
training Epoch: 100, train_Loss: 3.5217
training Epoch: 100, train_Loss: 0.9373
training Epoch: 100, train_Loss: 0.1991
training Epoch: 100, train_Loss: 1.7631
training Epoch: 100, train_Loss: 1.5830
training Epoch: 100, train_Loss: 1.1049
training Epoch: 100, train_Loss: 0.9668
training Epoch: 100, train_Loss: 1.3175
training Epoch: 100, train_Loss: 2.1400
training Epoch: 100, train_Loss: 0.7297
training Epoch: 100, train_Loss: 0.5820
training Epoch: 100, train_Loss: 0.5267
training Epoch: 100, train_Loss: 1.1229
training Epoch: 100, train_Loss: 0.5265
training Epoch: 100, train_Loss: 0.4672
training Epoch: 100, train_Loss: 1.4640
training Epoch: 100, train_Loss: 0.9822
training Epoch: 100, train_Loss: 0.3774
training Epoch: 100, train_Loss: 1.4150
training Epoch: 100, train_Loss: 2.5845
training Epoch: 100, train_Loss: 1.4602
training Epoch: 100, train_Loss: 1.5040
training Epoch: 100, train_Loss: 1.9577
training Epoch: 100, train_Loss: 0.7985
training Epoch: 100, train_Loss: 0.3760
training Epoch: 100, train_Loss: 0.6352
training Epoch: 100, train_Loss: 0.5324
training Epoch: 100, train_Loss: 1.3862
training Epoch: 100, train_Loss: 0.5324
training Epoch: 100, train_Loss: 0.3015
training Epoch: 100, train_Loss: 1.6199
training Epoch: 100, train_Loss: 1.1021
training Epoch: 100, train_Loss: 0.3597
training Epoch: 100, train_Loss: 0.5827
training Epoch: 100, train_Loss: 1.9589
training Epoch: 100, train_Loss: 0.5042
training Epoch: 100, train_Loss: 1.1709
training Epoch: 100, train_Loss: 1.4635
training Epoch: 100, train_Loss: 2.4722
training Epoch: 100, train_Loss: 0.4516
training Epoch: 100, train_Loss: 1.4382
training Epoch: 100, train_Loss: 1.6122
training Epoch: 100, train_Loss: 0.5499
training Epoch: 100, train_Loss: 0.4130
training Epoch: 100, train_Loss: 1.1153
training Epoch: 100, train_Loss: 0.5008
training Epoch: 100, train_Loss: 0.4059
training Epoch: 100, train_Loss: 1.3457
training Epoch: 100, train_Loss: 0.4366
training Epoch: 100, train_Loss: 1.2411
training Epoch: 100, train_Loss: 0.1988
training Epoch: 100, train_Loss: 1.1929
training Epoch: 100, train_Loss: 2.5233
training Epoch: 100, train_Loss: 1.4262
training Epoch: 100, train_Loss: 0.6699
training Epoch: 100, train_Loss: 0.8067
training Epoch: 100, train_Loss: 0.3448
training Epoch: 100, train_Loss: 1.1588
training Epoch: 100, train_Loss: 3.9663
training Epoch: 100, train_Loss: 1.0373
training Epoch: 100, train_Loss: 0.6739
training Epoch: 100, train_Loss: 0.8457
training Epoch: 100, train_Loss: 1.4059
training Epoch: 100, train_Loss: 0.7726
training Epoch: 100, train_Loss: 2.6000
training Epoch: 100, train_Loss: 2.0697
training Epoch: 100, train_Loss: 0.6051
training Epoch: 100, train_Loss: 0.9098
training Epoch: 100, train_Loss: 0.7057
training Epoch: 100, train_Loss: 0.5254
training Epoch: 100, train_Loss: 1.1120
training Epoch: 100, train_Loss: 0.8864
training Epoch: 100, train_Loss: 0.8369
training Epoch: 100, train_Loss: 0.4664
training Epoch: 100, train_Loss: 0.6041
training Epoch: 100, train_Loss: 1.5198
training Epoch: 100, train_Loss: 0.8611
training Epoch: 100, train_Loss: 3.3198
training Epoch: 100, train_Loss: 0.7211
training Epoch: 100, train_Loss: 0.6454
training Epoch: 100, train_Loss: 0.9226
training Epoch: 100, train_Loss: 1.1715
training Epoch: 100, train_Loss: 0.5919
training Epoch: 100, train_Loss: 1.1025
training Epoch: 100, train_Loss: 1.1370
training Epoch: 100, train_Loss: 0.4518
training Epoch: 100, train_Loss: 0.8322
training Epoch: 100, train_Loss: 1.7169
training Epoch: 100, train_Loss: 1.2097
training Epoch: 100, train_Loss: 0.4713
training Epoch: 100, train_Loss: 0.6859
training Epoch: 100, train_Loss: 0.3084
training Epoch: 100, train_Loss: 0.9818
training Epoch: 100, train_Loss: 0.5361
training Epoch: 100, train_Loss: 1.8292
training Epoch: 100, train_Loss: 1.4085
training Epoch: 100, train_Loss: 1.3564
training Epoch: 100, train_Loss: 0.6848
training Epoch: 100, train_Loss: 1.7144
training Epoch: 100, train_Loss: 0.8789
training Epoch: 100, train_Loss: 2.2027
training Epoch: 100, train_Loss: 1.5006
training Epoch: 100, train_Loss: 0.7571
training Epoch: 100, train_Loss: 3.1164
training Epoch: 100, train_Loss: 0.6640
training Epoch: 100, train_Loss: 0.9440
training Epoch: 100, train_Loss: 0.5696
training Epoch: 100, train_Loss: 0.8174
training Epoch: 100, train_Loss: 0.4877
training Epoch: 100, train_Loss: 0.9234
training Epoch: 100, train_Loss: 0.9292
training Epoch: 100, train_Loss: 0.6334
training Epoch: 100, train_Loss: 0.9471
training Epoch: 100, train_Loss: 0.4187
training Epoch: 100, train_Loss: 0.7575
training Epoch: 100, train_Loss: 1.1971
training Epoch: 100, train_Loss: 0.3898
training Epoch: 100, train_Loss: 0.3681
training Epoch: 100, train_Loss: 0.7724
training Epoch: 100, train_Loss: 1.3745
training Epoch: 100, train_Loss: 1.9057
training Epoch: 100, train_Loss: 1.9193
training Epoch: 100, train_Loss: 1.1196
training Epoch: 100, train_Loss: 0.3038
training Epoch: 100, train_Loss: 0.4704
training Epoch: 100, train_Loss: 0.8808
training Epoch: 100, train_Loss: 1.6762
training Epoch: 100, train_Loss: 0.6238
training Epoch: 100, train_Loss: 0.5867
training Epoch: 100, train_Loss: 1.7856
training Epoch: 100, train_Loss: 0.7608
training Epoch: 100, train_Loss: 0.8009
training Epoch: 100, train_Loss: 1.2013
training Epoch: 100, train_Loss: 0.9976
training Epoch: 100, train_Loss: 2.2292
training Epoch: 100, train_Loss: 3.3463
training Epoch: 100, train_Loss: 2.7970
training Epoch: 100, train_Loss: 0.6661
fold,epoch,train_loss: 4 99 1.0908103
fold,epoch,train_loss: 4 100 1.0920321
====Evaluation
fold:4, epoch:100,train:1.092032, valid:1.076228 

test_loss:0.768183

