{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3540a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not from scratch\n",
      "rese:model_gin\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "Using Rotation Embedding\n",
      "root: dataset/affinity\n",
      "raw_dir: dataset/affinity/raw\n",
      "root: dataset/affinity\n",
      "root: dataset/affinity\n",
      "root: dataset/affinity\n",
      "raw_dir: dataset/affinity/raw\n",
      "root: dataset/affinity\n",
      "root: dataset/affinity\n",
      "root: dataset/affinity\n",
      "raw_dir: dataset/affinity/raw\n",
      "root: dataset/affinity\n",
      "root: dataset/affinity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuyou/anaconda3/envs/wuyou_pytorch/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:217: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['lang_model.embed.weight', 'lang_model.embed.bias', 'lang_model.ln_f.weight', 'lang_model.ln_f.bias', 'lang_model.head.weight']\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: dataset/affinity\n",
      "raw_dir: dataset/affinity/raw\n",
      "root: dataset/affinity\n",
      "root: dataset/affinity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [17:20:09] Explicit valence for atom # 16 N, 4, is greater than permitted\n",
      "[17:20:09] Explicit valence for atom # 16 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:10] Can't kekulize mol.  Unkekulized atoms: 7 9 10 11 12 13 14\n",
      "RDKit ERROR: \n",
      "[17:20:10] Can't kekulize mol.  Unkekulized atoms: 7 9 10 11 12 13 14\n",
      "\n",
      "RDKit ERROR: [17:20:10] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:10] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:10] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "[17:20:10] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:10] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "[17:20:10] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:10] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:10] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:10] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[17:20:10] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:10] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[17:20:10] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:11] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:11] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:11] Explicit valence for atom # 13 N, 4, is greater than permitted\n",
      "[17:20:11] Explicit valence for atom # 13 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:11] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[17:20:11] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:11] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:11] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:11] Can't kekulize mol.  Unkekulized atoms: 8 10 11 13 15\n",
      "RDKit ERROR: \n",
      "[17:20:11] Can't kekulize mol.  Unkekulized atoms: 8 10 11 13 15\n",
      "\n",
      "RDKit ERROR: [17:20:11] Can't kekulize mol.  Unkekulized atoms: 22 24 25 27 29\n",
      "RDKit ERROR: \n",
      "[17:20:11] Can't kekulize mol.  Unkekulized atoms: 22 24 25 27 29\n",
      "\n",
      "RDKit ERROR: [17:20:12] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[17:20:12] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:12] Can't kekulize mol.  Unkekulized atoms: 22 24 25 27 29\n",
      "RDKit ERROR: \n",
      "[17:20:12] Can't kekulize mol.  Unkekulized atoms: 22 24 25 27 29\n",
      "\n",
      "RDKit ERROR: [17:20:12] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[17:20:12] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:12] Explicit valence for atom # 10 N, 4, is greater than permitted\n",
      "[17:20:12] Explicit valence for atom # 10 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:12] Can't kekulize mol.  Unkekulized atoms: 9 13 15 16 21\n",
      "RDKit ERROR: \n",
      "[17:20:12] Can't kekulize mol.  Unkekulized atoms: 9 13 15 16 21\n",
      "\n",
      "RDKit ERROR: [17:20:12] Can't kekulize mol.  Unkekulized atoms: 15\n",
      "RDKit ERROR: \n",
      "[17:20:12] Can't kekulize mol.  Unkekulized atoms: 15\n",
      "\n",
      "RDKit ERROR: [17:20:12] Explicit valence for atom # 10 N, 4, is greater than permitted\n",
      "[17:20:12] Explicit valence for atom # 10 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:12] Can't kekulize mol.  Unkekulized atoms: 3 5 7\n",
      "RDKit ERROR: \n",
      "[17:20:12] Can't kekulize mol.  Unkekulized atoms: 3 5 7\n",
      "\n",
      "RDKit ERROR: [17:20:12] Can't kekulize mol.  Unkekulized atoms: 35 37 38 39 40\n",
      "RDKit ERROR: \n",
      "[17:20:12] Can't kekulize mol.  Unkekulized atoms: 35 37 38 39 40\n",
      "\n",
      "RDKit ERROR: [17:20:12] Explicit valence for atom # 36 N, 4, is greater than permitted\n",
      "[17:20:12] Explicit valence for atom # 36 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:13] Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "[17:20:13] Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:13] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "[17:20:13] Explicit valence for atom # 31 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:13] Can't kekulize mol.  Unkekulized atoms: 18 20 21 23 25\n",
      "RDKit ERROR: \n",
      "[17:20:13] Can't kekulize mol.  Unkekulized atoms: 18 20 21 23 25\n",
      "\n",
      "RDKit ERROR: [17:20:13] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:13] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:13] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:13] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:13] Can't kekulize mol.  Unkekulized atoms: 22 24 25 26 27\n",
      "RDKit ERROR: \n",
      "[17:20:13] Can't kekulize mol.  Unkekulized atoms: 22 24 25 26 27\n",
      "\n",
      "RDKit ERROR: [17:20:13] Can't kekulize mol.  Unkekulized atoms: 4 6 7\n",
      "RDKit ERROR: \n",
      "[17:20:13] Can't kekulize mol.  Unkekulized atoms: 4 6 7\n",
      "\n",
      "RDKit ERROR: [17:20:14] Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "[17:20:14] Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:14] Explicit valence for atom # 27 N, 4, is greater than permitted\n",
      "[17:20:14] Explicit valence for atom # 27 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:14] Can't kekulize mol.  Unkekulized atoms: 22 24 25 27 29\n",
      "RDKit ERROR: \n",
      "[17:20:14] Can't kekulize mol.  Unkekulized atoms: 22 24 25 27 29\n",
      "\n",
      "RDKit ERROR: [17:20:14] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:14] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:14] Can't kekulize mol.  Unkekulized atoms: 8 11 12\n",
      "RDKit ERROR: \n",
      "[17:20:14] Can't kekulize mol.  Unkekulized atoms: 8 11 12\n",
      "\n",
      "RDKit ERROR: [17:20:14] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:14] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:15] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[17:20:15] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:15] Can't kekulize mol.  Unkekulized atoms: 22 23 25\n",
      "RDKit ERROR: \n",
      "[17:20:15] Can't kekulize mol.  Unkekulized atoms: 22 23 25\n",
      "\n",
      "RDKit ERROR: [17:20:15] Can't kekulize mol.  Unkekulized atoms: 9 10 12\n",
      "RDKit ERROR: \n",
      "[17:20:15] Can't kekulize mol.  Unkekulized atoms: 9 10 12\n",
      "\n",
      "RDKit ERROR: [17:20:15] Can't kekulize mol.  Unkekulized atoms: 11 16 17\n",
      "RDKit ERROR: \n",
      "[17:20:15] Can't kekulize mol.  Unkekulized atoms: 11 16 17\n",
      "\n",
      "RDKit ERROR: [17:20:15] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[17:20:15] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:15] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:15] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:15] Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "[17:20:15] Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:16] Can't kekulize mol.  Unkekulized atoms: 4 6 7\n",
      "RDKit ERROR: \n",
      "[17:20:16] Can't kekulize mol.  Unkekulized atoms: 4 6 7\n",
      "\n",
      "RDKit ERROR: [17:20:16] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:16] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n",
      "RDKit ERROR: [17:20:16] Can't kekulize mol.  Unkekulized atoms: 18 20 21 23 25\n",
      "RDKit ERROR: \n",
      "[17:20:16] Can't kekulize mol.  Unkekulized atoms: 18 20 21 23 25\n",
      "\n",
      "RDKit ERROR: [17:20:17] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[17:20:17] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:17] Explicit valence for atom # 2 N, 4, is greater than permitted\n",
      "[17:20:17] Explicit valence for atom # 2 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:17] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "RDKit ERROR: \n",
      "[17:20:17] Can't kekulize mol.  Unkekulized atoms: 10 12 13\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaffold\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuyou/anaconda3/envs/wuyou_pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 28 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 41 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 28 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 41 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 20 S, 7, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 20 S, 7, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 2 3 13\n",
      "RDKit ERROR: \n",
      "[17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 2 3 13\n",
      "\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 8 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 8 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 2 29 30\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 2 29 30\n",
      "\n",
      "[17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "RDKit ERROR: \n",
      "[17:20:19] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 24 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 24 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 17 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 17 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 2 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 34 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 2 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 34 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 21 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 21 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 52 C, 5, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 52 C, 5, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 17 S, 7, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 17 S, 7, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 32 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 24 C, 5, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Can't kekulize mol.  Unkekulized atoms: 12\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 32 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 24 C, 5, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "[17:20:19] Can't kekulize mol.  Unkekulized atoms: 12\n",
      "\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 19 S, 7, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 19 S, 7, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 20 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 20 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 16\n",
      "RDKit ERROR: \n",
      "[17:20:19] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[17:20:19] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 16\n",
      "\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:20:19] Explicit valence for atom # 16 C, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====epoch 1\n",
      "====Evaluation\n",
      "train: 652.485779 val: 725.932434 test: 516893.343750\n",
      "====epoch 2\n",
      "====Evaluation\n",
      "train: 340.969208 val: 389.096954 test: 105541.898438\n",
      "====epoch 3\n",
      "====Evaluation\n",
      "train: 364.958344 val: 415.365906 test: 155824.812500\n",
      "====epoch 4\n",
      "====Evaluation\n",
      "train: 228.249191 val: 260.980896 test: 62311.644531\n",
      "====epoch 5\n",
      "====Evaluation\n",
      "train: 70.048431 val: 80.929161 test: 5809.087402\n",
      "====epoch 6\n",
      "====Evaluation\n",
      "train: 14.935496 val: 15.157969 test: 325.459869\n",
      "====epoch 7\n",
      "====Evaluation\n",
      "train: 20.137577 val: 20.176720 test: 567.360474\n",
      "====epoch 8\n",
      "====Evaluation\n",
      "train: 13.566104 val: 12.650341 test: 292.047241\n",
      "====epoch 9\n",
      "====Evaluation\n",
      "train: 6.453430 val: 4.742199 test: 93.498055\n",
      "====epoch 10\n",
      "====Evaluation\n",
      "train: 6.162154 val: 4.059435 test: 78.159073\n",
      "====epoch 11\n",
      "====Evaluation\n",
      "train: 3.428726 val: 0.781984 test: 29.734982\n",
      "====epoch 12\n",
      "====Evaluation\n",
      "train: 2.596113 val: 5.212355 test: 2.593813\n",
      "====epoch 13\n",
      "====Evaluation\n",
      "train: 3.299796 val: 6.401170 test: 7.798047\n",
      "====epoch 14\n",
      "====Evaluation\n",
      "train: 2.018423 val: 5.301579 test: 3.364908\n",
      "====epoch 15\n",
      "====Evaluation\n",
      "train: 1.777702 val: 1.374862 test: 2.811904\n",
      "====epoch 16\n",
      "====Evaluation\n",
      "train: 2.148457 val: 0.564518 test: 5.970788\n",
      "====epoch 17\n",
      "====Evaluation\n",
      "train: 1.022613 val: 3.498790 test: 0.039991\n",
      "====epoch 18\n",
      "====Evaluation\n",
      "train: 2.098558 val: 5.741454 test: 4.721108\n",
      "====epoch 19\n",
      "====Evaluation\n",
      "train: 2.517070 val: 6.399591 test: 7.512130\n",
      "====epoch 20\n",
      "====Evaluation\n",
      "train: 2.001252 val: 5.694315 test: 4.191525\n",
      "====epoch 21\n",
      "====Evaluation\n",
      "train: 1.304657 val: 3.575462 test: 0.001118\n",
      "====epoch 22\n",
      "====Evaluation\n",
      "train: 2.365653 val: 0.453580 test: 8.946715\n",
      "====epoch 23\n",
      "====Evaluation\n",
      "train: 2.745954 val: 0.376024 test: 10.376670\n",
      "====epoch 24\n",
      "====Evaluation\n",
      "train: 1.428385 val: 3.236449 test: 0.333980\n",
      "====epoch 25\n",
      "====Evaluation\n",
      "train: 2.204638 val: 5.508445 test: 2.638217\n",
      "====epoch 26\n",
      "====Evaluation\n",
      "train: 2.292834 val: 5.912200 test: 3.956898\n",
      "====epoch 27\n",
      "====Evaluation\n",
      "train: 1.589650 val: 5.188072 test: 1.503463\n",
      "====epoch 28\n",
      "====Evaluation\n",
      "train: 0.801444 val: 3.963601 test: 0.017566\n",
      "====epoch 29\n",
      "====Evaluation\n",
      "train: 0.658235 val: 2.608499 test: 2.384191\n",
      "====epoch 30\n",
      "====Evaluation\n",
      "train: 2.181840 val: 0.248736 test: 14.503963\n",
      "====epoch 31\n",
      "====Evaluation\n",
      "train: 1.499797 val: 1.028053 test: 9.238364\n",
      "====epoch 32\n",
      "====Evaluation\n",
      "train: 0.576886 val: 3.678736 test: 0.147664\n",
      "====epoch 33\n",
      "====Evaluation\n",
      "train: 1.418463 val: 5.627088 test: 2.727050\n",
      "====epoch 34\n",
      "====Evaluation\n",
      "train: 1.830935 val: 6.139359 test: 4.919475\n",
      "====epoch 35\n",
      "====Evaluation\n",
      "train: 1.631849 val: 5.594511 test: 2.661132\n",
      "====epoch 36\n",
      "====Evaluation\n",
      "train: 1.459265 val: 4.620489 test: 0.382865\n",
      "====epoch 37\n",
      "====Evaluation\n",
      "train: 1.465483 val: 3.664071 test: 0.112789\n",
      "====epoch 38\n",
      "====Evaluation\n",
      "train: 1.446657 val: 3.332191 test: 0.378105\n",
      "====epoch 39\n",
      "====Evaluation\n",
      "train: 1.279390 val: 4.098836 test: 0.021810\n",
      "====epoch 40\n",
      "====Evaluation\n",
      "train: 1.176103 val: 4.536927 test: 0.388278\n",
      "====epoch 41\n",
      "====Evaluation\n",
      "train: 0.833298 val: 4.377074 test: 0.266601\n",
      "====epoch 42\n",
      "====Evaluation\n",
      "train: 0.577713 val: 4.193723 test: 0.118324\n",
      "====epoch 43\n",
      "====Evaluation\n",
      "train: 0.232674 val: 3.092760 test: 0.531627\n",
      "====epoch 44\n",
      "====Evaluation\n",
      "train: 0.694462 val: 1.655155 test: 4.509106\n",
      "====epoch 45\n",
      "====Evaluation\n",
      "train: 0.225063 val: 2.718244 test: 1.069770\n",
      "====epoch 46\n",
      "====Evaluation\n",
      "train: 0.770550 val: 4.118567 test: 0.130670\n",
      "====epoch 47\n",
      "====Evaluation\n",
      "train: 0.879288 val: 4.237627 test: 0.213952\n",
      "====epoch 48\n",
      "====Evaluation\n",
      "train: 0.273567 val: 3.138741 test: 0.334169\n",
      "====epoch 49\n",
      "====Evaluation\n",
      "train: 0.183924 val: 2.621311 test: 1.169859\n",
      "====epoch 50\n",
      "====Evaluation\n",
      "train: 0.173705 val: 2.698078 test: 0.957624\n",
      "====epoch 51\n",
      "====Evaluation\n",
      "train: 0.607510 val: 3.840188 test: 0.011170\n",
      "====epoch 52\n",
      "====Evaluation\n",
      "train: 0.705485 val: 4.006388 test: 0.071724\n",
      "====epoch 53\n",
      "====Evaluation\n",
      "train: 0.287025 val: 3.337456 test: 0.173919\n",
      "====epoch 54\n",
      "====Evaluation\n",
      "train: 0.156143 val: 3.037672 test: 0.552733\n",
      "====epoch 55\n",
      "====Evaluation\n",
      "train: 0.102752 val: 2.653999 test: 1.342935\n",
      "====epoch 56\n",
      "====Evaluation\n",
      "train: 0.158830 val: 3.126169 test: 0.533874\n",
      "====epoch 57\n",
      "====Evaluation\n",
      "train: 0.612052 val: 3.936359 test: 0.004713\n",
      "====epoch 58\n",
      "====Evaluation\n",
      "train: 0.286617 val: 3.525632 test: 0.116642\n",
      "====epoch 59\n",
      "====Evaluation\n",
      "train: 0.163853 val: 3.376905 test: 0.278423\n",
      "====epoch 60\n",
      "====Evaluation\n",
      "train: 0.108829 val: 3.298338 test: 0.345033\n",
      "====epoch 61\n",
      "====Evaluation\n",
      "train: 0.255199 val: 3.635099 test: 0.070988\n",
      "====epoch 62\n",
      "====Evaluation\n",
      "train: 0.144633 val: 3.452550 test: 0.230531\n",
      "====epoch 63\n",
      "====Evaluation\n",
      "train: 0.171606 val: 3.561361 test: 0.162778\n",
      "====epoch 64\n",
      "====Evaluation\n",
      "train: 0.028160 val: 3.227997 test: 0.617001\n",
      "====epoch 65\n",
      "====Evaluation\n",
      "train: 0.127095 val: 3.570324 test: 0.182904\n",
      "====epoch 66\n",
      "====Evaluation\n",
      "train: 0.264747 val: 3.856353 test: 0.024505\n",
      "====epoch 67\n",
      "====Evaluation\n",
      "train: 0.116209 val: 3.614837 test: 0.175615\n",
      "====epoch 68\n",
      "====Evaluation\n",
      "train: 0.089859 val: 3.572775 test: 0.270441\n",
      "====epoch 69\n",
      "====Evaluation\n",
      "train: 0.044335 val: 3.331205 test: 0.619580\n",
      "====epoch 70\n",
      "====Evaluation\n",
      "train: 0.195379 val: 3.860029 test: 0.072964\n",
      "====epoch 71\n",
      "====Evaluation\n",
      "train: 0.484125 val: 4.270912 test: 0.039588\n",
      "====epoch 72\n",
      "====Evaluation\n",
      "train: 0.278687 val: 3.990806 test: 0.016578\n",
      "====epoch 73\n",
      "====Evaluation\n",
      "train: 0.102626 val: 3.652976 test: 0.230749\n",
      "====epoch 74\n",
      "====Evaluation\n",
      "train: 0.440713 val: 4.196006 test: 0.006663\n",
      "====epoch 75\n",
      "====Evaluation\n",
      "train: 0.378357 val: 4.125557 test: 0.002695\n",
      "====epoch 76\n",
      "====Evaluation\n",
      "train: 0.039379 val: 3.307236 test: 0.691036\n",
      "====epoch 77\n",
      "====Evaluation\n",
      "train: 0.043000 val: 3.488269 test: 0.327422\n",
      "====epoch 78\n",
      "====Evaluation\n",
      "train: 0.181756 val: 3.822380 test: 0.049110\n",
      "====epoch 79\n",
      "====Evaluation\n",
      "train: 0.150701 val: 3.743859 test: 0.073897\n",
      "====epoch 80\n",
      "====Evaluation\n",
      "train: 0.091279 val: 3.590080 test: 0.193524\n",
      "====epoch 81\n",
      "====Evaluation\n",
      "train: 0.022434 val: 3.323545 test: 0.479488\n",
      "====epoch 82\n",
      "====Evaluation\n",
      "train: 0.089716 val: 3.533503 test: 0.204290\n",
      "====epoch 83\n",
      "====Evaluation\n",
      "train: 0.234190 val: 3.790982 test: 0.048617\n",
      "====epoch 84\n",
      "====Evaluation\n",
      "train: 0.217740 val: 3.752258 test: 0.077392\n",
      "====epoch 85\n",
      "====Evaluation\n",
      "train: 0.068240 val: 3.443276 test: 0.399944\n",
      "====epoch 86\n",
      "====Evaluation\n",
      "train: 0.376102 val: 3.965870 test: 0.003359\n",
      "====epoch 87\n",
      "====Evaluation\n",
      "train: 0.170814 val: 3.674527 test: 0.132757\n",
      "====epoch 88\n",
      "====Evaluation\n",
      "train: 0.061435 val: 2.891475 test: 1.546958\n",
      "====epoch 89\n",
      "====Evaluation\n",
      "train: 0.021870 val: 3.111799 test: 0.986079\n",
      "====epoch 90\n",
      "====Evaluation\n",
      "train: 0.775624 val: 4.487785 test: 0.298758\n",
      "====epoch 91\n",
      "====Evaluation\n",
      "train: 0.805633 val: 4.537705 test: 0.370208\n",
      "====epoch 92\n",
      "====Evaluation\n",
      "train: 0.469462 val: 4.191013 test: 0.045744\n",
      "====epoch 93\n",
      "====Evaluation\n",
      "train: 0.021077 val: 3.404214 test: 0.459408\n",
      "====epoch 94\n",
      "====Evaluation\n",
      "train: 0.333560 val: 2.705927 test: 2.227079\n",
      "====epoch 95\n",
      "====Evaluation\n",
      "train: 0.343506 val: 2.835509 test: 2.050488\n",
      "====epoch 96\n",
      "====Evaluation\n",
      "train: 0.094328 val: 3.741348 test: 0.236995\n",
      "====epoch 97\n",
      "====Evaluation\n",
      "train: 0.343444 val: 4.309200 test: 0.011050\n",
      "====epoch 98\n",
      "====Evaluation\n",
      "train: 0.630476 val: 4.614746 test: 0.221394\n",
      "====epoch 99\n",
      "training Epoch [100/100], Loss: 0.8870\n",
      "====Evaluation\n",
      "train: 0.675725 val: 4.663957 test: 0.257486\n",
      "====epoch 100\n",
      "====Evaluation\n",
      "train: 0.640296 val: 4.620332 test: 0.235240\n",
      "====epoch 101\n",
      "====Evaluation\n",
      "train: 0.412689 val: 4.394726 test: 0.036662\n",
      "====epoch 102\n",
      "====Evaluation\n",
      "train: 0.238686 val: 4.032774 test: 0.064398\n",
      "====epoch 103\n",
      "====Evaluation\n",
      "train: 0.208059 val: 3.739118 test: 0.327377\n",
      "====epoch 104\n",
      "====Evaluation\n",
      "train: 0.154674 val: 3.603456 test: 0.368693\n",
      "====epoch 105\n",
      "====Evaluation\n",
      "train: 0.149562 val: 3.679142 test: 0.195224\n",
      "====epoch 106\n",
      "====Evaluation\n",
      "train: 0.149420 val: 3.601672 test: 0.195501\n",
      "====epoch 107\n",
      "====Evaluation\n",
      "train: 0.197438 val: 3.607366 test: 0.157082\n",
      "====epoch 108\n",
      "====Evaluation\n",
      "train: 0.235942 val: 3.562412 test: 0.160160\n",
      "====epoch 109\n",
      "====Evaluation\n",
      "train: 0.277401 val: 3.548746 test: 0.150028\n",
      "====epoch 110\n",
      "====Evaluation\n",
      "train: 0.204628 val: 3.289804 test: 0.451941\n",
      "====epoch 111\n",
      "====Evaluation\n",
      "train: 0.187628 val: 2.903715 test: 1.168195\n",
      "====epoch 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Evaluation\n",
      "train: 0.188328 val: 2.956768 test: 1.054267\n",
      "====epoch 113\n",
      "====Evaluation\n",
      "train: 0.262312 val: 3.323680 test: 0.384694\n",
      "====epoch 114\n",
      "====Evaluation\n",
      "train: 0.425130 val: 3.683394 test: 0.049156\n",
      "====epoch 115\n",
      "====Evaluation\n",
      "train: 0.424899 val: 3.674952 test: 0.053388\n",
      "====epoch 116\n",
      "====Evaluation\n",
      "train: 0.276339 val: 3.358206 test: 0.347575\n",
      "====epoch 117\n",
      "====Evaluation\n",
      "train: 0.213644 val: 3.179203 test: 0.630217\n",
      "====epoch 118\n",
      "====Evaluation\n",
      "train: 0.205437 val: 2.914917 test: 1.212356\n",
      "====epoch 119\n",
      "====Evaluation\n",
      "train: 0.204609 val: 2.926875 test: 1.243656\n",
      "====epoch 120\n",
      "====Evaluation\n",
      "train: 0.209669 val: 2.940834 test: 1.241828\n",
      "====epoch 121\n",
      "====Evaluation\n",
      "train: 0.176975 val: 3.318915 test: 0.525016\n",
      "====epoch 122\n",
      "====Evaluation\n",
      "train: 0.278058 val: 3.600464 test: 0.167612\n",
      "====epoch 123\n",
      "====Evaluation\n",
      "train: 0.293424 val: 3.672901 test: 0.108773\n",
      "====epoch 124\n",
      "====Evaluation\n",
      "train: 0.208555 val: 3.603178 test: 0.197495\n",
      "====epoch 125\n",
      "====Evaluation\n",
      "train: 0.175416 val: 3.456720 test: 0.466272\n",
      "====epoch 126\n",
      "====Evaluation\n",
      "train: 0.212888 val: 3.441405 test: 0.512745\n",
      "====epoch 127\n",
      "====Evaluation\n",
      "train: 0.246717 val: 3.458166 test: 0.526501\n",
      "====epoch 128\n",
      "====Evaluation\n",
      "train: 0.197509 val: 3.611656 test: 0.276318\n",
      "====epoch 129\n",
      "====Evaluation\n",
      "train: 0.196204 val: 3.703441 test: 0.163985\n",
      "====epoch 130\n",
      "====Evaluation\n",
      "train: 0.204167 val: 3.734183 test: 0.122924\n",
      "====epoch 131\n",
      "====Evaluation\n",
      "train: 0.218768 val: 3.759613 test: 0.099616\n",
      "====epoch 132\n",
      "====Evaluation\n",
      "train: 0.235251 val: 3.762695 test: 0.085863\n",
      "====epoch 133\n",
      "====Evaluation\n",
      "train: 0.247150 val: 3.751999 test: 0.075750\n",
      "====epoch 134\n",
      "====Evaluation\n",
      "train: 0.229874 val: 3.686496 test: 0.110892\n",
      "====epoch 135\n",
      "====Evaluation\n",
      "train: 0.198410 val: 3.551505 test: 0.264978\n",
      "====epoch 136\n",
      "====Evaluation\n",
      "train: 0.198671 val: 3.457727 test: 0.357450\n",
      "====epoch 137\n",
      "====Evaluation\n",
      "train: 0.203472 val: 3.406545 test: 0.432487\n",
      "====epoch 138\n",
      "====Evaluation\n",
      "train: 0.213721 val: 3.502522 test: 0.260716\n",
      "====epoch 139\n",
      "====Evaluation\n",
      "train: 0.286725 val: 3.599166 test: 0.147701\n",
      "====epoch 140\n",
      "====Evaluation\n",
      "train: 0.376411 val: 3.673157 test: 0.069923\n",
      "====epoch 141\n",
      "====Evaluation\n",
      "train: 0.350787 val: 3.634810 test: 0.095818\n",
      "====epoch 142\n",
      "====Evaluation\n",
      "train: 0.243377 val: 3.493151 test: 0.232713\n",
      "====epoch 143\n",
      "====Evaluation\n",
      "train: 0.208972 val: 3.341181 test: 0.448578\n",
      "====epoch 144\n",
      "====Evaluation\n",
      "train: 0.217352 val: 3.276046 test: 0.560240\n",
      "====epoch 145\n",
      "====Evaluation\n",
      "train: 0.218540 val: 3.291437 test: 0.563328\n",
      "====epoch 146\n",
      "====Evaluation\n",
      "train: 0.203155 val: 3.405888 test: 0.394303\n",
      "====epoch 147\n",
      "====Evaluation\n",
      "train: 0.202810 val: 3.539753 test: 0.223226\n",
      "====epoch 148\n",
      "====Evaluation\n",
      "train: 0.254521 val: 3.695121 test: 0.088759\n",
      "====epoch 149\n",
      "====Evaluation\n",
      "train: 0.272583 val: 3.753619 test: 0.062129\n",
      "====epoch 150\n",
      "====Evaluation\n",
      "train: 0.258657 val: 3.779273 test: 0.049283\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n",
      "raw_dir: dataset/affinity/test/raw\n",
      "root: dataset/affinity/test\n",
      "root: dataset/affinity/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 28 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 41 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 28 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 41 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 20 S, 7, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 20 S, 7, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "\n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 2 3 13\n",
      "RDKit ERROR: \n",
      "[17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 2 3 13\n",
      "\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 8 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 8 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 2 29 30\n",
      "RDKit ERROR: \n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "[17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 2 29 30\n",
      "\n",
      "[17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 10 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 13 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "RDKit ERROR: \n",
      "[17:34:59] Can't kekulize mol.  Unkekulized atoms: 0 1 4 7 8 9 10 14\n",
      "\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 24 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 24 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 17 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 17 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 2 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 34 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 2 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 34 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 22 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 21 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 21 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 12 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 26 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 52 C, 5, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 52 C, 5, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 31 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 15 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 17 S, 7, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 17 S, 7, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 32 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 32 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 24 C, 5, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 24 C, 5, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Can't kekulize mol.  Unkekulized atoms: 12\n",
      "RDKit ERROR: \n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 5 C, 6, is greater than permitted\n",
      "[17:34:59] Can't kekulize mol.  Unkekulized atoms: 12\n",
      "\n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 19 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 19 S, 7, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 19 S, 7, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 20 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 20 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 25 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 6 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 7 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 9 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 16\n",
      "RDKit ERROR: \n",
      "[17:34:59] Can't kekulize mol.  Unkekulized atoms: 12 13 14 15 16\n",
      "\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 11 C, 6, is greater than permitted\n",
      "RDKit ERROR: [17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n",
      "[17:34:59] Explicit valence for atom # 16 C, 6, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 0.049283 \n"
     ]
    }
   ],
   "source": [
    "from loader1 import MoleculeDatasetBig, SeqDataset,SeqMolDataset,SmileDataset#########################\n",
    "import torch\n",
    "import torch\n",
    "#import args\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "#from loader import MoleculeDataset#################\n",
    "#from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import GNN, GNN_graphpred,GNN_graphpred_1\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from splitters import scaffold_split,scaffold_split_1\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tensorboardX import SummaryWriter\n",
    "import esm\n",
    "\n",
    "#from SeqMolModel import InteractionModel,InteractionModel_1,SequenceModel,InteractionModel_4\n",
    "#from SeqMolSmile import InteractionModel_4\n",
    "#from SeqMolModel import InteractionModel_4\n",
    "from SeqMol_without_cross_model1 import InteractionModel_4\n",
    "print(torch.cuda.is_available())\n",
    "import torch\n",
    "torch.cuda.current_device()\n",
    "torch.cuda._initialized = True\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch implementation of pre-training of graph neural networks')\n",
    "parser.add_argument('--device', type=int, default=0,\n",
    "                        help='which gpu to use if any (default: 0)')#0000\n",
    "parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='input batch size for training (default: 32)')\n",
    "parser.add_argument('--epochs', type=int, default=1000,\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=float, default=0.1,\n",
    "                        help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--lr_scale', type=float, default=1,\n",
    "                        help='relative learning rate for the feature extraction layer (default: 1)')\n",
    "parser.add_argument('--decay', type=float, default=0,\n",
    "                        help='weight decay (default: 0)')\n",
    "parser.add_argument('--num_layer', type=int, default=5,\n",
    "                        help='number of GNN message passing layers (default: 5).')\n",
    "parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                        help='embedding dimensions (default: 300)')\n",
    "parser.add_argument('--dropout_ratio', type=float, default=0.5,\n",
    "                        help='dropout ratio (default: 0.5)')\n",
    "parser.add_argument('--graph_pooling', type=str, default=\"mean\",\n",
    "                        help='graph level pooling (sum, mean, max, set2set, attention)')\n",
    "parser.add_argument('--JK', type=str, default=\"last\",\n",
    "                        help='how the node features across layers are combined. last, sum, max or concat')\n",
    "parser.add_argument('--gnn_type', type=str, default=\"gin\")\n",
    "parser.add_argument('--dataset', type=str, default = 'affinity', help='root directory of dataset. For now, only classification.')\n",
    "#parser.add_argument('--input_model_file', type=str, default = 'None', help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--input_model_file', type=str, default = 'Mole-BERT', help='filename to read the model (if there is any)')\n",
    "parser.add_argument('--filename', type=str, default = '', help='output filename')\n",
    "parser.add_argument('--seed', type=int, default=42, help = \"Seed for splitting the dataset.\")\n",
    "parser.add_argument('--runseed', type=int, default=0, help = \"Seed for minibatch selection, random initialization.\")\n",
    "parser.add_argument('--split', type = str, default=\"scaffold\", help = \"random or scaffold or random_scaffold\")\n",
    "parser.add_argument('--eval_train', type=int, default = 1, help='evaluating training or not')\n",
    "parser.add_argument('--num_workers', type=int, default = 4, help='number of workers for dataset loading')\n",
    "\n",
    "parser.add_argument('--n_head', type=int, default = 12, help='number of workers for dataset loading')\n",
    "\n",
    "parser.add_argument('--n_layer', type=int, default = 12, help='number of workers for dataset loading')\n",
    "parser.add_argument('--d_dropout', type=float, default = 0.1, help='number of workers for dataset loading')\n",
    "parser.add_argument('--n_embd', type=int, default = 768, help='number of workers for dataset loading')\n",
    "parser.add_argument('--dropout', type=float, default = 0.1, help='number of workers for dataset loading')\n",
    "parser.add_argument('--lr_start', type=float, default =  3e-5, help='number of workers for dataset loading')\n",
    "parser.add_argument('--max_epochs', type=int, default = 500, help='number of workers for dataset loading')\n",
    "parser.add_argument('--num_feats', type=int, default = 32, help='number of workers for dataset loading')\n",
    "parser.add_argument('--checkpoint_every', type=int, default = 100, help='number of workers for dataset loading')\n",
    "parser.add_argument('--seed_path', type=str, default =  'data/checkpoints/N-Step-Checkpoint_3_30000.ckpt', help='number of workers for dataset loading')\n",
    "parser.add_argument('--dims', type=list, default = [ 768, 768, 768, 1], help='number of workers for dataset loading')\n",
    "\n",
    "args = parser.parse_args(args=[])###############33\n",
    "\n",
    "\n",
    "#load pretained model of Mole-Bert\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.runseed)\n",
    "\n",
    "num_tasks=1\n",
    "# Load ESM-2 model\n",
    "protein_model, protein_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "protein_model.to(device)\n",
    "#freezing parameters\n",
    "for i,p in enumerate(protein_model.parameters()):\n",
    "    p.requires_grad = False\n",
    "#print(protein_alphabet)\n",
    "#alphabet = esm.Alphabet.from_architecture(model_data[\"args\"].arch)\n",
    "#batch_converter = alphabet.get_batch_converter()\n",
    "protein_model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "#self.molecular.model,self.molecular.node_representation,self.molecular.features = GNN_graphpred_1(args.num_layer, args.emb_dim, num_tasks, JK = args.JK, drop_ratio = args.dropout_ratio, graph_pooling = args.graph_pooling, gnn_type = args.gnn_type)\n",
    "molecular_model = GNN_graphpred_1(args.num_layer, args.emb_dim, num_tasks, JK = args.JK, drop_ratio = args.dropout_ratio, graph_pooling = args.graph_pooling, gnn_type = args.gnn_type)\n",
    "###################################\n",
    "if not args.input_model_file == \"None\":###############\n",
    "    print('Not from scratch')\n",
    "    molecular_model.from_pretrained('model_gin/{}.pth'.format(args.input_model_file))\n",
    "    print('rese:model_gin')\n",
    "molecular_model.to(device)\n",
    "for i,p in enumerate(molecular_model.parameters()):\n",
    "    p.requires_grad = False#freezing parameters\n",
    "#freezing parameters\n",
    "for i,p in enumerate(protein_model.parameters()):\n",
    "    p.requires_grad = False#freezing parameters\n",
    "\n",
    "'''\n",
    "model_param_group = []\n",
    "model_param_group.append({\"params\": molecular_model.gnn.parameters()})\n",
    "if args.graph_pooling == \"attention\":\n",
    "    model_param_group.append({\"params\": molecular_model.pool.parameters(), \"lr\":args.lr*args.lr_scale})\n",
    "'''\n",
    "'''\n",
    "\n",
    "CSDNDreamcatcherCC 4.0 BY-SA\n",
    "https://blog.csdn.net/Wind_2028/article/details/120541017   \n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "model_param_group.append({\"params\": molecular_model.graph_pred_linear.parameters(), \"lr\":args.lr*args.lr_scale})\n",
    "optimizer = optim.Adam(model_param_group, lr=0.01, weight_decay=args.decay)#############\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import rank_zero_warn, rank_zero_only, seed\n",
    "#from finetune.tokenizer.tokenizer import MolTranBertTokenizer\n",
    "from fast_transformers.masking import LengthMask as LM\n",
    "#from rotate_attention.rotate_builder import RotateEncoderBuilder as rotate_builder\n",
    "from fast_transformers.feature_maps import GeneralizedRandomFeatures\n",
    "from functools import partial\n",
    "from apex import optimizers\n",
    "import subprocess\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "#from utils import normalize_smiles\n",
    "import sys\n",
    "sys.path.append('finetune/')\n",
    "from utilss import normalize_smiles\n",
    "from tokenizer.tokenizer import MolTranBertTokenizer\n",
    "from rotate_attention.rotate_builder import RotateEncoderBuilder as rotate_builder\n",
    "#from utils import normalize_smiles\n",
    "# create a function (this my favorite choice)\n",
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "\n",
    "class LightningModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config, tokenizer):\n",
    "        super(LightningModule, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        #self.hparams = config\n",
    "        #self.mode = config.mode\n",
    "        self.save_hyperparameters(config)\n",
    "        self.tokenizer=tokenizer\n",
    "        '''\n",
    "        self.min_loss = {\n",
    "            self.hparams.measure_name + \"min_valid_loss\": torch.finfo(torch.float32).max,\n",
    "            self.hparams.measure_name + \"min_epoch\": 0,\n",
    "        }\n",
    "        '''\n",
    "        # Word embeddings layer\n",
    "        n_vocab, d_emb = len(tokenizer.vocab), config.n_embd\n",
    "        # input embedding stem\n",
    "        \n",
    "        builder = rotate_builder.from_kwargs(\n",
    "            n_layers=config.n_layer,\n",
    "            n_heads=config.n_head,\n",
    "            query_dimensions=config.n_embd//config.n_head,\n",
    "            value_dimensions=config.n_embd//config.n_head,\n",
    "            feed_forward_dimensions=config.n_embd,\n",
    "            attention_type='linear',\n",
    "            feature_map=partial(GeneralizedRandomFeatures, n_dims=config.num_feats),\n",
    "            activation='gelu',\n",
    "            )\n",
    "        self.pos_emb = None\n",
    "        self.tok_emb = nn.Embedding(n_vocab, config.n_embd)\n",
    "        #print('self.tok_emb:',self.tok_emb)\n",
    "        self.drop = nn.Dropout(config.d_dropout)\n",
    "        \n",
    "        ## transformer\n",
    "        self.blocks = builder.get()\n",
    "        #self.lang_model = self.lm_layer(config.n_embd, n_vocab)\n",
    "        #self.train_config = config\n",
    "        #if we are starting from scratch set seeds\n",
    "        #########################################\n",
    "        # protein_emb_dim, smiles_embed_dim, dims=dims, dropout=0.2):\n",
    "        #########################################\n",
    "        '''\n",
    "        self.fcs = []  \n",
    "        self.loss = torch.nn.L1Loss()\n",
    "        self.net = self.Net(\n",
    "            config.n_embd, dims=config.dims, dropout=config.dropout,\n",
    "        )\n",
    "        '''\n",
    "\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        dims = [150, 50, 50, 2]\n",
    "\n",
    "\n",
    "        def __init__(self, smiles_embed_dim, dims=dims, dropout=0.2):\n",
    "            super().__init__()\n",
    "            self.desc_skip_connection = True \n",
    "            self.fcs = []  # nn.ModuleList()\n",
    "            #print('dropout is {}'.format(dropout))\n",
    "\n",
    "            self.fc1 = nn.Linear(smiles_embed_dim, smiles_embed_dim)\n",
    "            self.dropout1 = nn.Dropout(dropout)\n",
    "            self.relu1 = nn.GELU()\n",
    "            self.fc2 = nn.Linear(smiles_embed_dim, smiles_embed_dim)\n",
    "            self.dropout2 = nn.Dropout(dropout)\n",
    "            self.relu2 = nn.GELU()\n",
    "            self.final = nn.Linear(smiles_embed_dim, 1)\n",
    "\n",
    "        def forward(self, smiles_emb):\n",
    "            x_out = self.fc1(smiles_emb)\n",
    "            x_out = self.dropout1(x_out)\n",
    "            x_out = self.relu1(x_out)\n",
    "\n",
    "            if self.desc_skip_connection is True:\n",
    "                x_out = x_out + smiles_emb\n",
    "\n",
    "            z = self.fc2(x_out)\n",
    "            z = self.dropout2(z)\n",
    "            z = self.relu2(z)\n",
    "            if self.desc_skip_connection is True:\n",
    "                z = self.final(z + x_out)\n",
    "            else:\n",
    "                z = self.final(z)\n",
    "\n",
    "            return z\n",
    "\n",
    "    class lm_layer(nn.Module):\n",
    "        def __init__(self, n_embd, n_vocab):\n",
    "            super().__init__()\n",
    "            self.embed = nn.Linear(n_embd, n_embd)\n",
    "            self.ln_f = nn.LayerNorm(n_embd)\n",
    "            self.head = nn.Linear(n_embd, n_vocab, bias=False)\n",
    "        def forward(self, tensor):\n",
    "            tensor = self.embed(tensor)\n",
    "            tensor = F.gelu(tensor)\n",
    "            tensor = self.ln_f(tensor)\n",
    "            tensor = self.head(tensor)\n",
    "            return tensor\n",
    "\n",
    "    def get_loss(self, smiles_emb, measures):\n",
    "\n",
    "        z_pred = self.net.forward(smiles_emb).squeeze()\n",
    "        measures = measures.float()\n",
    "\n",
    "        return self.loss(z_pred, measures), z_pred, measures\n",
    "    \n",
    "    \n",
    "margs = args\n",
    "tokenizer = MolTranBertTokenizer('finetune/bert_vocab.txt')\n",
    "seed.seed_everything(margs.seed)\n",
    "if margs.seed_path == '':\n",
    "    #print(\"# training from scratch\")\n",
    "    smile_model = LightningModule(margs, tokenizer)\n",
    "else:\n",
    "    #print(\"# loaded pre-trained model from {args.seed_path}\")\n",
    "    smile_model = LightningModule(margs, tokenizer).load_from_checkpoint(margs.seed_path, strict=False, config=margs, tokenizer=tokenizer, vocab=len(tokenizer.vocab))#########################33\n",
    "\n",
    "#print('model:',smile_model)\n",
    "#freezing parameters\n",
    "for i,p in enumerate(smile_model.parameters()):\n",
    "    p.requires_grad = False\n",
    "    \n",
    "\n",
    "#num_tasks=1\n",
    "model= InteractionModel_4(protein_model=protein_model,molecular_model=molecular_model,protein_embd_dim=1280,num_tasks=1,device=device,mol_embd_dim=300) \n",
    "model.to(device)\n",
    "#print(model)#nice#num_tasks=1\n",
    "\n",
    "\n",
    "###################when doing geometric.data process, if there is some changes, please delete the directory process and let it generate again\n",
    "\n",
    "gnn_dataset = MoleculeDatasetBig(root=\"./dataset/\" + args.dataset, dataset=args.dataset)###########################\n",
    "#print('args.dataset:',args.dataset)\n",
    "#print(gnn_dataset)\n",
    "#for i,gnn_data in enumerate(gnn_dataset):\n",
    "    #print(gnn_data)\n",
    "    \n",
    "seq_dataset=SeqDataset('dataset/affinity/processed/sequence.csv')\n",
    "#smiles_dataset=SmileDataset('dataset/affinity/processed/smiles.csv')\n",
    "\n",
    "#seq_dataset[2]\n",
    "\n",
    "def collate(batch):\n",
    "    #print('collate_batch:',batch)\n",
    "    #print('collate_batch_0:',batch[0])\n",
    "    tokenizer = MolTranBertTokenizer('finetune/bert_vocab.txt')\n",
    "        \n",
    "    tokens = tokenizer.batch_encode_plus([ smile for smile in batch], padding=True, add_special_tokens=True)\n",
    "    #print('tokens[1]_mask:',tokens[1])\n",
    "    #print('colate###########################')\n",
    "    #for i,m in enumerate(tokens):\n",
    "            \n",
    "    #print('collate_tokens_input_ids:',tokens['input_ids'])\n",
    "    #print('colate_tokens_attention_mask:',tokens['attention_mask'])\n",
    "    return (torch.tensor(tokens['input_ids']), torch.tensor(tokens['attention_mask']))\n",
    "    \n",
    "smiles_dataset=SmileDataset('dataset/affinity/processed/smiles.csv')\n",
    "#smiles_dataset=SmileDataset('dataset/affinity/processed/smiles.csv')\n",
    "\n",
    "#####test with chartGPT  DataSet extends two parents' classes\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "class MultiDatasetMixin:\n",
    "    def __init__(self, dataset1, dataset2,dataset3):\n",
    "        self.dataset1 = dataset1\n",
    "        self.dataset2 = dataset2\n",
    "        self.dataset3=dataset3\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.dataset1), len(self.dataset2),len(self.dataset3))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.dataset1[idx], self.dataset2[idx],self.dataset3[idx]\n",
    "\n",
    "class CustomMultiDataset(MultiDatasetMixin, Dataset):###############3extends two classes\n",
    "    def __init__(self, dataset1, dataset2,dataset3):\n",
    "        MultiDatasetMixin.__init__(self, dataset1, dataset2,dataset3)\n",
    "\n",
    "\n",
    "#chartGPT\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import DataLoader as GeometricDataLoader\n",
    "\n",
    "class MultiDataLoader:\n",
    "    def __init__(self, dataloader1, dataloader2,dataloader3):\n",
    "        self.dataloader1 = dataloader1\n",
    "        self.dataloader2 = dataloader2\n",
    "        self.dataloader3=dataloader3\n",
    "\n",
    "    def __iter__(self):\n",
    "        for data1, data2,data3 in zip(self.dataloader1, self.dataloader2, self.dataloader3):\n",
    "            yield data1, data2, data3\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.dataloader1), len(self.dataloader2), len(self.dataloader3))\n",
    "\n",
    "    def set_shuffle(self, shuffle):\n",
    "        self.dataloader1.shuffle = shuffle\n",
    "        self.dataloader2.shuffle = shuffle\n",
    "        self.dataloader3.shuffle=shuffle\n",
    "\n",
    "        \n",
    "###########split train dataset validate dataset test dataset\n",
    "seq_gnn_smile_dataset=MultiDatasetMixin(seq_dataset,gnn_dataset,smiles_dataset)\n",
    "\n",
    "#print('seq_dataset:',seq_dataset)\n",
    "\n",
    "#seq_dataloader=DataLoader(seq_dataset,batch_size=args.batch_size,shuffle=True,num_workers=args.num_workers)\n",
    "'''\n",
    "for i ,seq in enumerate(seq_dataloader):\n",
    "    print(seq)\n",
    "'''\n",
    "if args.split == \"scaffold\":\n",
    "        smiles_list = pd.read_csv('./dataset/' + args.dataset + '/processed/smiles.csv', header=None)[0].tolist()\n",
    "        \n",
    "        #print('smiles_list:',smiles_list)\n",
    "        mol_train_dataset, mol_valid_dataset, mol_test_dataset ,seq_train_dataset,seq_valid_dataset,seq_test_dataset,smile_train_dataset,smile_valid_dataset,smile_test_dataset= scaffold_split_1(seq_gnn_smile_dataset, smiles_list, null_value=0, frac_train=0.8,frac_valid=0.1, frac_test=0.1)##########dataset\n",
    "        print(\"scaffold\")\n",
    "elif args.split == \"random\":\n",
    "        train_dataset, valid_dataset, test_dataset = random_split(dataset, null_value=0, frac_train=0.8,frac_valid=0.1, frac_test=0.1, seed = args.seed)\n",
    "        #print(\"random\")\n",
    "elif args.split == \"random_scaffold\":\n",
    "        smiles_list = pd.read_csv('./dataset/' + args.dataset + '/processed/smiles.csv', header=None)[0].tolist()\n",
    "        train_dataset, valid_dataset, test_dataset = random_scaffold_split(dataset, smiles_list, null_value=0, frac_train=0.8,frac_valid=0.1, frac_test=0.1, seed = args.seed)\n",
    "        #print(\"random scaffold\")\n",
    "else:\n",
    "        raise ValueError(\"Invalid split option.\")\n",
    "\n",
    "#print('++++++++++', mol_train_dataset[0])\n",
    "'''\n",
    "for i, mol in enumerate(mol_train_dataset):\n",
    "    print('mol:',mol)\n",
    "'''\n",
    "#seq_mol_train_dataset=MultiDatasetMixini(seq_train_dataset,mol_train_dataset)\n",
    "#seq_mol_valid_dataset=SeqMolDataset(seq_valid_dataset,mol_valid_dataset)\n",
    "#seq_mol_test_dataset=SeqMolDataset(seq_train_dataset,mol_test_dataset)\n",
    "seq_train_dataloader1 = DataLoader(seq_train_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)######False\n",
    "mol_train_dataloader2 = GeometricDataLoader(mol_train_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)\n",
    "smile_train_dataloader3=DataLoader(smile_train_dataset,batch_size=args.batch_size,collate_fn=collate, shuffle=False,num_workers=args.num_workers)\n",
    "seq_mol_smile_train_multi_loader = MultiDataLoader(seq_train_dataloader1, mol_train_dataloader2,smile_train_dataloader3)\n",
    "# Set the shuffle parameter simultaneously for both dataloaders\n",
    "seq_mol_smile_train_multi_loader.set_shuffle(True)\n",
    "'''\n",
    "print('seq_train_dataset#########:',seq_train_dataset)\n",
    "\n",
    "for i,seq in enumerate(seq_train_dataloader1):\n",
    "    print(seq)\n",
    "'''\n",
    "seq_valid_dataloader1 = DataLoader(seq_valid_dataset, batch_size=args.batch_size,shuffle=False,num_workers=args.num_workers)######False\n",
    "mol_valid_dataloader2 = GeometricDataLoader(mol_valid_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)\n",
    "smile_valid_dataloader3=DataLoader(smile_valid_dataset, batch_size=args.batch_size,collate_fn=collate,shuffle=False,num_workers=args.num_workers)\n",
    "\n",
    "'''\n",
    "for i,m in enumerate(smile_train_dataloader3):\n",
    "    #print('m@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@:',m)\n",
    "    break\n",
    "'''\n",
    "seq_mol_smile_valid_multi_loader = MultiDataLoader(seq_valid_dataloader1, mol_valid_dataloader2,smile_valid_dataloader3)\n",
    "# Set the shuffle parameter simultaneously for both dataloaders\n",
    "seq_mol_smile_valid_multi_loader.set_shuffle(True)\n",
    "\n",
    "seq_test_dataloader1 = DataLoader(seq_test_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)######False\n",
    "mol_test_dataloader2 = GeometricDataLoader(mol_test_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)\n",
    "smile_test_dataloader3=DataLoader(smile_test_dataset,batch_size=args.batch_size,collate_fn=collate, shuffle=False,num_workers=args.num_workers)\n",
    "\n",
    "seq_mol_smile_test_multi_loader = MultiDataLoader(seq_test_dataloader1, mol_valid_dataloader2,smile_test_dataloader3)\n",
    "# Set the shuffle parameter simultaneously for both dataloaders\n",
    "seq_mol_smile_test_multi_loader.set_shuffle(True)\n",
    "'''\n",
    "for i ,(seq,mol,smile) in enumerate(seq_mol_smile_train_multi_loader):\n",
    "    print(seq)\n",
    "    print(mol)\n",
    "    print(smile)\n",
    "'''\n",
    "'''\n",
    "print('mol_dataloader:')\n",
    "for mol in mol_train_dataloader2:\n",
    "    print(mol)\n",
    "for seq in seq_train_dataloader1:\n",
    "    print(seq)\n",
    " '''   \n",
    "\n",
    "def train(args, epoch, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    save_pt='results/model2/'\n",
    "    #epoch_iter = tqdm(loader, desc=\"Iteration\")\n",
    "    for step, (A,B,C) in enumerate(loader):\n",
    "        \n",
    "        seq_data_list=[]\n",
    "        seq=A\n",
    "        lenth=len(seq)\n",
    "        for m , s in enumerate(seq):\n",
    "            seq_data_list.append((str(m),s))\n",
    "        B=B.to(device)\n",
    "        D,E=C\n",
    "        D=D.to(device)\n",
    "        E=E.to(device)\n",
    "        C=(D,E)\n",
    "        #print('D!!!!!!!!!!!!!!!!:',D)\n",
    "        #print('E#####################:',E)\n",
    "        #pred=model(seq_data_list,B,C)#model is error\n",
    "        pred=model(seq_data_list,B)#model is error\n",
    "        #pred=pred.to(torch.float32)\n",
    "        y_true = B.y.view(pred.shape).to(torch.float32)\n",
    "        #loss = criterion(pred, y_true)\n",
    "        \n",
    "        loss1=criterion(pred,y_true)\n",
    "        #loss2=criterion(u12,u34)\n",
    "        #print('loss1{0},loss2{1}:',loss1,loss2)\n",
    "        #loss=loss1+loss2\n",
    "        loss=loss1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #epoch_iter.set_description(f\"Epoch: {epoch} tloss: {loss:.4f}\")\n",
    "        nn=(epoch+1)//10\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'training Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "            torch.save(model, save_pt+f'full_model_{nn}.pt')\n",
    "    #return loss.item\n",
    "def eval(args, model, device, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    \n",
    "    #for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "    with torch.no_grad():\n",
    "        for step, (A,B,C) in enumerate(loader):\n",
    "            seq_data_list=[]\n",
    "            seq=A\n",
    "            lenth=len(seq)\n",
    "            for m , s in enumerate(seq):\n",
    "                seq_data_list.append((str(m),s))\n",
    "            B=B.to(device)\n",
    "            D,E=C\n",
    "            D=D.to(device)\n",
    "            E=E.to(device)##################\n",
    "            C=(D,E)\n",
    "        \n",
    "        \n",
    "            #pred=model(seq_data_list,B,C)#model is error\n",
    "            \n",
    "            pred=model(seq_data_list,B)#model is error\n",
    "            y_true=B.y.view(pred.shape).to(torch.float32)\n",
    "            val_loss = criterion(pred, y_true)\n",
    "            #print(f'Validation Loss: {val_loss.item():.4f}')    \n",
    "                             \n",
    "\n",
    "    #y_true = torch.cat(y_true, dim = 0).cpu().numpy()\n",
    "    #y_scores = torch.cat(y_scores, dim = 0).detach().cpu().numpy()\n",
    "    '''\n",
    "    roc_list = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        #AUC is only defined when there is at least one positive data.\n",
    "        if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == -1) > 0:\n",
    "            is_valid = y_true[:,i]**2 > 0\n",
    "            roc_list.append(roc_auc_score((y_true[is_valid,i] + 1)/2, y_scores[is_valid,i]))\n",
    "    if len(roc_list)==0:#########################\n",
    "        return 0\n",
    "    if len(roc_list) < y_true.shape[1]:\n",
    "        print(\"Some target is missing!\")\n",
    "        miss_ratio=(1 - float(len(roc_list))/y_true.shape[1])\n",
    "        print(\"Missing ratio: %f\" %(1 - float(len(roc_list))/y_true.shape[1]))\n",
    "    '''\n",
    "    \n",
    "    return val_loss.item()\n",
    "gnn_dataset = MoleculeDatasetBig(root=\"./dataset/\" + args.dataset+'/test/', dataset=args.dataset)\n",
    "seq_dataset=SeqDataset('dataset/affinity/test/processed/sequence.csv')\n",
    "smiles_dataset=SmileDataset('dataset/affinity/test/processed/smiles.csv')\n",
    "\n",
    "seq_test_dataloader1 = DataLoader(seq_test_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)######False\n",
    "mol_test_dataloader2 = GeometricDataLoader(mol_test_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)\n",
    "smile_test_dataloader3=DataLoader(smile_test_dataset,batch_size=args.batch_size,collate_fn=collate, shuffle=False,num_workers=args.num_workers)\n",
    "\n",
    "seq_mol_smile_test_multi_loader = MultiDataLoader(seq_test_dataloader1, mol_test_dataloader2,smile_test_dataloader3)\n",
    "# Set the shuffle parameter simultaneously for both dataloaders\n",
    "seq_mol_smile_test_multi_loader.set_shuffle(True)\n",
    "\n",
    "\n",
    "\n",
    "def test(args, model, device, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    \n",
    "    #for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "    with torch.no_grad():\n",
    "        for step, (A,B,C) in enumerate(loader):\n",
    "            seq_data_list=[]\n",
    "            seq=A\n",
    "            lenth=len(seq)\n",
    "            for m , s in enumerate(seq):\n",
    "                seq_data_list.append((str(m),s))\n",
    "            B=B.to(device)\n",
    "            D,E=C\n",
    "            D=D.to(device)\n",
    "            E=E.to(device)##################\n",
    "            C=(D,E)\n",
    "        \n",
    "        \n",
    "            #pred=model(seq_data_list,B,C)#model is error\n",
    "            \n",
    "            pred=model(seq_data_list,B)#model is error\n",
    "            y_true=B.y.view(pred.shape).to(torch.float32)\n",
    "            test_loss = mse_criterion(pred, y_true)\n",
    "            #print(f'Validation Loss: {val_loss.item():.4f}')    \n",
    "                             \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return test_loss.item()\n",
    "\n",
    "results_save_file='results/model2/results_save_model1.txt'\n",
    "\n",
    "\n",
    "import torch, gc\n",
    "#criterion = nn.BCEWithLogitsLoss(reduction = \"none\")\n",
    "criterion=nn.SmoothL1Loss()\n",
    "mse_criterion=nn.MSELoss()\n",
    "#criterion=nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "if not args.filename == \"\":\n",
    "    fname = 'runs/seq_mol_finetune_cls_runseed' + str(args.runseed) + '/' + args.filename\n",
    "    #delete the directory if there exists one\n",
    "    if os.path.exists(fname):\n",
    "        shutil.rmtree(fname)\n",
    "        print(\"removed the existing file.\")\n",
    "    writer = SummaryWriter(fname)\n",
    "\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "        \n",
    "    train(args, epoch, model, device, seq_mol_smile_train_multi_loader, optimizer)\n",
    "\n",
    "    print(\"====Evaluation\")\n",
    "    if args.eval_train:\n",
    "        train_loss = eval(args, model, device, seq_mol_smile_train_multi_loader)\n",
    "    else:\n",
    "        print(\"omit the training accuracy computation\")\n",
    "        train_loss = 0\n",
    "    val_loss = eval(args, model, device, seq_mol_smile_valid_multi_loader)\n",
    "    test_loss = test(args, model, device, seq_mol_smile_test_multi_loader)\n",
    "    with open(results_save_file, 'w+') as f:\n",
    "        f.write(str(epoch)+'\\t'+str(train_loss)+'\\t'+str(val_loss)+'\\n')\n",
    "        #f.write(epoch)\n",
    "        #f.write('\\t')\n",
    "        #f.write(train_loss)\n",
    "        #f.write('\\t')\n",
    "        #f.write(val_loss)\n",
    "        #f.write('\\n')\n",
    "        \n",
    "    print(\"train: %f val: %f test: %f\" %(train_loss, val_loss, test_loss))\n",
    "    \n",
    "\n",
    "gnn_dataset = MoleculeDatasetBig(root=\"./dataset/\" + args.dataset+'/test/', dataset=args.dataset)\n",
    "seq_dataset=SeqDataset('dataset/affinity/test/processed/sequence.csv')\n",
    "smiles_dataset=SmileDataset('dataset/affinity/test/processed/smiles.csv')\n",
    "\n",
    "seq_test_dataloader1 = DataLoader(seq_test_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)######False\n",
    "mol_test_dataloader2 = GeometricDataLoader(mol_test_dataset, batch_size=args.batch_size, shuffle=False,num_workers=args.num_workers)\n",
    "smile_test_dataloader3=DataLoader(smile_test_dataset,batch_size=args.batch_size,collate_fn=collate, shuffle=False,num_workers=args.num_workers)\n",
    "\n",
    "seq_mol_smile_test_multi_loader = MultiDataLoader(seq_test_dataloader1, mol_test_dataloader2,smile_test_dataloader3)\n",
    "# Set the shuffle parameter simultaneously for both dataloaders\n",
    "seq_mol_smile_test_multi_loader.set_shuffle(True)\n",
    "\n",
    "\n",
    "test_loss = test(args, model, device, seq_mol_smile_test_multi_loader)\n",
    "print(\"test: %f \" %(test_loss))    \n",
    "#mse: test_loss:0.4724404724407087\n",
    "\n",
    "#test: 0.049283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a05ab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4724404724407087\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mse=np.sqrt(0.2232)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd18fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
