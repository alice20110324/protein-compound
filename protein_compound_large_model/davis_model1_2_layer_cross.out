nohup: ignoring input
Global seed set to 42
True
Not from scratch
rese:model_gin
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Using Rotation Embedding
Pre-processed data found: /media/ext_disk/zhenfang/dataset/davis/processed/davis_train_mols.pt, loading ...
seq_train_dataset: <class 'pandas.core.series.Series'>
seq_train_dataset: <class 'loader.SeqDataset'>
scaffold
fold: 0
/home/zhenfang/anaconda3/envs/pytorch_3.8/lib/python3.8/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
fold,epoch,train_loss: 0 0 170.66844
/home/zhenfang/anaconda3/envs/pytorch_3.8/lib/python3.8/site-packages/fast_transformers/feature_maps/fourier_features.py:37: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.
The boolean parameter 'some' has been replaced with a string parameter 'mode'.
Q, R = torch.qr(A, some)
should be replaced with
Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)
  Q, _ = torch.qr(block)
fold,epoch,train_loss: 0 1 1.0780588
fold,epoch,train_loss: 0 2 1.0749147
fold,epoch,train_loss: 0 3 1.0750673
fold,epoch,train_loss: 0 4 1.0758313
fold,epoch,train_loss: 0 5 1.077771
fold,epoch,train_loss: 0 6 1.0763419
fold,epoch,train_loss: 0 7 1.0799723
fold,epoch,train_loss: 0 8 1.0805943
fold,epoch,train_loss: 0 9 1.0801325
fold,epoch,train_loss: 0 10 1.0848155
fold,epoch,train_loss: 0 11 1.0861517
fold,epoch,train_loss: 0 12 1.0887262
fold,epoch,train_loss: 0 13 1.088204
fold,epoch,train_loss: 0 14 1.08689
fold,epoch,train_loss: 0 15 1.0910767
fold,epoch,train_loss: 0 16 1.0889596
fold,epoch,train_loss: 0 17 1.0868899
fold,epoch,train_loss: 0 18 1.0922725
fold,epoch,train_loss: 0 19 1.0870568
fold,epoch,train_loss: 0 20 1.088296
fold,epoch,train_loss: 0 21 1.0892643
fold,epoch,train_loss: 0 22 1.0849192
fold,epoch,train_loss: 0 23 1.0852278
fold,epoch,train_loss: 0 24 1.0910184
fold,epoch,train_loss: 0 25 1.0893908
fold,epoch,train_loss: 0 26 1.0870019
fold,epoch,train_loss: 0 27 1.0858605
fold,epoch,train_loss: 0 28 1.0898601
fold,epoch,train_loss: 0 29 1.092798
fold,epoch,train_loss: 0 30 1.094048
fold,epoch,train_loss: 0 31 1.0922219
fold,epoch,train_loss: 0 32 1.0938457
fold,epoch,train_loss: 0 33 1.086727
fold,epoch,train_loss: 0 34 1.0888808
fold,epoch,train_loss: 0 35 1.0900314
fold,epoch,train_loss: 0 36 1.0883095
fold,epoch,train_loss: 0 37 1.0882789
fold,epoch,train_loss: 0 38 1.0879817
fold,epoch,train_loss: 0 39 1.0940667
fold,epoch,train_loss: 0 40 1.092365
fold,epoch,train_loss: 0 41 1.0893501
fold,epoch,train_loss: 0 42 1.088205
fold,epoch,train_loss: 0 43 1.0888257
fold,epoch,train_loss: 0 44 1.0879897
fold,epoch,train_loss: 0 45 1.0884286
fold,epoch,train_loss: 0 46 1.0932416
fold,epoch,train_loss: 0 47 1.0879399
fold,epoch,train_loss: 0 48 1.0896832
training Epoch: 50, train_Loss: 0.3781
training Epoch: 50, train_Loss: 0.6975
training Epoch: 50, train_Loss: 0.8947
training Epoch: 50, train_Loss: 2.4421
training Epoch: 50, train_Loss: 0.3116
training Epoch: 50, train_Loss: 0.7031
training Epoch: 50, train_Loss: 1.8909
training Epoch: 50, train_Loss: 4.5453
training Epoch: 50, train_Loss: 0.3088
training Epoch: 50, train_Loss: 1.0656
training Epoch: 50, train_Loss: 1.5090
training Epoch: 50, train_Loss: 0.3839
training Epoch: 50, train_Loss: 2.4680
training Epoch: 50, train_Loss: 1.0474
training Epoch: 50, train_Loss: 0.5119
training Epoch: 50, train_Loss: 1.0027
training Epoch: 50, train_Loss: 0.6657
training Epoch: 50, train_Loss: 0.3921
training Epoch: 50, train_Loss: 0.4119
training Epoch: 50, train_Loss: 2.4170
training Epoch: 50, train_Loss: 1.7030
training Epoch: 50, train_Loss: 0.3839
training Epoch: 50, train_Loss: 1.2849
training Epoch: 50, train_Loss: 0.6448
training Epoch: 50, train_Loss: 0.7391
training Epoch: 50, train_Loss: 1.0931
training Epoch: 50, train_Loss: 0.3828
training Epoch: 50, train_Loss: 0.5716
training Epoch: 50, train_Loss: 1.1293
training Epoch: 50, train_Loss: 0.4327
training Epoch: 50, train_Loss: 0.8130
training Epoch: 50, train_Loss: 0.9751
training Epoch: 50, train_Loss: 0.9882
training Epoch: 50, train_Loss: 0.7412
training Epoch: 50, train_Loss: 0.2654
training Epoch: 50, train_Loss: 0.5979
training Epoch: 50, train_Loss: 2.7605
training Epoch: 50, train_Loss: 1.9368
training Epoch: 50, train_Loss: 1.7005
training Epoch: 50, train_Loss: 0.2341
training Epoch: 50, train_Loss: 0.5186
training Epoch: 50, train_Loss: 2.9378
training Epoch: 50, train_Loss: 1.2484
training Epoch: 50, train_Loss: 0.4059
training Epoch: 50, train_Loss: 1.4337
training Epoch: 50, train_Loss: 2.1609
training Epoch: 50, train_Loss: 0.7735
training Epoch: 50, train_Loss: 1.8584
training Epoch: 50, train_Loss: 1.0722
training Epoch: 50, train_Loss: 0.9581
training Epoch: 50, train_Loss: 0.5927
training Epoch: 50, train_Loss: 1.1943
training Epoch: 50, train_Loss: 2.2365
training Epoch: 50, train_Loss: 1.1241
training Epoch: 50, train_Loss: 0.6334
training Epoch: 50, train_Loss: 0.5744
training Epoch: 50, train_Loss: 0.8970
training Epoch: 50, train_Loss: 0.4458
training Epoch: 50, train_Loss: 0.7630
training Epoch: 50, train_Loss: 0.4573
training Epoch: 50, train_Loss: 1.4082
training Epoch: 50, train_Loss: 0.3761
training Epoch: 50, train_Loss: 3.2485
training Epoch: 50, train_Loss: 0.3379
training Epoch: 50, train_Loss: 0.3126
training Epoch: 50, train_Loss: 0.8130
training Epoch: 50, train_Loss: 2.1613
training Epoch: 50, train_Loss: 2.2480
training Epoch: 50, train_Loss: 0.5867
training Epoch: 50, train_Loss: 1.1387
training Epoch: 50, train_Loss: 2.1278
training Epoch: 50, train_Loss: 1.1650
training Epoch: 50, train_Loss: 0.9158
training Epoch: 50, train_Loss: 1.1631
training Epoch: 50, train_Loss: 1.8707
training Epoch: 50, train_Loss: 1.1723
training Epoch: 50, train_Loss: 2.4315
training Epoch: 50, train_Loss: 1.2769
training Epoch: 50, train_Loss: 0.7092
training Epoch: 50, train_Loss: 0.7864
training Epoch: 50, train_Loss: 0.7344
training Epoch: 50, train_Loss: 2.0580
training Epoch: 50, train_Loss: 1.1042
training Epoch: 50, train_Loss: 1.4936
training Epoch: 50, train_Loss: 0.9246
training Epoch: 50, train_Loss: 1.5666
training Epoch: 50, train_Loss: 0.6364
training Epoch: 50, train_Loss: 0.6774
training Epoch: 50, train_Loss: 1.2025
training Epoch: 50, train_Loss: 0.8979
training Epoch: 50, train_Loss: 0.8237
training Epoch: 50, train_Loss: 1.3887
training Epoch: 50, train_Loss: 1.7964
training Epoch: 50, train_Loss: 0.3886
training Epoch: 50, train_Loss: 0.9574
training Epoch: 50, train_Loss: 0.7079
training Epoch: 50, train_Loss: 0.3109
training Epoch: 50, train_Loss: 0.8926
training Epoch: 50, train_Loss: 1.1896
training Epoch: 50, train_Loss: 0.1662
training Epoch: 50, train_Loss: 0.2475
training Epoch: 50, train_Loss: 1.0388
training Epoch: 50, train_Loss: 1.4888
training Epoch: 50, train_Loss: 0.1116
training Epoch: 50, train_Loss: 1.6112
training Epoch: 50, train_Loss: 0.1376
training Epoch: 50, train_Loss: 0.3184
training Epoch: 50, train_Loss: 0.6376
training Epoch: 50, train_Loss: 0.1507
training Epoch: 50, train_Loss: 2.0176
training Epoch: 50, train_Loss: 0.9557
training Epoch: 50, train_Loss: 0.7207
training Epoch: 50, train_Loss: 0.2296
training Epoch: 50, train_Loss: 0.9199
training Epoch: 50, train_Loss: 1.0865
training Epoch: 50, train_Loss: 0.2665
training Epoch: 50, train_Loss: 0.5115
training Epoch: 50, train_Loss: 0.2396
training Epoch: 50, train_Loss: 0.9205
training Epoch: 50, train_Loss: 0.1858
training Epoch: 50, train_Loss: 0.6772
training Epoch: 50, train_Loss: 0.6916
training Epoch: 50, train_Loss: 0.5951
training Epoch: 50, train_Loss: 2.5024
training Epoch: 50, train_Loss: 2.5235
training Epoch: 50, train_Loss: 0.3197
training Epoch: 50, train_Loss: 1.4066
training Epoch: 50, train_Loss: 1.9699
training Epoch: 50, train_Loss: 0.6188
training Epoch: 50, train_Loss: 0.6961
training Epoch: 50, train_Loss: 0.6225
training Epoch: 50, train_Loss: 1.0370
training Epoch: 50, train_Loss: 0.5824
training Epoch: 50, train_Loss: 0.7748
training Epoch: 50, train_Loss: 0.8726
training Epoch: 50, train_Loss: 0.6596
training Epoch: 50, train_Loss: 0.7540
training Epoch: 50, train_Loss: 2.6444
training Epoch: 50, train_Loss: 1.4995
training Epoch: 50, train_Loss: 1.2158
training Epoch: 50, train_Loss: 0.7506
training Epoch: 50, train_Loss: 1.5808
training Epoch: 50, train_Loss: 2.6576
training Epoch: 50, train_Loss: 1.3713
training Epoch: 50, train_Loss: 2.7770
training Epoch: 50, train_Loss: 1.2105
training Epoch: 50, train_Loss: 0.7266
training Epoch: 50, train_Loss: 0.8385
training Epoch: 50, train_Loss: 2.6995
training Epoch: 50, train_Loss: 1.9954
training Epoch: 50, train_Loss: 1.5756
training Epoch: 50, train_Loss: 1.7785
training Epoch: 50, train_Loss: 0.8181
training Epoch: 50, train_Loss: 0.7577
training Epoch: 50, train_Loss: 1.0499
training Epoch: 50, train_Loss: 0.6234
training Epoch: 50, train_Loss: 1.8832
training Epoch: 50, train_Loss: 2.0437
training Epoch: 50, train_Loss: 0.8521
training Epoch: 50, train_Loss: 1.2126
training Epoch: 50, train_Loss: 0.3121
training Epoch: 50, train_Loss: 1.1729
training Epoch: 50, train_Loss: 0.3329
training Epoch: 50, train_Loss: 0.2596
training Epoch: 50, train_Loss: 0.3265
training Epoch: 50, train_Loss: 1.3355
training Epoch: 50, train_Loss: 0.4134
training Epoch: 50, train_Loss: 0.1777
training Epoch: 50, train_Loss: 1.1017
training Epoch: 50, train_Loss: 1.2407
training Epoch: 50, train_Loss: 0.6340
training Epoch: 50, train_Loss: 1.0346
training Epoch: 50, train_Loss: 1.4568
training Epoch: 50, train_Loss: 1.3786
training Epoch: 50, train_Loss: 0.1180
training Epoch: 50, train_Loss: 0.8545
training Epoch: 50, train_Loss: 1.3373
training Epoch: 50, train_Loss: 0.6327
training Epoch: 50, train_Loss: 0.1583
training Epoch: 50, train_Loss: 0.6953
training Epoch: 50, train_Loss: 2.5016
training Epoch: 50, train_Loss: 0.7200
training Epoch: 50, train_Loss: 1.2115
training Epoch: 50, train_Loss: 0.3370
training Epoch: 50, train_Loss: 1.3758
training Epoch: 50, train_Loss: 0.5783
training Epoch: 50, train_Loss: 0.8247
training Epoch: 50, train_Loss: 1.5745
training Epoch: 50, train_Loss: 0.4244
training Epoch: 50, train_Loss: 0.4500
training Epoch: 50, train_Loss: 0.3770
training Epoch: 50, train_Loss: 0.7849
training Epoch: 50, train_Loss: 1.3189
training Epoch: 50, train_Loss: 0.3832
training Epoch: 50, train_Loss: 1.1395
training Epoch: 50, train_Loss: 0.5652
training Epoch: 50, train_Loss: 0.9910
training Epoch: 50, train_Loss: 1.7142
training Epoch: 50, train_Loss: 1.7474
training Epoch: 50, train_Loss: 1.4484
training Epoch: 50, train_Loss: 0.7988
training Epoch: 50, train_Loss: 0.8230
training Epoch: 50, train_Loss: 1.1119
training Epoch: 50, train_Loss: 2.4567
training Epoch: 50, train_Loss: 0.5219
training Epoch: 50, train_Loss: 0.6759
training Epoch: 50, train_Loss: 2.1700
training Epoch: 50, train_Loss: 2.2390
training Epoch: 50, train_Loss: 0.8200
training Epoch: 50, train_Loss: 0.4112
training Epoch: 50, train_Loss: 1.7061
training Epoch: 50, train_Loss: 0.6007
training Epoch: 50, train_Loss: 1.5404
training Epoch: 50, train_Loss: 0.7501
training Epoch: 50, train_Loss: 0.6462
training Epoch: 50, train_Loss: 0.6019
training Epoch: 50, train_Loss: 1.1653
training Epoch: 50, train_Loss: 1.4772
training Epoch: 50, train_Loss: 0.6339
training Epoch: 50, train_Loss: 0.8373
training Epoch: 50, train_Loss: 0.4480
training Epoch: 50, train_Loss: 0.6054
training Epoch: 50, train_Loss: 0.6532
training Epoch: 50, train_Loss: 0.5894
training Epoch: 50, train_Loss: 0.6303
training Epoch: 50, train_Loss: 1.1795
training Epoch: 50, train_Loss: 3.0963
training Epoch: 50, train_Loss: 2.0942
training Epoch: 50, train_Loss: 0.4762
training Epoch: 50, train_Loss: 1.5517
training Epoch: 50, train_Loss: 1.4471
training Epoch: 50, train_Loss: 0.3145
training Epoch: 50, train_Loss: 0.8850
training Epoch: 50, train_Loss: 2.4186
training Epoch: 50, train_Loss: 0.5062
training Epoch: 50, train_Loss: 0.3557
training Epoch: 50, train_Loss: 0.6432
training Epoch: 50, train_Loss: 0.8989
training Epoch: 50, train_Loss: 1.1894
training Epoch: 50, train_Loss: 1.2464
training Epoch: 50, train_Loss: 0.5883
training Epoch: 50, train_Loss: 0.4918
training Epoch: 50, train_Loss: 1.1726
training Epoch: 50, train_Loss: 0.8255
training Epoch: 50, train_Loss: 0.6229
training Epoch: 50, train_Loss: 0.9383
training Epoch: 50, train_Loss: 1.0969
training Epoch: 50, train_Loss: 0.2760
training Epoch: 50, train_Loss: 0.8962
training Epoch: 50, train_Loss: 0.5303
training Epoch: 50, train_Loss: 1.3955
training Epoch: 50, train_Loss: 2.5118
training Epoch: 50, train_Loss: 1.1740
training Epoch: 50, train_Loss: 0.8599
training Epoch: 50, train_Loss: 0.3406
training Epoch: 50, train_Loss: 1.3904
training Epoch: 50, train_Loss: 0.5349
training Epoch: 50, train_Loss: 0.3924
training Epoch: 50, train_Loss: 1.7332
training Epoch: 50, train_Loss: 0.4036
training Epoch: 50, train_Loss: 1.6084
training Epoch: 50, train_Loss: 0.5513
training Epoch: 50, train_Loss: 0.6842
training Epoch: 50, train_Loss: 2.0026
training Epoch: 50, train_Loss: 1.0377
training Epoch: 50, train_Loss: 0.6426
training Epoch: 50, train_Loss: 1.8546
training Epoch: 50, train_Loss: 4.0970
training Epoch: 50, train_Loss: 2.3782
training Epoch: 50, train_Loss: 0.5171
training Epoch: 50, train_Loss: 0.5212
training Epoch: 50, train_Loss: 1.2328
training Epoch: 50, train_Loss: 0.5779
training Epoch: 50, train_Loss: 0.4444
training Epoch: 50, train_Loss: 1.8099
training Epoch: 50, train_Loss: 0.7013
training Epoch: 50, train_Loss: 1.2605
training Epoch: 50, train_Loss: 0.6616
training Epoch: 50, train_Loss: 1.1234
training Epoch: 50, train_Loss: 2.2581
training Epoch: 50, train_Loss: 1.2806
training Epoch: 50, train_Loss: 2.2927
training Epoch: 50, train_Loss: 1.1587
training Epoch: 50, train_Loss: 0.9124
training Epoch: 50, train_Loss: 2.1595
training Epoch: 50, train_Loss: 0.8820
training Epoch: 50, train_Loss: 0.6795
training Epoch: 50, train_Loss: 1.1295
training Epoch: 50, train_Loss: 1.4135
training Epoch: 50, train_Loss: 0.8655
training Epoch: 50, train_Loss: 0.9786
training Epoch: 50, train_Loss: 0.5738
training Epoch: 50, train_Loss: 0.6519
training Epoch: 50, train_Loss: 0.8742
training Epoch: 50, train_Loss: 1.7738
training Epoch: 50, train_Loss: 1.5142
training Epoch: 50, train_Loss: 2.9191
training Epoch: 50, train_Loss: 0.8415
training Epoch: 50, train_Loss: 1.2537
training Epoch: 50, train_Loss: 1.7138
training Epoch: 50, train_Loss: 0.4012
training Epoch: 50, train_Loss: 1.9993
training Epoch: 50, train_Loss: 1.2653
training Epoch: 50, train_Loss: 0.9583
training Epoch: 50, train_Loss: 1.1453
training Epoch: 50, train_Loss: 1.0460
training Epoch: 50, train_Loss: 0.4207
training Epoch: 50, train_Loss: 1.0608
training Epoch: 50, train_Loss: 1.7941
training Epoch: 50, train_Loss: 1.0232
training Epoch: 50, train_Loss: 1.2343
training Epoch: 50, train_Loss: 1.1839
training Epoch: 50, train_Loss: 0.9024
training Epoch: 50, train_Loss: 1.0998
training Epoch: 50, train_Loss: 0.6284
training Epoch: 50, train_Loss: 1.1156
training Epoch: 50, train_Loss: 0.6957
training Epoch: 50, train_Loss: 0.6931
training Epoch: 50, train_Loss: 0.5549
training Epoch: 50, train_Loss: 0.8296
training Epoch: 50, train_Loss: 0.7830
training Epoch: 50, train_Loss: 0.6716
training Epoch: 50, train_Loss: 0.6486
training Epoch: 50, train_Loss: 0.3464
training Epoch: 50, train_Loss: 0.4458
training Epoch: 50, train_Loss: 1.6974
training Epoch: 50, train_Loss: 1.9067
training Epoch: 50, train_Loss: 1.0971
training Epoch: 50, train_Loss: 0.7655
training Epoch: 50, train_Loss: 0.4656
training Epoch: 50, train_Loss: 1.2440
training Epoch: 50, train_Loss: 0.2157
training Epoch: 50, train_Loss: 0.9444
training Epoch: 50, train_Loss: 0.5140
training Epoch: 50, train_Loss: 1.2201
training Epoch: 50, train_Loss: 0.4473
training Epoch: 50, train_Loss: 2.7316
training Epoch: 50, train_Loss: 1.0438
training Epoch: 50, train_Loss: 0.2565
training Epoch: 50, train_Loss: 1.4119
training Epoch: 50, train_Loss: 0.6463
training Epoch: 50, train_Loss: 0.3229
training Epoch: 50, train_Loss: 1.1834
training Epoch: 50, train_Loss: 0.7684
training Epoch: 50, train_Loss: 0.9372
training Epoch: 50, train_Loss: 0.4316
training Epoch: 50, train_Loss: 0.4448
training Epoch: 50, train_Loss: 2.5190
training Epoch: 50, train_Loss: 0.6121
training Epoch: 50, train_Loss: 0.6727
training Epoch: 50, train_Loss: 0.6976
training Epoch: 50, train_Loss: 3.0194
training Epoch: 50, train_Loss: 0.9286
training Epoch: 50, train_Loss: 0.7903
training Epoch: 50, train_Loss: 0.6547
training Epoch: 50, train_Loss: 1.3018
training Epoch: 50, train_Loss: 1.4654
training Epoch: 50, train_Loss: 0.9480
training Epoch: 50, train_Loss: 1.8236
training Epoch: 50, train_Loss: 0.5507
training Epoch: 50, train_Loss: 2.7198
training Epoch: 50, train_Loss: 0.3271
training Epoch: 50, train_Loss: 0.5062
training Epoch: 50, train_Loss: 2.3296
training Epoch: 50, train_Loss: 0.9810
training Epoch: 50, train_Loss: 0.6377
training Epoch: 50, train_Loss: 1.0210
training Epoch: 50, train_Loss: 0.9732
training Epoch: 50, train_Loss: 0.6326
training Epoch: 50, train_Loss: 2.0852
training Epoch: 50, train_Loss: 1.7948
training Epoch: 50, train_Loss: 1.2509
training Epoch: 50, train_Loss: 0.8618
training Epoch: 50, train_Loss: 0.7625
training Epoch: 50, train_Loss: 1.2597
training Epoch: 50, train_Loss: 1.1560
training Epoch: 50, train_Loss: 0.6921
training Epoch: 50, train_Loss: 1.5798
training Epoch: 50, train_Loss: 0.7176
training Epoch: 50, train_Loss: 0.6330
training Epoch: 50, train_Loss: 0.4675
training Epoch: 50, train_Loss: 0.9755
training Epoch: 50, train_Loss: 1.2814
training Epoch: 50, train_Loss: 0.7064
training Epoch: 50, train_Loss: 1.0677
training Epoch: 50, train_Loss: 0.5115
training Epoch: 50, train_Loss: 0.4738
training Epoch: 50, train_Loss: 2.0349
training Epoch: 50, train_Loss: 0.4551
training Epoch: 50, train_Loss: 1.3723
training Epoch: 50, train_Loss: 0.1621
training Epoch: 50, train_Loss: 0.3174
training Epoch: 50, train_Loss: 1.9102
training Epoch: 50, train_Loss: 0.1448
training Epoch: 50, train_Loss: 0.5567
training Epoch: 50, train_Loss: 3.2346
training Epoch: 50, train_Loss: 1.1743
training Epoch: 50, train_Loss: 0.5496
training Epoch: 50, train_Loss: 0.5750
training Epoch: 50, train_Loss: 2.2788
training Epoch: 50, train_Loss: 0.5881
training Epoch: 50, train_Loss: 1.0101
training Epoch: 50, train_Loss: 0.5140
training Epoch: 50, train_Loss: 0.6510
training Epoch: 50, train_Loss: 0.7818
training Epoch: 50, train_Loss: 2.0451
training Epoch: 50, train_Loss: 1.6839
training Epoch: 50, train_Loss: 0.9851
training Epoch: 50, train_Loss: 3.9329
training Epoch: 50, train_Loss: 2.0973
training Epoch: 50, train_Loss: 1.3740
training Epoch: 50, train_Loss: 0.7195
training Epoch: 50, train_Loss: 1.2044
training Epoch: 50, train_Loss: 0.6944
training Epoch: 50, train_Loss: 0.6546
training Epoch: 50, train_Loss: 0.5777
training Epoch: 50, train_Loss: 0.5447
training Epoch: 50, train_Loss: 0.8555
training Epoch: 50, train_Loss: 0.3374
training Epoch: 50, train_Loss: 1.1653
training Epoch: 50, train_Loss: 0.9269
training Epoch: 50, train_Loss: 0.3602
training Epoch: 50, train_Loss: 1.3821
training Epoch: 50, train_Loss: 0.9213
training Epoch: 50, train_Loss: 0.2669
training Epoch: 50, train_Loss: 1.5088
training Epoch: 50, train_Loss: 3.7367
training Epoch: 50, train_Loss: 1.6362
training Epoch: 50, train_Loss: 0.4034
training Epoch: 50, train_Loss: 1.6309
training Epoch: 50, train_Loss: 0.5645
training Epoch: 50, train_Loss: 2.6952
training Epoch: 50, train_Loss: 0.3909
training Epoch: 50, train_Loss: 0.3893
training Epoch: 50, train_Loss: 0.3457
training Epoch: 50, train_Loss: 1.5197
training Epoch: 50, train_Loss: 0.8965
training Epoch: 50, train_Loss: 1.5179
training Epoch: 50, train_Loss: 0.5902
training Epoch: 50, train_Loss: 0.3937
training Epoch: 50, train_Loss: 1.2793
training Epoch: 50, train_Loss: 1.5712
training Epoch: 50, train_Loss: 1.4089
training Epoch: 50, train_Loss: 0.5005
training Epoch: 50, train_Loss: 1.9594
training Epoch: 50, train_Loss: 0.8761
training Epoch: 50, train_Loss: 0.5877
training Epoch: 50, train_Loss: 0.8208
training Epoch: 50, train_Loss: 2.0160
training Epoch: 50, train_Loss: 1.2918
training Epoch: 50, train_Loss: 1.6542
training Epoch: 50, train_Loss: 0.6629
training Epoch: 50, train_Loss: 0.9479
training Epoch: 50, train_Loss: 1.1374
training Epoch: 50, train_Loss: 0.5866
training Epoch: 50, train_Loss: 1.8111
training Epoch: 50, train_Loss: 0.8404
training Epoch: 50, train_Loss: 1.1239
training Epoch: 50, train_Loss: 0.4656
training Epoch: 50, train_Loss: 1.1233
training Epoch: 50, train_Loss: 0.6214
training Epoch: 50, train_Loss: 0.7717
training Epoch: 50, train_Loss: 0.4604
training Epoch: 50, train_Loss: 0.9080
training Epoch: 50, train_Loss: 1.6829
training Epoch: 50, train_Loss: 0.8971
training Epoch: 50, train_Loss: 1.2824
training Epoch: 50, train_Loss: 0.4344
training Epoch: 50, train_Loss: 3.6129
training Epoch: 50, train_Loss: 0.5642
training Epoch: 50, train_Loss: 0.9975
training Epoch: 50, train_Loss: 1.8732
training Epoch: 50, train_Loss: 0.5669
training Epoch: 50, train_Loss: 0.9043
training Epoch: 50, train_Loss: 1.7432
training Epoch: 50, train_Loss: 0.9619
training Epoch: 50, train_Loss: 0.4973
training Epoch: 50, train_Loss: 0.8084
training Epoch: 50, train_Loss: 1.5494
training Epoch: 50, train_Loss: 2.2817
training Epoch: 50, train_Loss: 1.0230
training Epoch: 50, train_Loss: 1.4341
training Epoch: 50, train_Loss: 0.9757
training Epoch: 50, train_Loss: 0.7495
training Epoch: 50, train_Loss: 1.2282
training Epoch: 50, train_Loss: 2.3952
training Epoch: 50, train_Loss: 0.4812
training Epoch: 50, train_Loss: 2.3611
training Epoch: 50, train_Loss: 0.8939
training Epoch: 50, train_Loss: 0.6187
training Epoch: 50, train_Loss: 1.0514
training Epoch: 50, train_Loss: 0.6175
training Epoch: 50, train_Loss: 0.8430
training Epoch: 50, train_Loss: 0.4677
training Epoch: 50, train_Loss: 0.8309
training Epoch: 50, train_Loss: 1.6297
training Epoch: 50, train_Loss: 0.9061
training Epoch: 50, train_Loss: 0.7460
training Epoch: 50, train_Loss: 0.3548
training Epoch: 50, train_Loss: 0.8541
training Epoch: 50, train_Loss: 1.9204
training Epoch: 50, train_Loss: 0.8562
training Epoch: 50, train_Loss: 1.5909
training Epoch: 50, train_Loss: 0.8736
training Epoch: 50, train_Loss: 1.5310
training Epoch: 50, train_Loss: 1.1396
training Epoch: 50, train_Loss: 1.2254
training Epoch: 50, train_Loss: 2.1833
training Epoch: 50, train_Loss: 3.0314
training Epoch: 50, train_Loss: 0.8692
training Epoch: 50, train_Loss: 0.8655
training Epoch: 50, train_Loss: 2.6552
training Epoch: 50, train_Loss: 0.6482
training Epoch: 50, train_Loss: 0.6100
training Epoch: 50, train_Loss: 1.9199
training Epoch: 50, train_Loss: 1.4059
training Epoch: 50, train_Loss: 1.0390
training Epoch: 50, train_Loss: 0.7447
training Epoch: 50, train_Loss: 1.2226
training Epoch: 50, train_Loss: 1.2264
training Epoch: 50, train_Loss: 0.5484
training Epoch: 50, train_Loss: 0.7981
training Epoch: 50, train_Loss: 0.4533
training Epoch: 50, train_Loss: 1.0771
training Epoch: 50, train_Loss: 1.3288
training Epoch: 50, train_Loss: 0.5752
training Epoch: 50, train_Loss: 0.5836
training Epoch: 50, train_Loss: 0.4081
training Epoch: 50, train_Loss: 1.5386
training Epoch: 50, train_Loss: 1.0354
training Epoch: 50, train_Loss: 0.3411
training Epoch: 50, train_Loss: 0.3993
training Epoch: 50, train_Loss: 0.7454
training Epoch: 50, train_Loss: 0.1494
training Epoch: 50, train_Loss: 1.9752
training Epoch: 50, train_Loss: 1.7705
training Epoch: 50, train_Loss: 0.7296
training Epoch: 50, train_Loss: 0.8937
training Epoch: 50, train_Loss: 3.1296
training Epoch: 50, train_Loss: 0.3299
training Epoch: 50, train_Loss: 0.3372
training Epoch: 50, train_Loss: 2.0454
training Epoch: 50, train_Loss: 0.5651
training Epoch: 50, train_Loss: 1.2781
training Epoch: 50, train_Loss: 2.5773
training Epoch: 50, train_Loss: 0.6943
training Epoch: 50, train_Loss: 0.3939
training Epoch: 50, train_Loss: 0.3503
training Epoch: 50, train_Loss: 1.5279
training Epoch: 50, train_Loss: 2.3160
training Epoch: 50, train_Loss: 0.3214
training Epoch: 50, train_Loss: 1.1419
training Epoch: 50, train_Loss: 1.8582
training Epoch: 50, train_Loss: 1.1546
training Epoch: 50, train_Loss: 2.1669
training Epoch: 50, train_Loss: 0.7804
training Epoch: 50, train_Loss: 0.6476
training Epoch: 50, train_Loss: 2.7002
training Epoch: 50, train_Loss: 0.8450
training Epoch: 50, train_Loss: 1.5800
training Epoch: 50, train_Loss: 0.9203
training Epoch: 50, train_Loss: 0.6109
training Epoch: 50, train_Loss: 0.8760
training Epoch: 50, train_Loss: 0.7495
training Epoch: 50, train_Loss: 0.4698
training Epoch: 50, train_Loss: 1.1053
training Epoch: 50, train_Loss: 1.1145
training Epoch: 50, train_Loss: 1.2847
training Epoch: 50, train_Loss: 2.6375
training Epoch: 50, train_Loss: 0.5292
training Epoch: 50, train_Loss: 1.1126
training Epoch: 50, train_Loss: 0.8728
training Epoch: 50, train_Loss: 0.7122
training Epoch: 50, train_Loss: 1.0936
training Epoch: 50, train_Loss: 0.3199
fold,epoch,train_loss: 0 49 1.0888778
fold,epoch,train_loss: 0 50 1.0906142
fold,epoch,train_loss: 0 51 1.0866482
fold,epoch,train_loss: 0 52 1.0951703
fold,epoch,train_loss: 0 53 1.0849726
fold,epoch,train_loss: 0 54 1.089324
fold,epoch,train_loss: 0 55 1.0870916
fold,epoch,train_loss: 0 56 1.0877848
fold,epoch,train_loss: 0 57 1.0872661
fold,epoch,train_loss: 0 58 1.0930221
fold,epoch,train_loss: 0 59 1.0871376
fold,epoch,train_loss: 0 60 1.0854076
fold,epoch,train_loss: 0 61 1.0912653
fold,epoch,train_loss: 0 62 1.0925337
fold,epoch,train_loss: 0 63 1.0869262
fold,epoch,train_loss: 0 64 1.0863497
fold,epoch,train_loss: 0 65 1.0887344
fold,epoch,train_loss: 0 66 1.087196
fold,epoch,train_loss: 0 67 1.089214
fold,epoch,train_loss: 0 68 1.0859176
fold,epoch,train_loss: 0 69 1.0898308
fold,epoch,train_loss: 0 70 1.0878533
fold,epoch,train_loss: 0 71 1.0887737
fold,epoch,train_loss: 0 72 1.0890498
fold,epoch,train_loss: 0 73 1.0836128
fold,epoch,train_loss: 0 74 1.0896873
fold,epoch,train_loss: 0 75 1.0907401
fold,epoch,train_loss: 0 76 1.090159
fold,epoch,train_loss: 0 77 1.0860039
fold,epoch,train_loss: 0 78 1.0889249
fold,epoch,train_loss: 0 79 1.0900471
fold,epoch,train_loss: 0 80 1.08736
fold,epoch,train_loss: 0 81 1.0898151
fold,epoch,train_loss: 0 82 1.0938957
fold,epoch,train_loss: 0 83 1.0859947
fold,epoch,train_loss: 0 84 1.0895137
fold,epoch,train_loss: 0 85 1.091662
fold,epoch,train_loss: 0 86 1.0865808
fold,epoch,train_loss: 0 87 1.0863547
fold,epoch,train_loss: 0 88 1.086957
fold,epoch,train_loss: 0 89 1.095032
fold,epoch,train_loss: 0 90 1.0907061
fold,epoch,train_loss: 0 91 1.0919892
fold,epoch,train_loss: 0 92 1.0925086
fold,epoch,train_loss: 0 93 1.0934409
fold,epoch,train_loss: 0 94 1.0943787
fold,epoch,train_loss: 0 95 1.087118
fold,epoch,train_loss: 0 96 1.0925926
fold,epoch,train_loss: 0 97 1.0890733
fold,epoch,train_loss: 0 98 1.0872362
training Epoch: 100, train_Loss: 0.6435
training Epoch: 100, train_Loss: 1.2777
training Epoch: 100, train_Loss: 0.9709
training Epoch: 100, train_Loss: 0.8799
training Epoch: 100, train_Loss: 0.9870
training Epoch: 100, train_Loss: 0.9886
training Epoch: 100, train_Loss: 1.8745
training Epoch: 100, train_Loss: 1.5032
training Epoch: 100, train_Loss: 1.8668
training Epoch: 100, train_Loss: 1.7792
training Epoch: 100, train_Loss: 0.3686
training Epoch: 100, train_Loss: 1.3302
training Epoch: 100, train_Loss: 0.3040
training Epoch: 100, train_Loss: 1.0536
training Epoch: 100, train_Loss: 1.3855
training Epoch: 100, train_Loss: 2.6514
training Epoch: 100, train_Loss: 0.8881
training Epoch: 100, train_Loss: 0.7533
training Epoch: 100, train_Loss: 2.1123
training Epoch: 100, train_Loss: 1.6681
training Epoch: 100, train_Loss: 0.5876
training Epoch: 100, train_Loss: 0.6334
training Epoch: 100, train_Loss: 1.1651
training Epoch: 100, train_Loss: 1.4206
training Epoch: 100, train_Loss: 0.6831
training Epoch: 100, train_Loss: 1.3782
training Epoch: 100, train_Loss: 0.6480
training Epoch: 100, train_Loss: 0.4748
training Epoch: 100, train_Loss: 0.6128
training Epoch: 100, train_Loss: 0.5308
training Epoch: 100, train_Loss: 1.2076
training Epoch: 100, train_Loss: 1.0775
training Epoch: 100, train_Loss: 0.9943
training Epoch: 100, train_Loss: 0.7755
training Epoch: 100, train_Loss: 0.3440
training Epoch: 100, train_Loss: 0.6173
training Epoch: 100, train_Loss: 0.3242
training Epoch: 100, train_Loss: 2.7694
training Epoch: 100, train_Loss: 0.3054
training Epoch: 100, train_Loss: 1.9082
training Epoch: 100, train_Loss: 1.2144
training Epoch: 100, train_Loss: 1.0001
training Epoch: 100, train_Loss: 0.2236
training Epoch: 100, train_Loss: 1.0309
training Epoch: 100, train_Loss: 1.2989
training Epoch: 100, train_Loss: 2.1237
training Epoch: 100, train_Loss: 1.1536
training Epoch: 100, train_Loss: 1.1053
training Epoch: 100, train_Loss: 1.9006
training Epoch: 100, train_Loss: 0.4548
training Epoch: 100, train_Loss: 1.0589
training Epoch: 100, train_Loss: 0.3342
training Epoch: 100, train_Loss: 0.3543
training Epoch: 100, train_Loss: 1.8756
training Epoch: 100, train_Loss: 0.6393
training Epoch: 100, train_Loss: 0.6261
training Epoch: 100, train_Loss: 0.6597
training Epoch: 100, train_Loss: 0.4220
training Epoch: 100, train_Loss: 0.9873
training Epoch: 100, train_Loss: 0.6859
training Epoch: 100, train_Loss: 0.7874
training Epoch: 100, train_Loss: 1.5131
training Epoch: 100, train_Loss: 0.3544
training Epoch: 100, train_Loss: 0.4971
training Epoch: 100, train_Loss: 0.5019
training Epoch: 100, train_Loss: 2.2177
training Epoch: 100, train_Loss: 1.1074
training Epoch: 100, train_Loss: 0.6363
training Epoch: 100, train_Loss: 2.5976
training Epoch: 100, train_Loss: 0.9036
training Epoch: 100, train_Loss: 0.4647
training Epoch: 100, train_Loss: 0.7355
training Epoch: 100, train_Loss: 4.3737
training Epoch: 100, train_Loss: 1.1368
training Epoch: 100, train_Loss: 0.9650
training Epoch: 100, train_Loss: 1.1758
training Epoch: 100, train_Loss: 1.0542
training Epoch: 100, train_Loss: 1.1811
training Epoch: 100, train_Loss: 0.7089
training Epoch: 100, train_Loss: 0.9555
training Epoch: 100, train_Loss: 0.5433
training Epoch: 100, train_Loss: 0.5693
training Epoch: 100, train_Loss: 1.1874
training Epoch: 100, train_Loss: 0.7476
training Epoch: 100, train_Loss: 2.1382
training Epoch: 100, train_Loss: 1.8506
training Epoch: 100, train_Loss: 3.2693
training Epoch: 100, train_Loss: 1.0485
training Epoch: 100, train_Loss: 1.6609
training Epoch: 100, train_Loss: 0.9579
training Epoch: 100, train_Loss: 0.5284
training Epoch: 100, train_Loss: 0.6734
training Epoch: 100, train_Loss: 1.1483
training Epoch: 100, train_Loss: 0.9543
training Epoch: 100, train_Loss: 0.8262
training Epoch: 100, train_Loss: 0.5768
training Epoch: 100, train_Loss: 0.7181
training Epoch: 100, train_Loss: 1.7034
training Epoch: 100, train_Loss: 0.5164
training Epoch: 100, train_Loss: 2.2969
training Epoch: 100, train_Loss: 0.4578
training Epoch: 100, train_Loss: 1.4754
training Epoch: 100, train_Loss: 0.5306
training Epoch: 100, train_Loss: 0.4555
training Epoch: 100, train_Loss: 0.3425
training Epoch: 100, train_Loss: 0.5379
training Epoch: 100, train_Loss: 0.8739
training Epoch: 100, train_Loss: 1.2699
training Epoch: 100, train_Loss: 1.4882
training Epoch: 100, train_Loss: 0.9458
training Epoch: 100, train_Loss: 0.3649
training Epoch: 100, train_Loss: 0.7783
training Epoch: 100, train_Loss: 0.2932
training Epoch: 100, train_Loss: 1.0282
training Epoch: 100, train_Loss: 1.1017
training Epoch: 100, train_Loss: 3.6909
training Epoch: 100, train_Loss: 1.1482
training Epoch: 100, train_Loss: 2.3443
training Epoch: 100, train_Loss: 0.5379
training Epoch: 100, train_Loss: 0.8824
training Epoch: 100, train_Loss: 0.4637
training Epoch: 100, train_Loss: 0.3870
training Epoch: 100, train_Loss: 1.6813
training Epoch: 100, train_Loss: 0.3594
training Epoch: 100, train_Loss: 0.7163
training Epoch: 100, train_Loss: 1.5153
training Epoch: 100, train_Loss: 0.6402
training Epoch: 100, train_Loss: 0.7857
training Epoch: 100, train_Loss: 0.8564
training Epoch: 100, train_Loss: 0.4461
training Epoch: 100, train_Loss: 0.8334
training Epoch: 100, train_Loss: 0.5282
training Epoch: 100, train_Loss: 1.3738
training Epoch: 100, train_Loss: 1.2461
training Epoch: 100, train_Loss: 0.8156
training Epoch: 100, train_Loss: 1.2899
training Epoch: 100, train_Loss: 1.2176
training Epoch: 100, train_Loss: 0.5459
training Epoch: 100, train_Loss: 0.3371
training Epoch: 100, train_Loss: 0.4843
training Epoch: 100, train_Loss: 0.4867
training Epoch: 100, train_Loss: 0.8537
training Epoch: 100, train_Loss: 0.3079
training Epoch: 100, train_Loss: 2.1075
training Epoch: 100, train_Loss: 0.7796
training Epoch: 100, train_Loss: 0.9026
training Epoch: 100, train_Loss: 2.7734
training Epoch: 100, train_Loss: 0.5570
training Epoch: 100, train_Loss: 0.8079
training Epoch: 100, train_Loss: 0.3792
training Epoch: 100, train_Loss: 1.1794
training Epoch: 100, train_Loss: 0.6235
training Epoch: 100, train_Loss: 1.4595
training Epoch: 100, train_Loss: 0.8747
training Epoch: 100, train_Loss: 0.7206
training Epoch: 100, train_Loss: 1.6738
training Epoch: 100, train_Loss: 0.7491
training Epoch: 100, train_Loss: 0.9766
training Epoch: 100, train_Loss: 1.5760
training Epoch: 100, train_Loss: 0.4998
training Epoch: 100, train_Loss: 0.7128
training Epoch: 100, train_Loss: 1.2071
training Epoch: 100, train_Loss: 0.3845
training Epoch: 100, train_Loss: 0.8811
training Epoch: 100, train_Loss: 0.6271
training Epoch: 100, train_Loss: 0.6550
training Epoch: 100, train_Loss: 2.5447
training Epoch: 100, train_Loss: 2.9537
training Epoch: 100, train_Loss: 0.7904
training Epoch: 100, train_Loss: 1.0960
training Epoch: 100, train_Loss: 0.7191
training Epoch: 100, train_Loss: 0.6335
training Epoch: 100, train_Loss: 0.9964
training Epoch: 100, train_Loss: 1.0255
training Epoch: 100, train_Loss: 0.5960
training Epoch: 100, train_Loss: 0.7698
training Epoch: 100, train_Loss: 0.7840
training Epoch: 100, train_Loss: 0.4910
training Epoch: 100, train_Loss: 1.3212
training Epoch: 100, train_Loss: 0.5481
training Epoch: 100, train_Loss: 0.4824
training Epoch: 100, train_Loss: 0.5294
training Epoch: 100, train_Loss: 0.3941
training Epoch: 100, train_Loss: 0.5490
training Epoch: 100, train_Loss: 0.9359
training Epoch: 100, train_Loss: 0.3961
training Epoch: 100, train_Loss: 1.4988
training Epoch: 100, train_Loss: 0.3033
training Epoch: 100, train_Loss: 0.8005
training Epoch: 100, train_Loss: 1.7557
training Epoch: 100, train_Loss: 1.3668
training Epoch: 100, train_Loss: 1.8395
training Epoch: 100, train_Loss: 0.4377
training Epoch: 100, train_Loss: 0.5963
training Epoch: 100, train_Loss: 1.7581
training Epoch: 100, train_Loss: 1.2316
training Epoch: 100, train_Loss: 1.4705
training Epoch: 100, train_Loss: 0.5907
training Epoch: 100, train_Loss: 1.7565
training Epoch: 100, train_Loss: 1.1922
training Epoch: 100, train_Loss: 1.1335
training Epoch: 100, train_Loss: 0.7042
training Epoch: 100, train_Loss: 0.6335
training Epoch: 100, train_Loss: 1.4709
training Epoch: 100, train_Loss: 0.9598
training Epoch: 100, train_Loss: 2.7254
training Epoch: 100, train_Loss: 2.2975
training Epoch: 100, train_Loss: 1.0948
training Epoch: 100, train_Loss: 0.5970
training Epoch: 100, train_Loss: 0.8557
training Epoch: 100, train_Loss: 0.5440
training Epoch: 100, train_Loss: 0.7068
training Epoch: 100, train_Loss: 1.1855
training Epoch: 100, train_Loss: 0.4576
training Epoch: 100, train_Loss: 0.5110
training Epoch: 100, train_Loss: 0.6105
training Epoch: 100, train_Loss: 0.4656
training Epoch: 100, train_Loss: 0.6649
training Epoch: 100, train_Loss: 0.8194
training Epoch: 100, train_Loss: 0.4568
training Epoch: 100, train_Loss: 1.5447
training Epoch: 100, train_Loss: 1.4749
training Epoch: 100, train_Loss: 0.2851
training Epoch: 100, train_Loss: 1.9226
training Epoch: 100, train_Loss: 1.0095
training Epoch: 100, train_Loss: 0.2523
training Epoch: 100, train_Loss: 0.9069
training Epoch: 100, train_Loss: 1.2288
training Epoch: 100, train_Loss: 1.6658
training Epoch: 100, train_Loss: 0.6054
training Epoch: 100, train_Loss: 0.6259
training Epoch: 100, train_Loss: 2.3653
training Epoch: 100, train_Loss: 1.4057
training Epoch: 100, train_Loss: 0.7167
training Epoch: 100, train_Loss: 1.1143
training Epoch: 100, train_Loss: 0.6454
training Epoch: 100, train_Loss: 1.2906
training Epoch: 100, train_Loss: 0.4092
training Epoch: 100, train_Loss: 0.6077
training Epoch: 100, train_Loss: 3.4102
training Epoch: 100, train_Loss: 0.5210
training Epoch: 100, train_Loss: 1.4840
training Epoch: 100, train_Loss: 1.7493
training Epoch: 100, train_Loss: 1.1137
training Epoch: 100, train_Loss: 1.3241
training Epoch: 100, train_Loss: 0.5816
training Epoch: 100, train_Loss: 1.2877
training Epoch: 100, train_Loss: 0.8862
training Epoch: 100, train_Loss: 1.2384
training Epoch: 100, train_Loss: 0.9954
training Epoch: 100, train_Loss: 0.4191
training Epoch: 100, train_Loss: 0.3649
training Epoch: 100, train_Loss: 2.3767
training Epoch: 100, train_Loss: 1.2628
training Epoch: 100, train_Loss: 0.5243
training Epoch: 100, train_Loss: 0.5743
training Epoch: 100, train_Loss: 1.6419
training Epoch: 100, train_Loss: 0.5301
training Epoch: 100, train_Loss: 2.0509
training Epoch: 100, train_Loss: 0.5972
training Epoch: 100, train_Loss: 5.3126
training Epoch: 100, train_Loss: 2.2744
training Epoch: 100, train_Loss: 1.2877
training Epoch: 100, train_Loss: 1.2742
training Epoch: 100, train_Loss: 1.0983
training Epoch: 100, train_Loss: 1.8750
training Epoch: 100, train_Loss: 1.0116
training Epoch: 100, train_Loss: 1.1071
training Epoch: 100, train_Loss: 3.1832
training Epoch: 100, train_Loss: 0.7626
training Epoch: 100, train_Loss: 2.5298
training Epoch: 100, train_Loss: 0.7778
training Epoch: 100, train_Loss: 1.2622
training Epoch: 100, train_Loss: 1.8222
training Epoch: 100, train_Loss: 0.6768
training Epoch: 100, train_Loss: 0.9520
training Epoch: 100, train_Loss: 1.0574
training Epoch: 100, train_Loss: 0.8457
training Epoch: 100, train_Loss: 1.2629
training Epoch: 100, train_Loss: 0.6123
training Epoch: 100, train_Loss: 1.9934
training Epoch: 100, train_Loss: 2.5713
training Epoch: 100, train_Loss: 1.8244
training Epoch: 100, train_Loss: 0.9624
training Epoch: 100, train_Loss: 1.3725
training Epoch: 100, train_Loss: 0.7471
training Epoch: 100, train_Loss: 1.6689
training Epoch: 100, train_Loss: 0.2920
training Epoch: 100, train_Loss: 1.0332
training Epoch: 100, train_Loss: 0.2139
training Epoch: 100, train_Loss: 2.3683
training Epoch: 100, train_Loss: 0.9065
training Epoch: 100, train_Loss: 2.3603
training Epoch: 100, train_Loss: 0.9451
training Epoch: 100, train_Loss: 1.5259
training Epoch: 100, train_Loss: 1.6150
training Epoch: 100, train_Loss: 0.6318
training Epoch: 100, train_Loss: 2.4303
training Epoch: 100, train_Loss: 1.8172
training Epoch: 100, train_Loss: 1.0889
training Epoch: 100, train_Loss: 0.6204
training Epoch: 100, train_Loss: 1.2698
training Epoch: 100, train_Loss: 1.1635
training Epoch: 100, train_Loss: 0.8079
training Epoch: 100, train_Loss: 0.6953
training Epoch: 100, train_Loss: 1.1087
training Epoch: 100, train_Loss: 1.0503
training Epoch: 100, train_Loss: 0.8054
training Epoch: 100, train_Loss: 1.2254
training Epoch: 100, train_Loss: 0.6988
training Epoch: 100, train_Loss: 0.5976
training Epoch: 100, train_Loss: 2.2868
training Epoch: 100, train_Loss: 0.8104
training Epoch: 100, train_Loss: 0.8479
training Epoch: 100, train_Loss: 1.4226
training Epoch: 100, train_Loss: 3.3126
training Epoch: 100, train_Loss: 0.7047
training Epoch: 100, train_Loss: 0.4984
training Epoch: 100, train_Loss: 1.1678
training Epoch: 100, train_Loss: 0.5513
training Epoch: 100, train_Loss: 2.4745
training Epoch: 100, train_Loss: 0.4190
training Epoch: 100, train_Loss: 1.3729
training Epoch: 100, train_Loss: 0.3696
training Epoch: 100, train_Loss: 1.3765
training Epoch: 100, train_Loss: 0.5541
training Epoch: 100, train_Loss: 1.1056
training Epoch: 100, train_Loss: 0.9207
training Epoch: 100, train_Loss: 1.7264
training Epoch: 100, train_Loss: 2.6057
training Epoch: 100, train_Loss: 1.3286
training Epoch: 100, train_Loss: 1.4690
training Epoch: 100, train_Loss: 0.3259
training Epoch: 100, train_Loss: 0.5224
training Epoch: 100, train_Loss: 1.4362
training Epoch: 100, train_Loss: 1.3175
training Epoch: 100, train_Loss: 1.1432
training Epoch: 100, train_Loss: 0.6412
training Epoch: 100, train_Loss: 0.9298
training Epoch: 100, train_Loss: 1.9306
training Epoch: 100, train_Loss: 0.8777
training Epoch: 100, train_Loss: 0.7816
training Epoch: 100, train_Loss: 0.6069
training Epoch: 100, train_Loss: 0.5755
training Epoch: 100, train_Loss: 2.2829
training Epoch: 100, train_Loss: 0.5701
training Epoch: 100, train_Loss: 0.8707
training Epoch: 100, train_Loss: 1.4862
training Epoch: 100, train_Loss: 0.5150
training Epoch: 100, train_Loss: 1.5728
training Epoch: 100, train_Loss: 0.7724
training Epoch: 100, train_Loss: 1.0147
training Epoch: 100, train_Loss: 0.3938
training Epoch: 100, train_Loss: 0.8291
training Epoch: 100, train_Loss: 0.3884
training Epoch: 100, train_Loss: 0.8983
training Epoch: 100, train_Loss: 1.4590
training Epoch: 100, train_Loss: 0.8193
training Epoch: 100, train_Loss: 0.7330
training Epoch: 100, train_Loss: 0.6478
training Epoch: 100, train_Loss: 1.1219
training Epoch: 100, train_Loss: 0.8031
training Epoch: 100, train_Loss: 0.7206
training Epoch: 100, train_Loss: 1.6648
training Epoch: 100, train_Loss: 0.4709
training Epoch: 100, train_Loss: 1.5549
training Epoch: 100, train_Loss: 0.6700
training Epoch: 100, train_Loss: 0.2788
training Epoch: 100, train_Loss: 1.4925
training Epoch: 100, train_Loss: 1.5240
training Epoch: 100, train_Loss: 1.2697
training Epoch: 100, train_Loss: 1.3648
training Epoch: 100, train_Loss: 0.9250
training Epoch: 100, train_Loss: 1.4073
training Epoch: 100, train_Loss: 0.9453
training Epoch: 100, train_Loss: 0.8324
training Epoch: 100, train_Loss: 0.9752
training Epoch: 100, train_Loss: 1.1670
training Epoch: 100, train_Loss: 2.0377
training Epoch: 100, train_Loss: 0.7159
training Epoch: 100, train_Loss: 0.5123
training Epoch: 100, train_Loss: 0.5361
training Epoch: 100, train_Loss: 0.7273
training Epoch: 100, train_Loss: 1.5671
training Epoch: 100, train_Loss: 0.4577
training Epoch: 100, train_Loss: 0.6189
training Epoch: 100, train_Loss: 0.6911
training Epoch: 100, train_Loss: 2.4461
training Epoch: 100, train_Loss: 0.9948
training Epoch: 100, train_Loss: 1.1569
training Epoch: 100, train_Loss: 0.7724
training Epoch: 100, train_Loss: 0.4101
training Epoch: 100, train_Loss: 0.5723
training Epoch: 100, train_Loss: 0.3635
training Epoch: 100, train_Loss: 0.6494
training Epoch: 100, train_Loss: 1.8381
training Epoch: 100, train_Loss: 1.6856
training Epoch: 100, train_Loss: 0.6735
training Epoch: 100, train_Loss: 1.0502
training Epoch: 100, train_Loss: 0.5428
training Epoch: 100, train_Loss: 0.4171
training Epoch: 100, train_Loss: 0.4083
training Epoch: 100, train_Loss: 1.4724
training Epoch: 100, train_Loss: 0.3358
training Epoch: 100, train_Loss: 0.5450
training Epoch: 100, train_Loss: 0.4110
training Epoch: 100, train_Loss: 1.9234
training Epoch: 100, train_Loss: 1.2289
training Epoch: 100, train_Loss: 0.7318
training Epoch: 100, train_Loss: 2.8822
training Epoch: 100, train_Loss: 1.4471
training Epoch: 100, train_Loss: 2.5779
training Epoch: 100, train_Loss: 2.3116
training Epoch: 100, train_Loss: 0.6114
training Epoch: 100, train_Loss: 0.5957
training Epoch: 100, train_Loss: 2.0068
training Epoch: 100, train_Loss: 0.9253
training Epoch: 100, train_Loss: 0.8298
training Epoch: 100, train_Loss: 2.7757
training Epoch: 100, train_Loss: 1.3726
training Epoch: 100, train_Loss: 0.7781
training Epoch: 100, train_Loss: 1.2387
training Epoch: 100, train_Loss: 1.9047
training Epoch: 100, train_Loss: 0.9957
training Epoch: 100, train_Loss: 2.3251
training Epoch: 100, train_Loss: 1.3472
training Epoch: 100, train_Loss: 0.8105
training Epoch: 100, train_Loss: 1.8550
training Epoch: 100, train_Loss: 1.1722
training Epoch: 100, train_Loss: 0.4186
training Epoch: 100, train_Loss: 0.7958
training Epoch: 100, train_Loss: 1.1913
training Epoch: 100, train_Loss: 1.2962
training Epoch: 100, train_Loss: 0.7942
training Epoch: 100, train_Loss: 0.5293
training Epoch: 100, train_Loss: 1.4808
training Epoch: 100, train_Loss: 1.8917
training Epoch: 100, train_Loss: 1.2074
training Epoch: 100, train_Loss: 0.7701
training Epoch: 100, train_Loss: 0.6086
training Epoch: 100, train_Loss: 0.8162
training Epoch: 100, train_Loss: 1.0946
training Epoch: 100, train_Loss: 0.9183
training Epoch: 100, train_Loss: 2.0884
training Epoch: 100, train_Loss: 0.6997
training Epoch: 100, train_Loss: 1.6778
training Epoch: 100, train_Loss: 0.7674
training Epoch: 100, train_Loss: 1.8947
training Epoch: 100, train_Loss: 1.0833
training Epoch: 100, train_Loss: 0.4212
training Epoch: 100, train_Loss: 0.5146
training Epoch: 100, train_Loss: 0.5460
training Epoch: 100, train_Loss: 0.6614
training Epoch: 100, train_Loss: 1.4409
training Epoch: 100, train_Loss: 1.7703
training Epoch: 100, train_Loss: 1.2383
training Epoch: 100, train_Loss: 0.4888
training Epoch: 100, train_Loss: 1.1497
training Epoch: 100, train_Loss: 1.1771
training Epoch: 100, train_Loss: 0.4510
training Epoch: 100, train_Loss: 0.4145
training Epoch: 100, train_Loss: 1.0554
training Epoch: 100, train_Loss: 1.0717
training Epoch: 100, train_Loss: 2.3160
training Epoch: 100, train_Loss: 0.6750
training Epoch: 100, train_Loss: 0.8444
training Epoch: 100, train_Loss: 0.6792
training Epoch: 100, train_Loss: 0.6941
training Epoch: 100, train_Loss: 0.3763
training Epoch: 100, train_Loss: 0.7182
training Epoch: 100, train_Loss: 0.7884
training Epoch: 100, train_Loss: 0.6227
training Epoch: 100, train_Loss: 0.7410
training Epoch: 100, train_Loss: 1.1118
training Epoch: 100, train_Loss: 0.5895
training Epoch: 100, train_Loss: 0.5071
training Epoch: 100, train_Loss: 0.7158
training Epoch: 100, train_Loss: 2.7350
training Epoch: 100, train_Loss: 1.4280
training Epoch: 100, train_Loss: 0.4696
training Epoch: 100, train_Loss: 1.0729
training Epoch: 100, train_Loss: 0.6215
training Epoch: 100, train_Loss: 0.6240
training Epoch: 100, train_Loss: 0.3359
training Epoch: 100, train_Loss: 0.8244
training Epoch: 100, train_Loss: 0.4654
training Epoch: 100, train_Loss: 0.6351
training Epoch: 100, train_Loss: 1.5846
training Epoch: 100, train_Loss: 1.2487
training Epoch: 100, train_Loss: 1.4075
training Epoch: 100, train_Loss: 0.6726
training Epoch: 100, train_Loss: 1.6468
training Epoch: 100, train_Loss: 0.5139
training Epoch: 100, train_Loss: 1.9162
training Epoch: 100, train_Loss: 1.4959
training Epoch: 100, train_Loss: 0.7783
training Epoch: 100, train_Loss: 0.8618
training Epoch: 100, train_Loss: 0.9014
training Epoch: 100, train_Loss: 0.5909
training Epoch: 100, train_Loss: 1.9802
training Epoch: 100, train_Loss: 1.0774
training Epoch: 100, train_Loss: 0.7029
training Epoch: 100, train_Loss: 0.4646
training Epoch: 100, train_Loss: 2.3674
training Epoch: 100, train_Loss: 0.6935
training Epoch: 100, train_Loss: 0.7377
training Epoch: 100, train_Loss: 1.2536
training Epoch: 100, train_Loss: 0.8885
training Epoch: 100, train_Loss: 2.2874
training Epoch: 100, train_Loss: 0.4414
training Epoch: 100, train_Loss: 1.0288
training Epoch: 100, train_Loss: 1.2663
training Epoch: 100, train_Loss: 0.7017
training Epoch: 100, train_Loss: 4.0356
training Epoch: 100, train_Loss: 0.5789
training Epoch: 100, train_Loss: 1.0287
training Epoch: 100, train_Loss: 0.8755
training Epoch: 100, train_Loss: 0.5436
training Epoch: 100, train_Loss: 0.6233
training Epoch: 100, train_Loss: 1.1677
training Epoch: 100, train_Loss: 1.2985
training Epoch: 100, train_Loss: 1.0341
training Epoch: 100, train_Loss: 0.4986
training Epoch: 100, train_Loss: 0.5576
training Epoch: 100, train_Loss: 1.6365
training Epoch: 100, train_Loss: 0.6740
training Epoch: 100, train_Loss: 1.0776
training Epoch: 100, train_Loss: 1.2600
training Epoch: 100, train_Loss: 1.3562
training Epoch: 100, train_Loss: 1.5836
training Epoch: 100, train_Loss: 0.4893
training Epoch: 100, train_Loss: 1.1953
training Epoch: 100, train_Loss: 0.7591
training Epoch: 100, train_Loss: 1.0009
training Epoch: 100, train_Loss: 0.4471
training Epoch: 100, train_Loss: 1.0628
training Epoch: 100, train_Loss: 2.1918
training Epoch: 100, train_Loss: 0.4937
training Epoch: 100, train_Loss: 1.0314
training Epoch: 100, train_Loss: 2.2221
training Epoch: 100, train_Loss: 2.1590
training Epoch: 100, train_Loss: 0.5015
training Epoch: 100, train_Loss: 1.6382
training Epoch: 100, train_Loss: 1.2267
training Epoch: 100, train_Loss: 1.5141
training Epoch: 100, train_Loss: 1.0198
training Epoch: 100, train_Loss: 0.3781
training Epoch: 100, train_Loss: 1.0587
training Epoch: 100, train_Loss: 0.6510
training Epoch: 100, train_Loss: 1.8421
training Epoch: 100, train_Loss: 1.2110
training Epoch: 100, train_Loss: 1.2741
training Epoch: 100, train_Loss: 0.7978
training Epoch: 100, train_Loss: 0.7931
training Epoch: 100, train_Loss: 0.8803
training Epoch: 100, train_Loss: 1.3518
training Epoch: 100, train_Loss: 0.5314
training Epoch: 100, train_Loss: 0.4917
training Epoch: 100, train_Loss: 0.8663
training Epoch: 100, train_Loss: 0.7099
training Epoch: 100, train_Loss: 1.0803
training Epoch: 100, train_Loss: 1.4745
training Epoch: 100, train_Loss: 0.5204
training Epoch: 100, train_Loss: 1.8223
training Epoch: 100, train_Loss: 1.0124
training Epoch: 100, train_Loss: 1.1238
training Epoch: 100, train_Loss: 0.5905
training Epoch: 100, train_Loss: 0.8136
training Epoch: 100, train_Loss: 0.4060
training Epoch: 100, train_Loss: 0.8958
training Epoch: 100, train_Loss: 3.3592
training Epoch: 100, train_Loss: 1.5936
training Epoch: 100, train_Loss: 0.3480
training Epoch: 100, train_Loss: 1.2907
training Epoch: 100, train_Loss: 0.4159
fold,epoch,train_loss: 0 99 1.0886372
fold,epoch,train_loss: 0 100 1.0932659
====Evaluation
fold:0, epoch:100,train:1.093266, valid:1.079450 

fold: 1
fold,epoch,train_loss: 1 0 1.0923843
fold,epoch,train_loss: 1 1 1.0914583
fold,epoch,train_loss: 1 2 1.0914207
fold,epoch,train_loss: 1 3 1.0919012
fold,epoch,train_loss: 1 4 1.084957
fold,epoch,train_loss: 1 5 1.0890825
fold,epoch,train_loss: 1 6 1.0889184
fold,epoch,train_loss: 1 7 1.0873485
fold,epoch,train_loss: 1 8 1.0900526
fold,epoch,train_loss: 1 9 1.0928408
fold,epoch,train_loss: 1 10 1.0860941
fold,epoch,train_loss: 1 11 1.0855027
fold,epoch,train_loss: 1 12 1.0915375
fold,epoch,train_loss: 1 13 1.0880897
fold,epoch,train_loss: 1 14 1.0891901
fold,epoch,train_loss: 1 15 1.095686
fold,epoch,train_loss: 1 16 1.088063
fold,epoch,train_loss: 1 17 1.0923134
fold,epoch,train_loss: 1 18 1.095024
fold,epoch,train_loss: 1 19 1.0940003
fold,epoch,train_loss: 1 20 1.089745
fold,epoch,train_loss: 1 21 1.0849407
fold,epoch,train_loss: 1 22 1.0870812
fold,epoch,train_loss: 1 23 1.0888249
fold,epoch,train_loss: 1 24 1.084384
fold,epoch,train_loss: 1 25 1.0885314
fold,epoch,train_loss: 1 26 1.092469
fold,epoch,train_loss: 1 27 1.0909758
fold,epoch,train_loss: 1 28 1.082199
fold,epoch,train_loss: 1 29 1.0884222
fold,epoch,train_loss: 1 30 1.0889809
fold,epoch,train_loss: 1 31 1.0896244
fold,epoch,train_loss: 1 32 1.09106
fold,epoch,train_loss: 1 33 1.0890207
fold,epoch,train_loss: 1 34 1.093147
fold,epoch,train_loss: 1 35 1.088268
fold,epoch,train_loss: 1 36 1.0884598
fold,epoch,train_loss: 1 37 1.0866127
fold,epoch,train_loss: 1 38 1.0903769
fold,epoch,train_loss: 1 39 1.0902117
fold,epoch,train_loss: 1 40 1.0902406
fold,epoch,train_loss: 1 41 1.0922565
fold,epoch,train_loss: 1 42 1.0873305
fold,epoch,train_loss: 1 43 1.0875885
fold,epoch,train_loss: 1 44 1.0860901
fold,epoch,train_loss: 1 45 1.0889965
fold,epoch,train_loss: 1 46 1.088717
fold,epoch,train_loss: 1 47 1.0913383
fold,epoch,train_loss: 1 48 1.0968839
training Epoch: 50, train_Loss: 0.8665
training Epoch: 50, train_Loss: 0.5402
training Epoch: 50, train_Loss: 0.5193
training Epoch: 50, train_Loss: 1.2484
training Epoch: 50, train_Loss: 1.4645
training Epoch: 50, train_Loss: 1.3444
training Epoch: 50, train_Loss: 0.9214
training Epoch: 50, train_Loss: 1.5047
training Epoch: 50, train_Loss: 0.6772
training Epoch: 50, train_Loss: 0.6567
training Epoch: 50, train_Loss: 1.3195
training Epoch: 50, train_Loss: 0.8109
training Epoch: 50, train_Loss: 0.6746
training Epoch: 50, train_Loss: 0.6531
training Epoch: 50, train_Loss: 0.3765
training Epoch: 50, train_Loss: 1.8999
training Epoch: 50, train_Loss: 2.6573
training Epoch: 50, train_Loss: 1.2499
training Epoch: 50, train_Loss: 0.8887
training Epoch: 50, train_Loss: 0.5701
training Epoch: 50, train_Loss: 0.4379
training Epoch: 50, train_Loss: 0.5167
training Epoch: 50, train_Loss: 1.2010
training Epoch: 50, train_Loss: 1.4302
training Epoch: 50, train_Loss: 1.2841
training Epoch: 50, train_Loss: 0.3926
training Epoch: 50, train_Loss: 0.3901
training Epoch: 50, train_Loss: 0.9180
training Epoch: 50, train_Loss: 0.3711
training Epoch: 50, train_Loss: 0.5721
training Epoch: 50, train_Loss: 0.6056
training Epoch: 50, train_Loss: 0.6462
training Epoch: 50, train_Loss: 1.0512
training Epoch: 50, train_Loss: 1.6254
training Epoch: 50, train_Loss: 0.2159
training Epoch: 50, train_Loss: 1.6560
training Epoch: 50, train_Loss: 1.5419
training Epoch: 50, train_Loss: 0.2463
training Epoch: 50, train_Loss: 0.4439
training Epoch: 50, train_Loss: 1.2286
training Epoch: 50, train_Loss: 0.5021
training Epoch: 50, train_Loss: 0.2617
training Epoch: 50, train_Loss: 1.3441
training Epoch: 50, train_Loss: 0.9375
training Epoch: 50, train_Loss: 0.8808
training Epoch: 50, train_Loss: 0.2152
training Epoch: 50, train_Loss: 0.8496
training Epoch: 50, train_Loss: 1.0333
training Epoch: 50, train_Loss: 1.3948
training Epoch: 50, train_Loss: 0.2883
training Epoch: 50, train_Loss: 1.2160
training Epoch: 50, train_Loss: 1.3848
training Epoch: 50, train_Loss: 0.3124
training Epoch: 50, train_Loss: 2.0696
training Epoch: 50, train_Loss: 0.5850
training Epoch: 50, train_Loss: 0.2858
training Epoch: 50, train_Loss: 0.3360
training Epoch: 50, train_Loss: 1.0381
training Epoch: 50, train_Loss: 0.4164
training Epoch: 50, train_Loss: 0.8352
training Epoch: 50, train_Loss: 0.7814
training Epoch: 50, train_Loss: 1.4234
training Epoch: 50, train_Loss: 0.4333
training Epoch: 50, train_Loss: 2.7805
training Epoch: 50, train_Loss: 0.6167
training Epoch: 50, train_Loss: 0.5415
training Epoch: 50, train_Loss: 0.6278
training Epoch: 50, train_Loss: 0.3264
training Epoch: 50, train_Loss: 0.7751
training Epoch: 50, train_Loss: 0.5564
training Epoch: 50, train_Loss: 1.8346
training Epoch: 50, train_Loss: 2.0426
training Epoch: 50, train_Loss: 0.7155
training Epoch: 50, train_Loss: 0.6728
training Epoch: 50, train_Loss: 0.6484
training Epoch: 50, train_Loss: 0.5584
training Epoch: 50, train_Loss: 1.5584
training Epoch: 50, train_Loss: 2.1533
training Epoch: 50, train_Loss: 0.2922
training Epoch: 50, train_Loss: 1.2638
training Epoch: 50, train_Loss: 0.5606
training Epoch: 50, train_Loss: 1.5574
training Epoch: 50, train_Loss: 3.3696
training Epoch: 50, train_Loss: 1.1231
training Epoch: 50, train_Loss: 0.2938
training Epoch: 50, train_Loss: 1.0509
training Epoch: 50, train_Loss: 0.8345
training Epoch: 50, train_Loss: 1.6937
training Epoch: 50, train_Loss: 0.8734
training Epoch: 50, train_Loss: 1.1072
training Epoch: 50, train_Loss: 1.0231
training Epoch: 50, train_Loss: 2.1821
training Epoch: 50, train_Loss: 0.7090
training Epoch: 50, train_Loss: 1.6275
training Epoch: 50, train_Loss: 1.2065
training Epoch: 50, train_Loss: 1.0031
training Epoch: 50, train_Loss: 2.2626
training Epoch: 50, train_Loss: 1.0013
training Epoch: 50, train_Loss: 1.1193
training Epoch: 50, train_Loss: 0.8360
training Epoch: 50, train_Loss: 0.5386
training Epoch: 50, train_Loss: 0.8350
training Epoch: 50, train_Loss: 2.2029
training Epoch: 50, train_Loss: 0.5314
training Epoch: 50, train_Loss: 1.0908
training Epoch: 50, train_Loss: 1.0629
training Epoch: 50, train_Loss: 0.9114
training Epoch: 50, train_Loss: 0.8905
training Epoch: 50, train_Loss: 0.4157
training Epoch: 50, train_Loss: 1.6160
training Epoch: 50, train_Loss: 0.7301
training Epoch: 50, train_Loss: 1.3582
training Epoch: 50, train_Loss: 1.4857
training Epoch: 50, train_Loss: 0.4953
training Epoch: 50, train_Loss: 1.5492
training Epoch: 50, train_Loss: 1.5518
training Epoch: 50, train_Loss: 1.6748
training Epoch: 50, train_Loss: 1.0265
training Epoch: 50, train_Loss: 2.2293
training Epoch: 50, train_Loss: 1.1282
training Epoch: 50, train_Loss: 0.4983
training Epoch: 50, train_Loss: 0.8443
training Epoch: 50, train_Loss: 1.4167
training Epoch: 50, train_Loss: 0.5270
training Epoch: 50, train_Loss: 0.6796
training Epoch: 50, train_Loss: 0.8131
training Epoch: 50, train_Loss: 0.6698
training Epoch: 50, train_Loss: 0.3866
training Epoch: 50, train_Loss: 2.1364
training Epoch: 50, train_Loss: 2.0348
training Epoch: 50, train_Loss: 0.3551
training Epoch: 50, train_Loss: 0.5880
training Epoch: 50, train_Loss: 0.2422
training Epoch: 50, train_Loss: 0.5566
training Epoch: 50, train_Loss: 2.2567
training Epoch: 50, train_Loss: 0.5085
training Epoch: 50, train_Loss: 1.8933
training Epoch: 50, train_Loss: 1.6593
training Epoch: 50, train_Loss: 0.4043
training Epoch: 50, train_Loss: 4.3447
training Epoch: 50, train_Loss: 0.6298
training Epoch: 50, train_Loss: 0.7334
training Epoch: 50, train_Loss: 0.4418
training Epoch: 50, train_Loss: 1.0546
training Epoch: 50, train_Loss: 0.9019
training Epoch: 50, train_Loss: 1.1138
training Epoch: 50, train_Loss: 0.4580
training Epoch: 50, train_Loss: 0.6174
training Epoch: 50, train_Loss: 0.6918
training Epoch: 50, train_Loss: 0.4417
training Epoch: 50, train_Loss: 0.4445
training Epoch: 50, train_Loss: 0.5491
training Epoch: 50, train_Loss: 1.1388
training Epoch: 50, train_Loss: 0.2431
training Epoch: 50, train_Loss: 0.6028
training Epoch: 50, train_Loss: 0.6368
training Epoch: 50, train_Loss: 0.2019
training Epoch: 50, train_Loss: 0.6525
training Epoch: 50, train_Loss: 0.9352
training Epoch: 50, train_Loss: 1.2102
training Epoch: 50, train_Loss: 0.7933
training Epoch: 50, train_Loss: 1.1153
training Epoch: 50, train_Loss: 2.0970
training Epoch: 50, train_Loss: 2.3918
training Epoch: 50, train_Loss: 2.1190
training Epoch: 50, train_Loss: 0.3425
training Epoch: 50, train_Loss: 0.9118
training Epoch: 50, train_Loss: 1.5490
training Epoch: 50, train_Loss: 0.6705
training Epoch: 50, train_Loss: 2.2046
training Epoch: 50, train_Loss: 0.3392
training Epoch: 50, train_Loss: 0.6513
training Epoch: 50, train_Loss: 1.9300
training Epoch: 50, train_Loss: 1.1143
training Epoch: 50, train_Loss: 1.2921
training Epoch: 50, train_Loss: 1.9554
training Epoch: 50, train_Loss: 0.7126
training Epoch: 50, train_Loss: 0.9800
training Epoch: 50, train_Loss: 1.0742
training Epoch: 50, train_Loss: 0.8132
training Epoch: 50, train_Loss: 1.1169
training Epoch: 50, train_Loss: 1.0334
training Epoch: 50, train_Loss: 1.8356
training Epoch: 50, train_Loss: 0.7007
training Epoch: 50, train_Loss: 0.5443
training Epoch: 50, train_Loss: 1.1300
training Epoch: 50, train_Loss: 1.0450
training Epoch: 50, train_Loss: 0.4390
training Epoch: 50, train_Loss: 0.9594
training Epoch: 50, train_Loss: 0.2928
training Epoch: 50, train_Loss: 1.8151
training Epoch: 50, train_Loss: 2.4324
training Epoch: 50, train_Loss: 1.9751
training Epoch: 50, train_Loss: 0.2534
training Epoch: 50, train_Loss: 0.6637
training Epoch: 50, train_Loss: 0.4439
training Epoch: 50, train_Loss: 1.4076
training Epoch: 50, train_Loss: 0.7991
training Epoch: 50, train_Loss: 0.9054
training Epoch: 50, train_Loss: 0.3133
training Epoch: 50, train_Loss: 0.9909
training Epoch: 50, train_Loss: 0.7694
training Epoch: 50, train_Loss: 1.0466
training Epoch: 50, train_Loss: 2.9168
training Epoch: 50, train_Loss: 0.5693
training Epoch: 50, train_Loss: 0.9260
training Epoch: 50, train_Loss: 0.9293
training Epoch: 50, train_Loss: 1.2051
training Epoch: 50, train_Loss: 0.4839
training Epoch: 50, train_Loss: 0.5517
training Epoch: 50, train_Loss: 0.3757
training Epoch: 50, train_Loss: 0.7658
training Epoch: 50, train_Loss: 1.1257
training Epoch: 50, train_Loss: 0.6238
training Epoch: 50, train_Loss: 0.5030
training Epoch: 50, train_Loss: 1.7622
training Epoch: 50, train_Loss: 2.5332
training Epoch: 50, train_Loss: 1.5097
training Epoch: 50, train_Loss: 1.3899
training Epoch: 50, train_Loss: 0.4085
training Epoch: 50, train_Loss: 1.8856
training Epoch: 50, train_Loss: 1.8461
training Epoch: 50, train_Loss: 0.4384
training Epoch: 50, train_Loss: 0.3797
training Epoch: 50, train_Loss: 0.4083
training Epoch: 50, train_Loss: 1.8728
training Epoch: 50, train_Loss: 0.6861
training Epoch: 50, train_Loss: 0.7634
training Epoch: 50, train_Loss: 2.1670
training Epoch: 50, train_Loss: 2.3297
training Epoch: 50, train_Loss: 1.9679
training Epoch: 50, train_Loss: 0.4376
training Epoch: 50, train_Loss: 1.1480
training Epoch: 50, train_Loss: 0.8867
training Epoch: 50, train_Loss: 1.1069
training Epoch: 50, train_Loss: 1.6160
training Epoch: 50, train_Loss: 1.0867
training Epoch: 50, train_Loss: 1.0474
training Epoch: 50, train_Loss: 2.0006
training Epoch: 50, train_Loss: 1.1074
training Epoch: 50, train_Loss: 1.2141
training Epoch: 50, train_Loss: 1.0084
training Epoch: 50, train_Loss: 0.5080
training Epoch: 50, train_Loss: 0.6060
training Epoch: 50, train_Loss: 1.5017
training Epoch: 50, train_Loss: 1.0283
training Epoch: 50, train_Loss: 1.8547
training Epoch: 50, train_Loss: 0.5379
training Epoch: 50, train_Loss: 0.9290
training Epoch: 50, train_Loss: 0.8914
training Epoch: 50, train_Loss: 1.0793
training Epoch: 50, train_Loss: 0.4214
training Epoch: 50, train_Loss: 0.9751
training Epoch: 50, train_Loss: 0.4753
training Epoch: 50, train_Loss: 0.7843
training Epoch: 50, train_Loss: 0.9771
training Epoch: 50, train_Loss: 0.9580
training Epoch: 50, train_Loss: 0.2925
training Epoch: 50, train_Loss: 1.0233
training Epoch: 50, train_Loss: 1.2128
training Epoch: 50, train_Loss: 0.5847
training Epoch: 50, train_Loss: 1.2491
training Epoch: 50, train_Loss: 1.0838
training Epoch: 50, train_Loss: 1.6553
training Epoch: 50, train_Loss: 0.5053
training Epoch: 50, train_Loss: 0.4664
training Epoch: 50, train_Loss: 0.4235
training Epoch: 50, train_Loss: 1.0297
training Epoch: 50, train_Loss: 1.5277
training Epoch: 50, train_Loss: 0.6491
training Epoch: 50, train_Loss: 0.3835
training Epoch: 50, train_Loss: 0.3209
training Epoch: 50, train_Loss: 0.3759
training Epoch: 50, train_Loss: 0.3339
training Epoch: 50, train_Loss: 1.6357
training Epoch: 50, train_Loss: 0.4533
training Epoch: 50, train_Loss: 1.7101
training Epoch: 50, train_Loss: 0.2386
training Epoch: 50, train_Loss: 0.5424
training Epoch: 50, train_Loss: 1.6711
training Epoch: 50, train_Loss: 1.9516
training Epoch: 50, train_Loss: 1.4914
training Epoch: 50, train_Loss: 1.5841
training Epoch: 50, train_Loss: 0.7248
training Epoch: 50, train_Loss: 0.5147
training Epoch: 50, train_Loss: 0.9806
training Epoch: 50, train_Loss: 1.9762
training Epoch: 50, train_Loss: 0.6845
training Epoch: 50, train_Loss: 1.0204
training Epoch: 50, train_Loss: 1.1901
training Epoch: 50, train_Loss: 1.1523
training Epoch: 50, train_Loss: 1.4895
training Epoch: 50, train_Loss: 1.0747
training Epoch: 50, train_Loss: 0.6762
training Epoch: 50, train_Loss: 1.7140
training Epoch: 50, train_Loss: 1.3823
training Epoch: 50, train_Loss: 2.6197
training Epoch: 50, train_Loss: 1.1073
training Epoch: 50, train_Loss: 1.1752
training Epoch: 50, train_Loss: 2.4354
training Epoch: 50, train_Loss: 0.5171
training Epoch: 50, train_Loss: 0.7604
training Epoch: 50, train_Loss: 0.5234
training Epoch: 50, train_Loss: 1.7630
training Epoch: 50, train_Loss: 1.4153
training Epoch: 50, train_Loss: 0.8972
training Epoch: 50, train_Loss: 0.6116
training Epoch: 50, train_Loss: 0.9391
training Epoch: 50, train_Loss: 1.7120
training Epoch: 50, train_Loss: 3.0654
training Epoch: 50, train_Loss: 0.9018
training Epoch: 50, train_Loss: 1.1198
training Epoch: 50, train_Loss: 1.1364
training Epoch: 50, train_Loss: 1.9015
training Epoch: 50, train_Loss: 0.4451
training Epoch: 50, train_Loss: 1.6448
training Epoch: 50, train_Loss: 0.4880
training Epoch: 50, train_Loss: 1.6227
training Epoch: 50, train_Loss: 0.6003
training Epoch: 50, train_Loss: 1.8631
training Epoch: 50, train_Loss: 1.3226
training Epoch: 50, train_Loss: 0.7411
training Epoch: 50, train_Loss: 0.3783
training Epoch: 50, train_Loss: 0.8635
training Epoch: 50, train_Loss: 2.4488
training Epoch: 50, train_Loss: 0.9525
training Epoch: 50, train_Loss: 1.3796
training Epoch: 50, train_Loss: 0.4710
training Epoch: 50, train_Loss: 1.8955
training Epoch: 50, train_Loss: 1.5581
training Epoch: 50, train_Loss: 1.0281
training Epoch: 50, train_Loss: 1.8819
training Epoch: 50, train_Loss: 0.8720
training Epoch: 50, train_Loss: 1.6368
training Epoch: 50, train_Loss: 1.7029
training Epoch: 50, train_Loss: 1.5085
training Epoch: 50, train_Loss: 0.8305
training Epoch: 50, train_Loss: 0.7069
training Epoch: 50, train_Loss: 0.6591
training Epoch: 50, train_Loss: 0.7797
training Epoch: 50, train_Loss: 1.0678
training Epoch: 50, train_Loss: 1.4156
training Epoch: 50, train_Loss: 0.4999
training Epoch: 50, train_Loss: 0.8900
training Epoch: 50, train_Loss: 1.6000
training Epoch: 50, train_Loss: 0.8930
training Epoch: 50, train_Loss: 1.1697
training Epoch: 50, train_Loss: 0.9681
training Epoch: 50, train_Loss: 0.3353
training Epoch: 50, train_Loss: 1.0784
training Epoch: 50, train_Loss: 1.3588
training Epoch: 50, train_Loss: 0.9819
training Epoch: 50, train_Loss: 1.0137
training Epoch: 50, train_Loss: 2.0819
training Epoch: 50, train_Loss: 1.1221
training Epoch: 50, train_Loss: 2.6382
training Epoch: 50, train_Loss: 0.6712
training Epoch: 50, train_Loss: 0.5135
training Epoch: 50, train_Loss: 1.7079
training Epoch: 50, train_Loss: 1.2844
training Epoch: 50, train_Loss: 1.6458
training Epoch: 50, train_Loss: 1.6280
training Epoch: 50, train_Loss: 0.5985
training Epoch: 50, train_Loss: 0.5769
training Epoch: 50, train_Loss: 1.4506
training Epoch: 50, train_Loss: 0.8891
training Epoch: 50, train_Loss: 0.9251
training Epoch: 50, train_Loss: 1.2588
training Epoch: 50, train_Loss: 0.6216
training Epoch: 50, train_Loss: 0.4714
training Epoch: 50, train_Loss: 2.1358
training Epoch: 50, train_Loss: 0.4653
training Epoch: 50, train_Loss: 1.6688
training Epoch: 50, train_Loss: 6.2126
training Epoch: 50, train_Loss: 2.3840
training Epoch: 50, train_Loss: 0.4209
training Epoch: 50, train_Loss: 1.1571
training Epoch: 50, train_Loss: 0.9259
training Epoch: 50, train_Loss: 0.8622
training Epoch: 50, train_Loss: 0.7473
training Epoch: 50, train_Loss: 1.0789
training Epoch: 50, train_Loss: 1.2788
training Epoch: 50, train_Loss: 2.3667
training Epoch: 50, train_Loss: 1.3027
training Epoch: 50, train_Loss: 0.8769
training Epoch: 50, train_Loss: 1.1188
training Epoch: 50, train_Loss: 2.9750
training Epoch: 50, train_Loss: 0.7023
training Epoch: 50, train_Loss: 1.4486
training Epoch: 50, train_Loss: 0.6297
training Epoch: 50, train_Loss: 1.5146
training Epoch: 50, train_Loss: 1.4584
training Epoch: 50, train_Loss: 1.2631
training Epoch: 50, train_Loss: 1.1219
training Epoch: 50, train_Loss: 1.7193
training Epoch: 50, train_Loss: 1.4765
training Epoch: 50, train_Loss: 1.7245
training Epoch: 50, train_Loss: 0.3883
training Epoch: 50, train_Loss: 0.8591
training Epoch: 50, train_Loss: 0.3745
training Epoch: 50, train_Loss: 0.2978
training Epoch: 50, train_Loss: 0.6664
training Epoch: 50, train_Loss: 0.3288
training Epoch: 50, train_Loss: 2.8077
training Epoch: 50, train_Loss: 1.2558
training Epoch: 50, train_Loss: 2.5080
training Epoch: 50, train_Loss: 0.7738
training Epoch: 50, train_Loss: 2.3348
training Epoch: 50, train_Loss: 1.2723
training Epoch: 50, train_Loss: 0.5563
training Epoch: 50, train_Loss: 0.5303
training Epoch: 50, train_Loss: 1.7593
training Epoch: 50, train_Loss: 0.5440
training Epoch: 50, train_Loss: 1.3330
training Epoch: 50, train_Loss: 2.0115
training Epoch: 50, train_Loss: 1.2326
training Epoch: 50, train_Loss: 0.9213
training Epoch: 50, train_Loss: 2.4424
training Epoch: 50, train_Loss: 0.6957
training Epoch: 50, train_Loss: 0.5327
training Epoch: 50, train_Loss: 0.6076
training Epoch: 50, train_Loss: 0.9890
training Epoch: 50, train_Loss: 0.6844
training Epoch: 50, train_Loss: 0.9188
training Epoch: 50, train_Loss: 1.7190
training Epoch: 50, train_Loss: 0.9570
training Epoch: 50, train_Loss: 1.1495
training Epoch: 50, train_Loss: 0.5599
training Epoch: 50, train_Loss: 1.5746
training Epoch: 50, train_Loss: 1.1554
training Epoch: 50, train_Loss: 1.6109
training Epoch: 50, train_Loss: 1.6465
training Epoch: 50, train_Loss: 0.4266
training Epoch: 50, train_Loss: 0.7509
training Epoch: 50, train_Loss: 0.7207
training Epoch: 50, train_Loss: 1.5842
training Epoch: 50, train_Loss: 2.6102
training Epoch: 50, train_Loss: 0.4406
training Epoch: 50, train_Loss: 0.9040
training Epoch: 50, train_Loss: 0.8863
training Epoch: 50, train_Loss: 2.7082
training Epoch: 50, train_Loss: 0.9061
training Epoch: 50, train_Loss: 0.7989
training Epoch: 50, train_Loss: 2.3423
training Epoch: 50, train_Loss: 1.3454
training Epoch: 50, train_Loss: 1.7595
training Epoch: 50, train_Loss: 0.5721
training Epoch: 50, train_Loss: 2.7551
training Epoch: 50, train_Loss: 0.7633
training Epoch: 50, train_Loss: 0.9475
training Epoch: 50, train_Loss: 1.0157
training Epoch: 50, train_Loss: 0.8748
training Epoch: 50, train_Loss: 1.1171
training Epoch: 50, train_Loss: 0.3956
training Epoch: 50, train_Loss: 0.4332
training Epoch: 50, train_Loss: 1.1621
training Epoch: 50, train_Loss: 0.3114
training Epoch: 50, train_Loss: 1.0572
training Epoch: 50, train_Loss: 2.1388
training Epoch: 50, train_Loss: 0.2733
training Epoch: 50, train_Loss: 1.0348
training Epoch: 50, train_Loss: 0.4151
training Epoch: 50, train_Loss: 0.6616
training Epoch: 50, train_Loss: 0.9520
training Epoch: 50, train_Loss: 0.8342
training Epoch: 50, train_Loss: 0.8622
training Epoch: 50, train_Loss: 0.3318
training Epoch: 50, train_Loss: 0.2355
training Epoch: 50, train_Loss: 0.4490
training Epoch: 50, train_Loss: 1.1397
training Epoch: 50, train_Loss: 2.3512
training Epoch: 50, train_Loss: 0.2687
training Epoch: 50, train_Loss: 0.6915
training Epoch: 50, train_Loss: 0.6758
training Epoch: 50, train_Loss: 0.6710
training Epoch: 50, train_Loss: 0.9041
training Epoch: 50, train_Loss: 1.5285
training Epoch: 50, train_Loss: 1.1077
training Epoch: 50, train_Loss: 0.7063
training Epoch: 50, train_Loss: 3.8082
training Epoch: 50, train_Loss: 1.1368
training Epoch: 50, train_Loss: 1.6871
training Epoch: 50, train_Loss: 0.5015
training Epoch: 50, train_Loss: 1.4263
training Epoch: 50, train_Loss: 0.6753
training Epoch: 50, train_Loss: 1.7226
training Epoch: 50, train_Loss: 0.5690
training Epoch: 50, train_Loss: 0.5584
training Epoch: 50, train_Loss: 0.7168
training Epoch: 50, train_Loss: 0.5606
training Epoch: 50, train_Loss: 0.9357
training Epoch: 50, train_Loss: 1.7490
training Epoch: 50, train_Loss: 0.4091
training Epoch: 50, train_Loss: 0.6579
training Epoch: 50, train_Loss: 0.7470
training Epoch: 50, train_Loss: 0.4705
training Epoch: 50, train_Loss: 0.5146
training Epoch: 50, train_Loss: 0.6718
training Epoch: 50, train_Loss: 1.6639
training Epoch: 50, train_Loss: 1.3709
training Epoch: 50, train_Loss: 0.3455
training Epoch: 50, train_Loss: 0.6766
training Epoch: 50, train_Loss: 0.6705
training Epoch: 50, train_Loss: 0.9933
training Epoch: 50, train_Loss: 1.7593
training Epoch: 50, train_Loss: 1.5280
training Epoch: 50, train_Loss: 1.8896
training Epoch: 50, train_Loss: 0.3440
training Epoch: 50, train_Loss: 1.0647
training Epoch: 50, train_Loss: 0.5055
training Epoch: 50, train_Loss: 1.1248
training Epoch: 50, train_Loss: 0.4475
training Epoch: 50, train_Loss: 0.4501
training Epoch: 50, train_Loss: 0.4572
training Epoch: 50, train_Loss: 0.5779
training Epoch: 50, train_Loss: 0.9137
training Epoch: 50, train_Loss: 0.3082
training Epoch: 50, train_Loss: 0.6578
training Epoch: 50, train_Loss: 0.8573
training Epoch: 50, train_Loss: 0.4372
training Epoch: 50, train_Loss: 1.0784
training Epoch: 50, train_Loss: 0.1856
training Epoch: 50, train_Loss: 0.3222
training Epoch: 50, train_Loss: 0.5149
training Epoch: 50, train_Loss: 1.1810
training Epoch: 50, train_Loss: 2.6577
training Epoch: 50, train_Loss: 0.4514
training Epoch: 50, train_Loss: 0.3311
training Epoch: 50, train_Loss: 1.6569
training Epoch: 50, train_Loss: 1.2110
training Epoch: 50, train_Loss: 1.2572
training Epoch: 50, train_Loss: 1.3341
training Epoch: 50, train_Loss: 1.1594
training Epoch: 50, train_Loss: 0.8687
training Epoch: 50, train_Loss: 0.4460
training Epoch: 50, train_Loss: 0.3769
training Epoch: 50, train_Loss: 0.7110
training Epoch: 50, train_Loss: 0.7351
training Epoch: 50, train_Loss: 3.1353
training Epoch: 50, train_Loss: 0.5249
training Epoch: 50, train_Loss: 1.8682
training Epoch: 50, train_Loss: 0.8743
training Epoch: 50, train_Loss: 2.0096
training Epoch: 50, train_Loss: 1.7806
training Epoch: 50, train_Loss: 1.5722
training Epoch: 50, train_Loss: 1.3429
training Epoch: 50, train_Loss: 1.6275
training Epoch: 50, train_Loss: 1.0536
training Epoch: 50, train_Loss: 0.5508
training Epoch: 50, train_Loss: 0.7142
training Epoch: 50, train_Loss: 1.8389
training Epoch: 50, train_Loss: 0.4879
training Epoch: 50, train_Loss: 1.1764
training Epoch: 50, train_Loss: 1.4165
training Epoch: 50, train_Loss: 0.6868
training Epoch: 50, train_Loss: 0.7844
training Epoch: 50, train_Loss: 0.3390
training Epoch: 50, train_Loss: 1.6238
training Epoch: 50, train_Loss: 1.1960
training Epoch: 50, train_Loss: 0.5742
training Epoch: 50, train_Loss: 1.4121
training Epoch: 50, train_Loss: 0.8112
training Epoch: 50, train_Loss: 2.8915
training Epoch: 50, train_Loss: 1.9921
training Epoch: 50, train_Loss: 1.6323
training Epoch: 50, train_Loss: 0.5528
training Epoch: 50, train_Loss: 3.0618
training Epoch: 50, train_Loss: 1.1290
training Epoch: 50, train_Loss: 1.4546
training Epoch: 50, train_Loss: 1.1651
training Epoch: 50, train_Loss: 1.1281
training Epoch: 50, train_Loss: 1.3718
training Epoch: 50, train_Loss: 1.1251
training Epoch: 50, train_Loss: 0.7794
training Epoch: 50, train_Loss: 0.7661
fold,epoch,train_loss: 1 49 1.0899585
fold,epoch,train_loss: 1 50 1.0862252
fold,epoch,train_loss: 1 51 1.0890139
fold,epoch,train_loss: 1 52 1.0884857
fold,epoch,train_loss: 1 53 1.0849131
fold,epoch,train_loss: 1 54 1.0908896
fold,epoch,train_loss: 1 55 1.0878743
fold,epoch,train_loss: 1 56 1.0911739
fold,epoch,train_loss: 1 57 1.0887089
fold,epoch,train_loss: 1 58 1.0869212
fold,epoch,train_loss: 1 59 1.0940692
fold,epoch,train_loss: 1 60 1.0951155
fold,epoch,train_loss: 1 61 1.083908
fold,epoch,train_loss: 1 62 1.0925851
fold,epoch,train_loss: 1 63 1.0898583
fold,epoch,train_loss: 1 64 1.0948651
fold,epoch,train_loss: 1 65 1.0891597
fold,epoch,train_loss: 1 66 1.0879539
fold,epoch,train_loss: 1 67 1.0858024
fold,epoch,train_loss: 1 68 1.0907799
fold,epoch,train_loss: 1 69 1.0895469
fold,epoch,train_loss: 1 70 1.0858198
fold,epoch,train_loss: 1 71 1.0922785
fold,epoch,train_loss: 1 72 1.087532
fold,epoch,train_loss: 1 73 1.0905999
fold,epoch,train_loss: 1 74 1.0865875
fold,epoch,train_loss: 1 75 1.090876
fold,epoch,train_loss: 1 76 1.0939877
fold,epoch,train_loss: 1 77 1.085372
fold,epoch,train_loss: 1 78 1.0895656
fold,epoch,train_loss: 1 79 1.0873227
fold,epoch,train_loss: 1 80 1.0920268
fold,epoch,train_loss: 1 81 1.0857301
fold,epoch,train_loss: 1 82 1.0918039
fold,epoch,train_loss: 1 83 1.0907617
fold,epoch,train_loss: 1 84 1.0872073
fold,epoch,train_loss: 1 85 1.0859874
fold,epoch,train_loss: 1 86 1.0902488
fold,epoch,train_loss: 1 87 1.0867455
fold,epoch,train_loss: 1 88 1.0840827
fold,epoch,train_loss: 1 89 1.0872393
fold,epoch,train_loss: 1 90 1.092935
fold,epoch,train_loss: 1 91 1.0872556
fold,epoch,train_loss: 1 92 1.0903624
fold,epoch,train_loss: 1 93 1.0925722
fold,epoch,train_loss: 1 94 1.0883498
fold,epoch,train_loss: 1 95 1.0867529
fold,epoch,train_loss: 1 96 1.0984833
fold,epoch,train_loss: 1 97 1.091363
fold,epoch,train_loss: 1 98 1.0931174
training Epoch: 100, train_Loss: 2.0086
training Epoch: 100, train_Loss: 0.6464
training Epoch: 100, train_Loss: 0.4742
training Epoch: 100, train_Loss: 0.3569
training Epoch: 100, train_Loss: 1.4862
training Epoch: 100, train_Loss: 2.5741
training Epoch: 100, train_Loss: 0.4373
training Epoch: 100, train_Loss: 1.1765
training Epoch: 100, train_Loss: 0.9349
training Epoch: 100, train_Loss: 0.6224
training Epoch: 100, train_Loss: 1.6838
training Epoch: 100, train_Loss: 1.1768
training Epoch: 100, train_Loss: 0.7534
training Epoch: 100, train_Loss: 0.7467
training Epoch: 100, train_Loss: 0.3128
training Epoch: 100, train_Loss: 1.4882
training Epoch: 100, train_Loss: 1.3354
training Epoch: 100, train_Loss: 1.1981
training Epoch: 100, train_Loss: 0.4873
training Epoch: 100, train_Loss: 1.0147
training Epoch: 100, train_Loss: 1.0181
training Epoch: 100, train_Loss: 0.4151
training Epoch: 100, train_Loss: 1.0106
training Epoch: 100, train_Loss: 1.9317
training Epoch: 100, train_Loss: 2.5777
training Epoch: 100, train_Loss: 0.8833
training Epoch: 100, train_Loss: 0.4363
training Epoch: 100, train_Loss: 2.3584
training Epoch: 100, train_Loss: 0.7947
training Epoch: 100, train_Loss: 1.0395
training Epoch: 100, train_Loss: 0.9258
training Epoch: 100, train_Loss: 2.1802
training Epoch: 100, train_Loss: 2.6169
training Epoch: 100, train_Loss: 0.8068
training Epoch: 100, train_Loss: 0.7706
training Epoch: 100, train_Loss: 0.4854
training Epoch: 100, train_Loss: 0.6430
training Epoch: 100, train_Loss: 0.9915
training Epoch: 100, train_Loss: 1.1548
training Epoch: 100, train_Loss: 0.7703
training Epoch: 100, train_Loss: 0.4895
training Epoch: 100, train_Loss: 1.6158
training Epoch: 100, train_Loss: 0.5844
training Epoch: 100, train_Loss: 0.7963
training Epoch: 100, train_Loss: 0.5658
training Epoch: 100, train_Loss: 0.7374
training Epoch: 100, train_Loss: 1.2643
training Epoch: 100, train_Loss: 1.0140
training Epoch: 100, train_Loss: 1.1052
training Epoch: 100, train_Loss: 0.4568
training Epoch: 100, train_Loss: 0.5953
training Epoch: 100, train_Loss: 0.8054
training Epoch: 100, train_Loss: 0.5957
training Epoch: 100, train_Loss: 0.3502
training Epoch: 100, train_Loss: 0.6818
training Epoch: 100, train_Loss: 0.5095
training Epoch: 100, train_Loss: 0.9865
training Epoch: 100, train_Loss: 0.3016
training Epoch: 100, train_Loss: 2.4583
training Epoch: 100, train_Loss: 1.0474
training Epoch: 100, train_Loss: 2.0168
training Epoch: 100, train_Loss: 1.6317
training Epoch: 100, train_Loss: 0.7590
training Epoch: 100, train_Loss: 0.7961
training Epoch: 100, train_Loss: 1.2551
training Epoch: 100, train_Loss: 1.0714
training Epoch: 100, train_Loss: 1.8309
training Epoch: 100, train_Loss: 1.1230
training Epoch: 100, train_Loss: 0.4848
training Epoch: 100, train_Loss: 0.9004
training Epoch: 100, train_Loss: 1.2273
training Epoch: 100, train_Loss: 0.5410
training Epoch: 100, train_Loss: 0.9191
training Epoch: 100, train_Loss: 1.3729
training Epoch: 100, train_Loss: 0.5671
training Epoch: 100, train_Loss: 1.6572
training Epoch: 100, train_Loss: 2.6353
training Epoch: 100, train_Loss: 0.4013
training Epoch: 100, train_Loss: 1.1002
training Epoch: 100, train_Loss: 0.3005
training Epoch: 100, train_Loss: 0.7445
training Epoch: 100, train_Loss: 1.0764
training Epoch: 100, train_Loss: 0.5474
training Epoch: 100, train_Loss: 1.0996
training Epoch: 100, train_Loss: 0.5110
training Epoch: 100, train_Loss: 1.5483
training Epoch: 100, train_Loss: 1.4614
training Epoch: 100, train_Loss: 1.3105
training Epoch: 100, train_Loss: 1.4746
training Epoch: 100, train_Loss: 1.3864
training Epoch: 100, train_Loss: 0.5400
training Epoch: 100, train_Loss: 0.2994
training Epoch: 100, train_Loss: 1.0937
training Epoch: 100, train_Loss: 0.9633
training Epoch: 100, train_Loss: 0.3082
training Epoch: 100, train_Loss: 4.7325
training Epoch: 100, train_Loss: 0.8483
training Epoch: 100, train_Loss: 0.8255
training Epoch: 100, train_Loss: 1.3580
training Epoch: 100, train_Loss: 0.5348
training Epoch: 100, train_Loss: 0.9606
training Epoch: 100, train_Loss: 1.5982
training Epoch: 100, train_Loss: 0.5022
training Epoch: 100, train_Loss: 1.3148
training Epoch: 100, train_Loss: 2.0509
training Epoch: 100, train_Loss: 0.5279
training Epoch: 100, train_Loss: 0.6679
training Epoch: 100, train_Loss: 0.6505
training Epoch: 100, train_Loss: 1.1157
training Epoch: 100, train_Loss: 2.2897
training Epoch: 100, train_Loss: 0.9074
training Epoch: 100, train_Loss: 1.6157
training Epoch: 100, train_Loss: 1.0758
training Epoch: 100, train_Loss: 0.5889
training Epoch: 100, train_Loss: 1.2349
training Epoch: 100, train_Loss: 2.7451
training Epoch: 100, train_Loss: 1.7893
training Epoch: 100, train_Loss: 0.4429
training Epoch: 100, train_Loss: 0.8593
training Epoch: 100, train_Loss: 0.4173
training Epoch: 100, train_Loss: 0.4494
training Epoch: 100, train_Loss: 1.1425
training Epoch: 100, train_Loss: 0.8392
training Epoch: 100, train_Loss: 1.7233
training Epoch: 100, train_Loss: 0.6815
training Epoch: 100, train_Loss: 0.3721
training Epoch: 100, train_Loss: 1.9204
training Epoch: 100, train_Loss: 0.4737
training Epoch: 100, train_Loss: 0.9172
training Epoch: 100, train_Loss: 1.9446
training Epoch: 100, train_Loss: 0.2467
training Epoch: 100, train_Loss: 0.3702
training Epoch: 100, train_Loss: 0.8242
training Epoch: 100, train_Loss: 0.5806
training Epoch: 100, train_Loss: 0.6549
training Epoch: 100, train_Loss: 2.6995
training Epoch: 100, train_Loss: 1.6535
training Epoch: 100, train_Loss: 0.3214
training Epoch: 100, train_Loss: 1.7168
training Epoch: 100, train_Loss: 0.2906
training Epoch: 100, train_Loss: 0.6979
training Epoch: 100, train_Loss: 0.3375
training Epoch: 100, train_Loss: 1.8288
training Epoch: 100, train_Loss: 1.4884
training Epoch: 100, train_Loss: 0.8505
training Epoch: 100, train_Loss: 0.8223
training Epoch: 100, train_Loss: 0.5544
training Epoch: 100, train_Loss: 1.0643
training Epoch: 100, train_Loss: 1.0328
training Epoch: 100, train_Loss: 2.1756
training Epoch: 100, train_Loss: 1.7935
training Epoch: 100, train_Loss: 0.4910
training Epoch: 100, train_Loss: 1.5613
training Epoch: 100, train_Loss: 0.9901
training Epoch: 100, train_Loss: 0.3972
training Epoch: 100, train_Loss: 0.8613
training Epoch: 100, train_Loss: 0.7706
training Epoch: 100, train_Loss: 2.0427
training Epoch: 100, train_Loss: 0.6775
training Epoch: 100, train_Loss: 1.6749
training Epoch: 100, train_Loss: 2.3447
training Epoch: 100, train_Loss: 1.9712
training Epoch: 100, train_Loss: 0.9518
training Epoch: 100, train_Loss: 0.4898
training Epoch: 100, train_Loss: 3.5829
training Epoch: 100, train_Loss: 1.3665
training Epoch: 100, train_Loss: 0.5410
training Epoch: 100, train_Loss: 0.6412
training Epoch: 100, train_Loss: 0.4785
training Epoch: 100, train_Loss: 0.4945
training Epoch: 100, train_Loss: 0.4553
training Epoch: 100, train_Loss: 0.7168
training Epoch: 100, train_Loss: 0.5379
training Epoch: 100, train_Loss: 0.2762
training Epoch: 100, train_Loss: 0.3217
training Epoch: 100, train_Loss: 0.7759
training Epoch: 100, train_Loss: 1.3168
training Epoch: 100, train_Loss: 1.3092
training Epoch: 100, train_Loss: 2.0899
training Epoch: 100, train_Loss: 1.2687
training Epoch: 100, train_Loss: 2.7363
training Epoch: 100, train_Loss: 0.4838
training Epoch: 100, train_Loss: 0.7527
training Epoch: 100, train_Loss: 0.4100
training Epoch: 100, train_Loss: 0.5466
training Epoch: 100, train_Loss: 0.5153
training Epoch: 100, train_Loss: 1.2733
training Epoch: 100, train_Loss: 0.5935
training Epoch: 100, train_Loss: 0.7980
training Epoch: 100, train_Loss: 0.5926
training Epoch: 100, train_Loss: 0.9799
training Epoch: 100, train_Loss: 1.6189
training Epoch: 100, train_Loss: 1.3356
training Epoch: 100, train_Loss: 0.5707
training Epoch: 100, train_Loss: 1.4196
training Epoch: 100, train_Loss: 1.3061
training Epoch: 100, train_Loss: 0.6666
training Epoch: 100, train_Loss: 0.5640
training Epoch: 100, train_Loss: 2.0972
training Epoch: 100, train_Loss: 1.3184
training Epoch: 100, train_Loss: 2.3878
training Epoch: 100, train_Loss: 1.4046
training Epoch: 100, train_Loss: 1.8771
training Epoch: 100, train_Loss: 1.0393
training Epoch: 100, train_Loss: 0.9350
training Epoch: 100, train_Loss: 0.4739
training Epoch: 100, train_Loss: 1.3748
training Epoch: 100, train_Loss: 0.7496
training Epoch: 100, train_Loss: 1.3943
training Epoch: 100, train_Loss: 1.6444
training Epoch: 100, train_Loss: 0.4001
training Epoch: 100, train_Loss: 2.7845
training Epoch: 100, train_Loss: 0.6039
training Epoch: 100, train_Loss: 1.7535
training Epoch: 100, train_Loss: 1.2360
training Epoch: 100, train_Loss: 0.8625
training Epoch: 100, train_Loss: 0.3832
training Epoch: 100, train_Loss: 0.2893
training Epoch: 100, train_Loss: 0.7594
training Epoch: 100, train_Loss: 0.3357
training Epoch: 100, train_Loss: 0.9088
training Epoch: 100, train_Loss: 0.3667
training Epoch: 100, train_Loss: 1.9746
training Epoch: 100, train_Loss: 1.4129
training Epoch: 100, train_Loss: 0.8529
training Epoch: 100, train_Loss: 0.9414
training Epoch: 100, train_Loss: 0.6415
training Epoch: 100, train_Loss: 0.4881
training Epoch: 100, train_Loss: 0.4714
training Epoch: 100, train_Loss: 0.4733
training Epoch: 100, train_Loss: 2.2626
training Epoch: 100, train_Loss: 0.8673
training Epoch: 100, train_Loss: 0.7626
training Epoch: 100, train_Loss: 0.8244
training Epoch: 100, train_Loss: 1.3607
training Epoch: 100, train_Loss: 0.7301
training Epoch: 100, train_Loss: 0.6323
training Epoch: 100, train_Loss: 1.0904
training Epoch: 100, train_Loss: 2.4810
training Epoch: 100, train_Loss: 0.6981
training Epoch: 100, train_Loss: 0.9201
training Epoch: 100, train_Loss: 1.4914
training Epoch: 100, train_Loss: 1.1200
training Epoch: 100, train_Loss: 0.9558
training Epoch: 100, train_Loss: 0.7950
training Epoch: 100, train_Loss: 0.5546
training Epoch: 100, train_Loss: 0.6291
training Epoch: 100, train_Loss: 0.5241
training Epoch: 100, train_Loss: 1.6276
training Epoch: 100, train_Loss: 0.5333
training Epoch: 100, train_Loss: 0.8963
training Epoch: 100, train_Loss: 0.6763
training Epoch: 100, train_Loss: 0.4997
training Epoch: 100, train_Loss: 0.6489
training Epoch: 100, train_Loss: 0.5822
training Epoch: 100, train_Loss: 0.4406
training Epoch: 100, train_Loss: 0.4318
training Epoch: 100, train_Loss: 1.3573
training Epoch: 100, train_Loss: 0.6344
training Epoch: 100, train_Loss: 0.8152
training Epoch: 100, train_Loss: 0.7125
training Epoch: 100, train_Loss: 0.8766
training Epoch: 100, train_Loss: 0.3596
training Epoch: 100, train_Loss: 0.6458
training Epoch: 100, train_Loss: 0.5517
training Epoch: 100, train_Loss: 0.4325
training Epoch: 100, train_Loss: 2.8156
training Epoch: 100, train_Loss: 0.4487
training Epoch: 100, train_Loss: 0.1852
training Epoch: 100, train_Loss: 1.0914
training Epoch: 100, train_Loss: 0.7638
training Epoch: 100, train_Loss: 0.8480
training Epoch: 100, train_Loss: 1.6320
training Epoch: 100, train_Loss: 1.8989
training Epoch: 100, train_Loss: 1.0856
training Epoch: 100, train_Loss: 1.0976
training Epoch: 100, train_Loss: 0.6187
training Epoch: 100, train_Loss: 0.6520
training Epoch: 100, train_Loss: 0.9431
training Epoch: 100, train_Loss: 0.9882
training Epoch: 100, train_Loss: 0.7643
training Epoch: 100, train_Loss: 0.6490
training Epoch: 100, train_Loss: 1.2427
training Epoch: 100, train_Loss: 0.6833
training Epoch: 100, train_Loss: 0.7532
training Epoch: 100, train_Loss: 1.6079
training Epoch: 100, train_Loss: 1.3402
training Epoch: 100, train_Loss: 2.0586
training Epoch: 100, train_Loss: 1.4110
training Epoch: 100, train_Loss: 1.3988
training Epoch: 100, train_Loss: 1.7949
training Epoch: 100, train_Loss: 0.7281
training Epoch: 100, train_Loss: 1.9093
training Epoch: 100, train_Loss: 1.3451
training Epoch: 100, train_Loss: 1.9147
training Epoch: 100, train_Loss: 0.8338
training Epoch: 100, train_Loss: 1.4596
training Epoch: 100, train_Loss: 0.8766
training Epoch: 100, train_Loss: 1.0770
training Epoch: 100, train_Loss: 1.0132
training Epoch: 100, train_Loss: 1.5348
training Epoch: 100, train_Loss: 1.1951
training Epoch: 100, train_Loss: 0.8068
training Epoch: 100, train_Loss: 0.6697
training Epoch: 100, train_Loss: 0.9133
training Epoch: 100, train_Loss: 1.1164
training Epoch: 100, train_Loss: 2.6138
training Epoch: 100, train_Loss: 0.6386
training Epoch: 100, train_Loss: 0.8653
training Epoch: 100, train_Loss: 0.5770
training Epoch: 100, train_Loss: 0.8527
training Epoch: 100, train_Loss: 1.2166
training Epoch: 100, train_Loss: 0.7417
training Epoch: 100, train_Loss: 1.0880
training Epoch: 100, train_Loss: 0.3747
training Epoch: 100, train_Loss: 0.6432
training Epoch: 100, train_Loss: 3.7120
training Epoch: 100, train_Loss: 2.4738
training Epoch: 100, train_Loss: 2.6958
training Epoch: 100, train_Loss: 0.3333
training Epoch: 100, train_Loss: 0.5881
training Epoch: 100, train_Loss: 2.2036
training Epoch: 100, train_Loss: 0.8479
training Epoch: 100, train_Loss: 1.2270
training Epoch: 100, train_Loss: 0.3519
training Epoch: 100, train_Loss: 2.1897
training Epoch: 100, train_Loss: 1.8048
training Epoch: 100, train_Loss: 0.5337
training Epoch: 100, train_Loss: 1.9984
training Epoch: 100, train_Loss: 1.5981
training Epoch: 100, train_Loss: 1.4966
training Epoch: 100, train_Loss: 0.6605
training Epoch: 100, train_Loss: 1.0751
training Epoch: 100, train_Loss: 1.1263
training Epoch: 100, train_Loss: 0.8427
training Epoch: 100, train_Loss: 1.4936
training Epoch: 100, train_Loss: 1.2473
training Epoch: 100, train_Loss: 2.6523
training Epoch: 100, train_Loss: 1.3415
training Epoch: 100, train_Loss: 1.5105
training Epoch: 100, train_Loss: 1.1777
training Epoch: 100, train_Loss: 0.9748
training Epoch: 100, train_Loss: 1.1219
training Epoch: 100, train_Loss: 0.7872
training Epoch: 100, train_Loss: 0.9899
training Epoch: 100, train_Loss: 0.7726
training Epoch: 100, train_Loss: 0.5128
training Epoch: 100, train_Loss: 0.9515
training Epoch: 100, train_Loss: 1.6702
training Epoch: 100, train_Loss: 0.9662
training Epoch: 100, train_Loss: 0.4529
training Epoch: 100, train_Loss: 0.7053
training Epoch: 100, train_Loss: 0.7739
training Epoch: 100, train_Loss: 2.1784
training Epoch: 100, train_Loss: 0.6114
training Epoch: 100, train_Loss: 1.4173
training Epoch: 100, train_Loss: 1.0983
training Epoch: 100, train_Loss: 1.0737
training Epoch: 100, train_Loss: 0.8887
training Epoch: 100, train_Loss: 0.8307
training Epoch: 100, train_Loss: 2.4371
training Epoch: 100, train_Loss: 0.3310
training Epoch: 100, train_Loss: 2.3089
training Epoch: 100, train_Loss: 0.5612
training Epoch: 100, train_Loss: 0.7646
training Epoch: 100, train_Loss: 1.6964
training Epoch: 100, train_Loss: 1.4159
training Epoch: 100, train_Loss: 0.4134
training Epoch: 100, train_Loss: 0.5325
training Epoch: 100, train_Loss: 1.6658
training Epoch: 100, train_Loss: 0.6660
training Epoch: 100, train_Loss: 2.1137
training Epoch: 100, train_Loss: 0.6512
training Epoch: 100, train_Loss: 0.8624
training Epoch: 100, train_Loss: 1.0930
training Epoch: 100, train_Loss: 0.4358
training Epoch: 100, train_Loss: 1.6274
training Epoch: 100, train_Loss: 0.7211
training Epoch: 100, train_Loss: 0.4370
training Epoch: 100, train_Loss: 1.7096
training Epoch: 100, train_Loss: 0.6371
training Epoch: 100, train_Loss: 1.6273
training Epoch: 100, train_Loss: 1.6037
training Epoch: 100, train_Loss: 0.6145
training Epoch: 100, train_Loss: 1.3775
training Epoch: 100, train_Loss: 0.2961
training Epoch: 100, train_Loss: 1.6344
training Epoch: 100, train_Loss: 0.3355
training Epoch: 100, train_Loss: 0.3486
training Epoch: 100, train_Loss: 1.9435
training Epoch: 100, train_Loss: 0.8277
training Epoch: 100, train_Loss: 1.2464
training Epoch: 100, train_Loss: 0.7663
training Epoch: 100, train_Loss: 2.3066
training Epoch: 100, train_Loss: 2.7957
training Epoch: 100, train_Loss: 0.7368
training Epoch: 100, train_Loss: 0.4111
training Epoch: 100, train_Loss: 1.1007
training Epoch: 100, train_Loss: 1.5595
training Epoch: 100, train_Loss: 0.5962
training Epoch: 100, train_Loss: 1.3709
training Epoch: 100, train_Loss: 2.0876
training Epoch: 100, train_Loss: 0.8701
training Epoch: 100, train_Loss: 0.5730
training Epoch: 100, train_Loss: 0.7669
training Epoch: 100, train_Loss: 0.5307
training Epoch: 100, train_Loss: 0.4939
training Epoch: 100, train_Loss: 1.5163
training Epoch: 100, train_Loss: 0.7370
training Epoch: 100, train_Loss: 0.8772
training Epoch: 100, train_Loss: 0.6733
training Epoch: 100, train_Loss: 0.9994
training Epoch: 100, train_Loss: 1.0617
training Epoch: 100, train_Loss: 0.4929
training Epoch: 100, train_Loss: 0.4870
training Epoch: 100, train_Loss: 1.4390
training Epoch: 100, train_Loss: 3.2145
training Epoch: 100, train_Loss: 1.3467
training Epoch: 100, train_Loss: 0.6523
training Epoch: 100, train_Loss: 0.3813
training Epoch: 100, train_Loss: 0.3196
training Epoch: 100, train_Loss: 3.1186
training Epoch: 100, train_Loss: 1.5966
training Epoch: 100, train_Loss: 0.6531
training Epoch: 100, train_Loss: 1.7298
training Epoch: 100, train_Loss: 0.4202
training Epoch: 100, train_Loss: 0.5502
training Epoch: 100, train_Loss: 1.4802
training Epoch: 100, train_Loss: 1.6604
training Epoch: 100, train_Loss: 1.0448
training Epoch: 100, train_Loss: 0.5283
training Epoch: 100, train_Loss: 0.6933
training Epoch: 100, train_Loss: 0.6703
training Epoch: 100, train_Loss: 0.7502
training Epoch: 100, train_Loss: 0.9843
training Epoch: 100, train_Loss: 1.9593
training Epoch: 100, train_Loss: 0.4000
training Epoch: 100, train_Loss: 1.0294
training Epoch: 100, train_Loss: 0.5694
training Epoch: 100, train_Loss: 2.2048
training Epoch: 100, train_Loss: 1.6240
training Epoch: 100, train_Loss: 0.4981
training Epoch: 100, train_Loss: 1.4768
training Epoch: 100, train_Loss: 0.6771
training Epoch: 100, train_Loss: 1.9683
training Epoch: 100, train_Loss: 0.2973
training Epoch: 100, train_Loss: 0.8097
training Epoch: 100, train_Loss: 2.2275
training Epoch: 100, train_Loss: 0.2800
training Epoch: 100, train_Loss: 1.2014
training Epoch: 100, train_Loss: 0.2678
training Epoch: 100, train_Loss: 0.3262
training Epoch: 100, train_Loss: 3.3438
training Epoch: 100, train_Loss: 0.2322
training Epoch: 100, train_Loss: 1.6159
training Epoch: 100, train_Loss: 0.2486
training Epoch: 100, train_Loss: 0.5039
training Epoch: 100, train_Loss: 0.8172
training Epoch: 100, train_Loss: 1.9389
training Epoch: 100, train_Loss: 0.3830
training Epoch: 100, train_Loss: 0.4213
training Epoch: 100, train_Loss: 0.4843
training Epoch: 100, train_Loss: 1.2284
training Epoch: 100, train_Loss: 2.7826
training Epoch: 100, train_Loss: 0.5764
training Epoch: 100, train_Loss: 0.5881
training Epoch: 100, train_Loss: 1.5779
training Epoch: 100, train_Loss: 0.3693
training Epoch: 100, train_Loss: 0.6445
training Epoch: 100, train_Loss: 1.7068
training Epoch: 100, train_Loss: 1.2158
training Epoch: 100, train_Loss: 0.7171
training Epoch: 100, train_Loss: 2.4349
training Epoch: 100, train_Loss: 0.4197
training Epoch: 100, train_Loss: 1.0684
training Epoch: 100, train_Loss: 1.2612
training Epoch: 100, train_Loss: 1.6292
training Epoch: 100, train_Loss: 1.0641
training Epoch: 100, train_Loss: 0.7056
training Epoch: 100, train_Loss: 0.7644
training Epoch: 100, train_Loss: 2.6112
training Epoch: 100, train_Loss: 0.4051
training Epoch: 100, train_Loss: 0.8018
training Epoch: 100, train_Loss: 0.4745
training Epoch: 100, train_Loss: 0.9438
training Epoch: 100, train_Loss: 0.5574
training Epoch: 100, train_Loss: 0.7063
training Epoch: 100, train_Loss: 1.0252
training Epoch: 100, train_Loss: 0.6112
training Epoch: 100, train_Loss: 1.3388
training Epoch: 100, train_Loss: 0.8585
training Epoch: 100, train_Loss: 0.7433
training Epoch: 100, train_Loss: 1.4865
training Epoch: 100, train_Loss: 0.5325
training Epoch: 100, train_Loss: 0.9956
training Epoch: 100, train_Loss: 0.8337
training Epoch: 100, train_Loss: 0.2623
training Epoch: 100, train_Loss: 1.5370
training Epoch: 100, train_Loss: 1.4475
training Epoch: 100, train_Loss: 0.3089
training Epoch: 100, train_Loss: 1.1139
training Epoch: 100, train_Loss: 0.9074
training Epoch: 100, train_Loss: 0.8462
training Epoch: 100, train_Loss: 0.8837
training Epoch: 100, train_Loss: 3.1439
training Epoch: 100, train_Loss: 1.3848
training Epoch: 100, train_Loss: 2.2110
training Epoch: 100, train_Loss: 0.9979
training Epoch: 100, train_Loss: 0.3993
training Epoch: 100, train_Loss: 0.5908
training Epoch: 100, train_Loss: 1.6404
training Epoch: 100, train_Loss: 1.8705
training Epoch: 100, train_Loss: 2.0362
training Epoch: 100, train_Loss: 0.8466
training Epoch: 100, train_Loss: 0.6392
training Epoch: 100, train_Loss: 1.5131
training Epoch: 100, train_Loss: 0.6622
training Epoch: 100, train_Loss: 0.5707
training Epoch: 100, train_Loss: 2.2104
training Epoch: 100, train_Loss: 1.7007
training Epoch: 100, train_Loss: 1.1935
training Epoch: 100, train_Loss: 1.0126
training Epoch: 100, train_Loss: 2.3055
training Epoch: 100, train_Loss: 2.6795
training Epoch: 100, train_Loss: 0.5644
training Epoch: 100, train_Loss: 0.7017
training Epoch: 100, train_Loss: 1.8534
training Epoch: 100, train_Loss: 0.9718
training Epoch: 100, train_Loss: 0.8891
training Epoch: 100, train_Loss: 1.5743
training Epoch: 100, train_Loss: 0.8620
training Epoch: 100, train_Loss: 1.5631
training Epoch: 100, train_Loss: 0.6451
training Epoch: 100, train_Loss: 0.7199
training Epoch: 100, train_Loss: 1.0638
training Epoch: 100, train_Loss: 0.4657
training Epoch: 100, train_Loss: 0.9759
training Epoch: 100, train_Loss: 0.4388
training Epoch: 100, train_Loss: 0.7060
training Epoch: 100, train_Loss: 2.3462
training Epoch: 100, train_Loss: 1.0007
training Epoch: 100, train_Loss: 1.0721
training Epoch: 100, train_Loss: 0.6329
training Epoch: 100, train_Loss: 0.3295
training Epoch: 100, train_Loss: 0.8827
training Epoch: 100, train_Loss: 1.1185
training Epoch: 100, train_Loss: 0.6894
training Epoch: 100, train_Loss: 1.1874
training Epoch: 100, train_Loss: 1.3318
training Epoch: 100, train_Loss: 0.3486
training Epoch: 100, train_Loss: 0.6340
training Epoch: 100, train_Loss: 1.6274
training Epoch: 100, train_Loss: 1.1273
training Epoch: 100, train_Loss: 0.5711
training Epoch: 100, train_Loss: 1.0505
training Epoch: 100, train_Loss: 1.2604
training Epoch: 100, train_Loss: 1.0648
training Epoch: 100, train_Loss: 1.7010
training Epoch: 100, train_Loss: 1.0864
training Epoch: 100, train_Loss: 2.1480
training Epoch: 100, train_Loss: 1.9125
training Epoch: 100, train_Loss: 0.9009
training Epoch: 100, train_Loss: 0.4745
training Epoch: 100, train_Loss: 0.9862
training Epoch: 100, train_Loss: 1.1207
training Epoch: 100, train_Loss: 0.7149
training Epoch: 100, train_Loss: 1.0395
training Epoch: 100, train_Loss: 1.0165
training Epoch: 100, train_Loss: 1.9140
training Epoch: 100, train_Loss: 2.2107
training Epoch: 100, train_Loss: 0.6693
training Epoch: 100, train_Loss: 1.5977
training Epoch: 100, train_Loss: 0.7501
training Epoch: 100, train_Loss: 0.5445
training Epoch: 100, train_Loss: 0.4370
fold,epoch,train_loss: 1 99 1.0869532
fold,epoch,train_loss: 1 100 1.0842944
====Evaluation
fold:1, epoch:100,train:1.084294, valid:1.122735 

fold: 2
fold,epoch,train_loss: 2 0 1.0893731
fold,epoch,train_loss: 2 1 1.0833791
fold,epoch,train_loss: 2 2 1.085783
fold,epoch,train_loss: 2 3 1.0871316
fold,epoch,train_loss: 2 4 1.0907675
fold,epoch,train_loss: 2 5 1.0879358
fold,epoch,train_loss: 2 6 1.0895739
fold,epoch,train_loss: 2 7 1.0931578
fold,epoch,train_loss: 2 8 1.091668
fold,epoch,train_loss: 2 9 1.091934
fold,epoch,train_loss: 2 10 1.0872993
fold,epoch,train_loss: 2 11 1.0871525
fold,epoch,train_loss: 2 12 1.0868634
fold,epoch,train_loss: 2 13 1.0868313
fold,epoch,train_loss: 2 14 1.0880315
fold,epoch,train_loss: 2 15 1.0884537
fold,epoch,train_loss: 2 16 1.0939394
fold,epoch,train_loss: 2 17 1.0899769
fold,epoch,train_loss: 2 18 1.0875989
fold,epoch,train_loss: 2 19 1.0871232
fold,epoch,train_loss: 2 20 1.0886468
fold,epoch,train_loss: 2 21 1.0940415
fold,epoch,train_loss: 2 22 1.0958155
fold,epoch,train_loss: 2 23 1.0869732
fold,epoch,train_loss: 2 24 1.0949616
fold,epoch,train_loss: 2 25 1.0876851
fold,epoch,train_loss: 2 26 1.0869997
fold,epoch,train_loss: 2 27 1.0893759
fold,epoch,train_loss: 2 28 1.0901299
fold,epoch,train_loss: 2 29 1.0867934
fold,epoch,train_loss: 2 30 1.0921345
fold,epoch,train_loss: 2 31 1.0877849
fold,epoch,train_loss: 2 32 1.0896537
fold,epoch,train_loss: 2 33 1.0839617
fold,epoch,train_loss: 2 34 1.0905795
fold,epoch,train_loss: 2 35 1.0860307
fold,epoch,train_loss: 2 36 1.0950234
fold,epoch,train_loss: 2 37 1.0914274
fold,epoch,train_loss: 2 38 1.097228
fold,epoch,train_loss: 2 39 1.0889151
fold,epoch,train_loss: 2 40 1.0858208
fold,epoch,train_loss: 2 41 1.0851746
fold,epoch,train_loss: 2 42 1.088424
fold,epoch,train_loss: 2 43 1.0889087
fold,epoch,train_loss: 2 44 1.0912343
fold,epoch,train_loss: 2 45 1.0912496
fold,epoch,train_loss: 2 46 1.0896053
fold,epoch,train_loss: 2 47 1.0903637
fold,epoch,train_loss: 2 48 1.0878999
training Epoch: 50, train_Loss: 1.7896
training Epoch: 50, train_Loss: 0.4206
training Epoch: 50, train_Loss: 1.5289
training Epoch: 50, train_Loss: 0.5249
training Epoch: 50, train_Loss: 1.3486
training Epoch: 50, train_Loss: 1.0335
training Epoch: 50, train_Loss: 3.2833
training Epoch: 50, train_Loss: 0.7988
training Epoch: 50, train_Loss: 0.7911
training Epoch: 50, train_Loss: 0.4072
training Epoch: 50, train_Loss: 1.6040
training Epoch: 50, train_Loss: 1.2369
training Epoch: 50, train_Loss: 1.2462
training Epoch: 50, train_Loss: 0.4164
training Epoch: 50, train_Loss: 1.0522
training Epoch: 50, train_Loss: 0.6415
training Epoch: 50, train_Loss: 1.2048
training Epoch: 50, train_Loss: 0.3864
training Epoch: 50, train_Loss: 1.5508
training Epoch: 50, train_Loss: 0.4630
training Epoch: 50, train_Loss: 0.5404
training Epoch: 50, train_Loss: 0.5675
training Epoch: 50, train_Loss: 1.4673
training Epoch: 50, train_Loss: 2.5395
training Epoch: 50, train_Loss: 0.5369
training Epoch: 50, train_Loss: 1.3442
training Epoch: 50, train_Loss: 0.5277
training Epoch: 50, train_Loss: 0.7616
training Epoch: 50, train_Loss: 0.4566
training Epoch: 50, train_Loss: 0.4261
training Epoch: 50, train_Loss: 0.6126
training Epoch: 50, train_Loss: 0.5136
training Epoch: 50, train_Loss: 0.2798
training Epoch: 50, train_Loss: 0.5464
training Epoch: 50, train_Loss: 0.8951
training Epoch: 50, train_Loss: 2.2324
training Epoch: 50, train_Loss: 1.5136
training Epoch: 50, train_Loss: 0.5691
training Epoch: 50, train_Loss: 0.3481
training Epoch: 50, train_Loss: 1.7399
training Epoch: 50, train_Loss: 0.6694
training Epoch: 50, train_Loss: 0.4410
training Epoch: 50, train_Loss: 1.6347
training Epoch: 50, train_Loss: 2.6966
training Epoch: 50, train_Loss: 0.3846
training Epoch: 50, train_Loss: 1.0405
training Epoch: 50, train_Loss: 1.9656
training Epoch: 50, train_Loss: 0.8032
training Epoch: 50, train_Loss: 1.6727
training Epoch: 50, train_Loss: 1.9010
training Epoch: 50, train_Loss: 0.7485
training Epoch: 50, train_Loss: 0.8794
training Epoch: 50, train_Loss: 1.8632
training Epoch: 50, train_Loss: 0.8514
training Epoch: 50, train_Loss: 1.5370
training Epoch: 50, train_Loss: 1.1367
training Epoch: 50, train_Loss: 1.1747
training Epoch: 50, train_Loss: 1.4027
training Epoch: 50, train_Loss: 0.6026
training Epoch: 50, train_Loss: 0.8958
training Epoch: 50, train_Loss: 1.0884
training Epoch: 50, train_Loss: 1.4122
training Epoch: 50, train_Loss: 0.8737
training Epoch: 50, train_Loss: 1.0621
training Epoch: 50, train_Loss: 0.4480
training Epoch: 50, train_Loss: 1.2313
training Epoch: 50, train_Loss: 1.4406
training Epoch: 50, train_Loss: 1.5087
training Epoch: 50, train_Loss: 0.8895
training Epoch: 50, train_Loss: 0.5772
training Epoch: 50, train_Loss: 2.0089
training Epoch: 50, train_Loss: 1.2242
training Epoch: 50, train_Loss: 1.0846
training Epoch: 50, train_Loss: 1.2268
training Epoch: 50, train_Loss: 0.6560
training Epoch: 50, train_Loss: 0.4495
training Epoch: 50, train_Loss: 1.6310
training Epoch: 50, train_Loss: 0.5806
training Epoch: 50, train_Loss: 0.8950
training Epoch: 50, train_Loss: 0.4947
training Epoch: 50, train_Loss: 0.8537
training Epoch: 50, train_Loss: 0.7506
training Epoch: 50, train_Loss: 0.9518
training Epoch: 50, train_Loss: 0.3030
training Epoch: 50, train_Loss: 0.2368
training Epoch: 50, train_Loss: 0.5688
training Epoch: 50, train_Loss: 2.4056
training Epoch: 50, train_Loss: 2.3180
training Epoch: 50, train_Loss: 1.7840
training Epoch: 50, train_Loss: 1.1166
training Epoch: 50, train_Loss: 0.4528
training Epoch: 50, train_Loss: 1.3476
training Epoch: 50, train_Loss: 1.7949
training Epoch: 50, train_Loss: 1.2431
training Epoch: 50, train_Loss: 0.7523
training Epoch: 50, train_Loss: 0.5944
training Epoch: 50, train_Loss: 0.8232
training Epoch: 50, train_Loss: 0.9794
training Epoch: 50, train_Loss: 0.6436
training Epoch: 50, train_Loss: 1.0054
training Epoch: 50, train_Loss: 1.8135
training Epoch: 50, train_Loss: 0.4125
training Epoch: 50, train_Loss: 1.4079
training Epoch: 50, train_Loss: 1.1082
training Epoch: 50, train_Loss: 1.8982
training Epoch: 50, train_Loss: 0.3958
training Epoch: 50, train_Loss: 0.9138
training Epoch: 50, train_Loss: 2.2593
training Epoch: 50, train_Loss: 1.4961
training Epoch: 50, train_Loss: 1.0445
training Epoch: 50, train_Loss: 0.9756
training Epoch: 50, train_Loss: 1.7618
training Epoch: 50, train_Loss: 1.7308
training Epoch: 50, train_Loss: 2.1113
training Epoch: 50, train_Loss: 1.2739
training Epoch: 50, train_Loss: 0.8045
training Epoch: 50, train_Loss: 1.8958
training Epoch: 50, train_Loss: 0.6230
training Epoch: 50, train_Loss: 0.6075
training Epoch: 50, train_Loss: 2.1367
training Epoch: 50, train_Loss: 0.5223
training Epoch: 50, train_Loss: 1.8070
training Epoch: 50, train_Loss: 0.6977
training Epoch: 50, train_Loss: 0.7826
training Epoch: 50, train_Loss: 1.1980
training Epoch: 50, train_Loss: 0.4911
training Epoch: 50, train_Loss: 1.3856
training Epoch: 50, train_Loss: 1.4889
training Epoch: 50, train_Loss: 0.4425
training Epoch: 50, train_Loss: 2.2471
training Epoch: 50, train_Loss: 0.8447
training Epoch: 50, train_Loss: 1.4709
training Epoch: 50, train_Loss: 0.7300
training Epoch: 50, train_Loss: 1.9940
training Epoch: 50, train_Loss: 3.8506
training Epoch: 50, train_Loss: 0.4926
training Epoch: 50, train_Loss: 0.6737
training Epoch: 50, train_Loss: 0.7910
training Epoch: 50, train_Loss: 0.9443
training Epoch: 50, train_Loss: 0.8071
training Epoch: 50, train_Loss: 0.4126
training Epoch: 50, train_Loss: 0.9477
training Epoch: 50, train_Loss: 0.4780
training Epoch: 50, train_Loss: 1.0467
training Epoch: 50, train_Loss: 0.6665
training Epoch: 50, train_Loss: 1.7580
training Epoch: 50, train_Loss: 1.4159
training Epoch: 50, train_Loss: 0.5347
training Epoch: 50, train_Loss: 2.3048
training Epoch: 50, train_Loss: 1.8791
training Epoch: 50, train_Loss: 1.0213
training Epoch: 50, train_Loss: 1.6166
training Epoch: 50, train_Loss: 0.6237
training Epoch: 50, train_Loss: 1.2018
training Epoch: 50, train_Loss: 1.7123
training Epoch: 50, train_Loss: 2.1270
training Epoch: 50, train_Loss: 0.6828
training Epoch: 50, train_Loss: 0.8897
training Epoch: 50, train_Loss: 0.8241
training Epoch: 50, train_Loss: 0.8392
training Epoch: 50, train_Loss: 1.2181
training Epoch: 50, train_Loss: 0.6903
training Epoch: 50, train_Loss: 1.5204
training Epoch: 50, train_Loss: 1.0635
training Epoch: 50, train_Loss: 1.1005
training Epoch: 50, train_Loss: 0.5844
training Epoch: 50, train_Loss: 0.9014
training Epoch: 50, train_Loss: 0.5067
training Epoch: 50, train_Loss: 0.3947
training Epoch: 50, train_Loss: 1.4875
training Epoch: 50, train_Loss: 0.2860
training Epoch: 50, train_Loss: 0.2604
training Epoch: 50, train_Loss: 2.8894
training Epoch: 50, train_Loss: 1.9133
training Epoch: 50, train_Loss: 3.3635
training Epoch: 50, train_Loss: 1.6506
training Epoch: 50, train_Loss: 1.7135
training Epoch: 50, train_Loss: 0.1755
training Epoch: 50, train_Loss: 0.7036
training Epoch: 50, train_Loss: 0.6855
training Epoch: 50, train_Loss: 0.9964
training Epoch: 50, train_Loss: 1.2019
training Epoch: 50, train_Loss: 0.7901
training Epoch: 50, train_Loss: 0.6364
training Epoch: 50, train_Loss: 2.1585
training Epoch: 50, train_Loss: 1.0257
training Epoch: 50, train_Loss: 0.5990
training Epoch: 50, train_Loss: 0.5043
training Epoch: 50, train_Loss: 0.4880
training Epoch: 50, train_Loss: 0.7534
training Epoch: 50, train_Loss: 0.8680
training Epoch: 50, train_Loss: 0.2781
training Epoch: 50, train_Loss: 0.4079
training Epoch: 50, train_Loss: 0.4629
training Epoch: 50, train_Loss: 0.4696
training Epoch: 50, train_Loss: 1.9802
training Epoch: 50, train_Loss: 1.4527
training Epoch: 50, train_Loss: 0.2432
training Epoch: 50, train_Loss: 0.9881
training Epoch: 50, train_Loss: 0.7269
training Epoch: 50, train_Loss: 0.4664
training Epoch: 50, train_Loss: 1.9499
training Epoch: 50, train_Loss: 1.2127
training Epoch: 50, train_Loss: 0.8011
training Epoch: 50, train_Loss: 1.7950
training Epoch: 50, train_Loss: 0.9495
training Epoch: 50, train_Loss: 0.6262
training Epoch: 50, train_Loss: 1.8882
training Epoch: 50, train_Loss: 1.5628
training Epoch: 50, train_Loss: 0.9660
training Epoch: 50, train_Loss: 1.8272
training Epoch: 50, train_Loss: 1.5983
training Epoch: 50, train_Loss: 0.9392
training Epoch: 50, train_Loss: 1.1720
training Epoch: 50, train_Loss: 0.3728
training Epoch: 50, train_Loss: 0.9901
training Epoch: 50, train_Loss: 0.9109
training Epoch: 50, train_Loss: 1.7356
training Epoch: 50, train_Loss: 0.8346
training Epoch: 50, train_Loss: 2.2644
training Epoch: 50, train_Loss: 1.0856
training Epoch: 50, train_Loss: 0.8701
training Epoch: 50, train_Loss: 0.8822
training Epoch: 50, train_Loss: 0.7163
training Epoch: 50, train_Loss: 0.6729
training Epoch: 50, train_Loss: 0.9362
training Epoch: 50, train_Loss: 0.5556
training Epoch: 50, train_Loss: 1.4968
training Epoch: 50, train_Loss: 0.8321
training Epoch: 50, train_Loss: 2.4832
training Epoch: 50, train_Loss: 0.9632
training Epoch: 50, train_Loss: 1.2852
training Epoch: 50, train_Loss: 0.6421
training Epoch: 50, train_Loss: 1.1806
training Epoch: 50, train_Loss: 1.0792
training Epoch: 50, train_Loss: 1.7697
training Epoch: 50, train_Loss: 1.3880
training Epoch: 50, train_Loss: 0.6431
training Epoch: 50, train_Loss: 0.7502
training Epoch: 50, train_Loss: 0.3406
training Epoch: 50, train_Loss: 2.5052
training Epoch: 50, train_Loss: 1.7871
training Epoch: 50, train_Loss: 2.0443
training Epoch: 50, train_Loss: 1.2503
training Epoch: 50, train_Loss: 0.6213
training Epoch: 50, train_Loss: 1.6733
training Epoch: 50, train_Loss: 0.5693
training Epoch: 50, train_Loss: 1.0282
training Epoch: 50, train_Loss: 0.8552
training Epoch: 50, train_Loss: 1.2155
training Epoch: 50, train_Loss: 1.1599
training Epoch: 50, train_Loss: 1.8274
training Epoch: 50, train_Loss: 1.0872
training Epoch: 50, train_Loss: 0.8203
training Epoch: 50, train_Loss: 0.8117
training Epoch: 50, train_Loss: 1.6736
training Epoch: 50, train_Loss: 0.8870
training Epoch: 50, train_Loss: 1.5877
training Epoch: 50, train_Loss: 0.7144
training Epoch: 50, train_Loss: 0.6345
training Epoch: 50, train_Loss: 0.6374
training Epoch: 50, train_Loss: 0.6875
training Epoch: 50, train_Loss: 1.0979
training Epoch: 50, train_Loss: 1.4136
training Epoch: 50, train_Loss: 0.9763
training Epoch: 50, train_Loss: 0.9332
training Epoch: 50, train_Loss: 0.6333
training Epoch: 50, train_Loss: 1.4269
training Epoch: 50, train_Loss: 1.0159
training Epoch: 50, train_Loss: 1.3863
training Epoch: 50, train_Loss: 0.8559
training Epoch: 50, train_Loss: 0.7934
training Epoch: 50, train_Loss: 2.1519
training Epoch: 50, train_Loss: 2.1024
training Epoch: 50, train_Loss: 0.5539
training Epoch: 50, train_Loss: 0.6740
training Epoch: 50, train_Loss: 0.6391
training Epoch: 50, train_Loss: 1.8497
training Epoch: 50, train_Loss: 1.7037
training Epoch: 50, train_Loss: 1.5394
training Epoch: 50, train_Loss: 0.6856
training Epoch: 50, train_Loss: 1.8202
training Epoch: 50, train_Loss: 0.5738
training Epoch: 50, train_Loss: 0.3764
training Epoch: 50, train_Loss: 2.3051
training Epoch: 50, train_Loss: 0.4197
training Epoch: 50, train_Loss: 0.4770
training Epoch: 50, train_Loss: 1.2946
training Epoch: 50, train_Loss: 2.1054
training Epoch: 50, train_Loss: 0.5298
training Epoch: 50, train_Loss: 0.5380
training Epoch: 50, train_Loss: 0.5782
training Epoch: 50, train_Loss: 1.2711
training Epoch: 50, train_Loss: 1.1606
training Epoch: 50, train_Loss: 0.9783
training Epoch: 50, train_Loss: 1.1874
training Epoch: 50, train_Loss: 1.1084
training Epoch: 50, train_Loss: 1.4583
training Epoch: 50, train_Loss: 2.2141
training Epoch: 50, train_Loss: 0.7097
training Epoch: 50, train_Loss: 0.9655
training Epoch: 50, train_Loss: 2.2672
training Epoch: 50, train_Loss: 0.8077
training Epoch: 50, train_Loss: 0.7045
training Epoch: 50, train_Loss: 1.2102
training Epoch: 50, train_Loss: 0.9765
training Epoch: 50, train_Loss: 1.0184
training Epoch: 50, train_Loss: 2.7624
training Epoch: 50, train_Loss: 1.8327
training Epoch: 50, train_Loss: 1.6238
training Epoch: 50, train_Loss: 1.7087
training Epoch: 50, train_Loss: 0.7956
training Epoch: 50, train_Loss: 0.5012
training Epoch: 50, train_Loss: 0.9484
training Epoch: 50, train_Loss: 0.5337
training Epoch: 50, train_Loss: 0.6160
training Epoch: 50, train_Loss: 0.7924
training Epoch: 50, train_Loss: 0.5222
training Epoch: 50, train_Loss: 2.6174
training Epoch: 50, train_Loss: 0.8706
training Epoch: 50, train_Loss: 0.4774
training Epoch: 50, train_Loss: 0.5643
training Epoch: 50, train_Loss: 1.2665
training Epoch: 50, train_Loss: 0.6448
training Epoch: 50, train_Loss: 0.6732
training Epoch: 50, train_Loss: 2.7686
training Epoch: 50, train_Loss: 0.8112
training Epoch: 50, train_Loss: 2.7567
training Epoch: 50, train_Loss: 2.2108
training Epoch: 50, train_Loss: 0.6824
training Epoch: 50, train_Loss: 1.2734
training Epoch: 50, train_Loss: 0.6766
training Epoch: 50, train_Loss: 0.3999
training Epoch: 50, train_Loss: 1.0941
training Epoch: 50, train_Loss: 0.7232
training Epoch: 50, train_Loss: 0.6681
training Epoch: 50, train_Loss: 0.5045
training Epoch: 50, train_Loss: 0.5050
training Epoch: 50, train_Loss: 0.8094
training Epoch: 50, train_Loss: 0.9348
training Epoch: 50, train_Loss: 0.6439
training Epoch: 50, train_Loss: 0.5499
training Epoch: 50, train_Loss: 0.2470
training Epoch: 50, train_Loss: 1.2812
training Epoch: 50, train_Loss: 1.2252
training Epoch: 50, train_Loss: 2.2407
training Epoch: 50, train_Loss: 1.4876
training Epoch: 50, train_Loss: 1.9766
training Epoch: 50, train_Loss: 0.1681
training Epoch: 50, train_Loss: 0.9381
training Epoch: 50, train_Loss: 2.4164
training Epoch: 50, train_Loss: 1.0986
training Epoch: 50, train_Loss: 0.9570
training Epoch: 50, train_Loss: 0.4578
training Epoch: 50, train_Loss: 2.5900
training Epoch: 50, train_Loss: 0.8483
training Epoch: 50, train_Loss: 1.8820
training Epoch: 50, train_Loss: 0.9575
training Epoch: 50, train_Loss: 1.0931
training Epoch: 50, train_Loss: 0.8314
training Epoch: 50, train_Loss: 0.5688
training Epoch: 50, train_Loss: 0.5262
training Epoch: 50, train_Loss: 0.6569
training Epoch: 50, train_Loss: 0.5720
training Epoch: 50, train_Loss: 0.7537
training Epoch: 50, train_Loss: 1.5917
training Epoch: 50, train_Loss: 2.7462
training Epoch: 50, train_Loss: 0.4657
training Epoch: 50, train_Loss: 1.2765
training Epoch: 50, train_Loss: 0.4677
training Epoch: 50, train_Loss: 1.8646
training Epoch: 50, train_Loss: 0.9561
training Epoch: 50, train_Loss: 1.1041
training Epoch: 50, train_Loss: 0.3996
training Epoch: 50, train_Loss: 0.8212
training Epoch: 50, train_Loss: 0.3461
training Epoch: 50, train_Loss: 1.2751
training Epoch: 50, train_Loss: 0.5153
training Epoch: 50, train_Loss: 0.6228
training Epoch: 50, train_Loss: 2.6581
training Epoch: 50, train_Loss: 0.7177
training Epoch: 50, train_Loss: 1.9339
training Epoch: 50, train_Loss: 1.7108
training Epoch: 50, train_Loss: 2.5514
training Epoch: 50, train_Loss: 0.7266
training Epoch: 50, train_Loss: 0.3971
training Epoch: 50, train_Loss: 0.6698
training Epoch: 50, train_Loss: 1.1523
training Epoch: 50, train_Loss: 0.4326
training Epoch: 50, train_Loss: 2.9733
training Epoch: 50, train_Loss: 0.3514
training Epoch: 50, train_Loss: 0.3917
training Epoch: 50, train_Loss: 0.8770
training Epoch: 50, train_Loss: 0.3787
training Epoch: 50, train_Loss: 1.5061
training Epoch: 50, train_Loss: 0.9436
training Epoch: 50, train_Loss: 0.6110
training Epoch: 50, train_Loss: 1.0400
training Epoch: 50, train_Loss: 2.2336
training Epoch: 50, train_Loss: 1.2836
training Epoch: 50, train_Loss: 0.6605
training Epoch: 50, train_Loss: 1.2403
training Epoch: 50, train_Loss: 0.9298
training Epoch: 50, train_Loss: 0.5136
training Epoch: 50, train_Loss: 0.9170
training Epoch: 50, train_Loss: 0.4498
training Epoch: 50, train_Loss: 0.7254
training Epoch: 50, train_Loss: 0.5118
training Epoch: 50, train_Loss: 0.8216
training Epoch: 50, train_Loss: 0.8396
training Epoch: 50, train_Loss: 1.6215
training Epoch: 50, train_Loss: 0.5796
training Epoch: 50, train_Loss: 0.7072
training Epoch: 50, train_Loss: 0.4556
training Epoch: 50, train_Loss: 1.7755
training Epoch: 50, train_Loss: 1.4498
training Epoch: 50, train_Loss: 0.2100
training Epoch: 50, train_Loss: 0.4894
training Epoch: 50, train_Loss: 0.2068
training Epoch: 50, train_Loss: 0.3277
training Epoch: 50, train_Loss: 0.4567
training Epoch: 50, train_Loss: 1.1146
training Epoch: 50, train_Loss: 0.6881
training Epoch: 50, train_Loss: 0.6963
training Epoch: 50, train_Loss: 2.0209
training Epoch: 50, train_Loss: 0.4711
training Epoch: 50, train_Loss: 1.4684
training Epoch: 50, train_Loss: 0.6502
training Epoch: 50, train_Loss: 1.5460
training Epoch: 50, train_Loss: 1.5010
training Epoch: 50, train_Loss: 0.2035
training Epoch: 50, train_Loss: 1.3141
training Epoch: 50, train_Loss: 0.3308
training Epoch: 50, train_Loss: 0.5472
training Epoch: 50, train_Loss: 0.2965
training Epoch: 50, train_Loss: 0.8622
training Epoch: 50, train_Loss: 1.3487
training Epoch: 50, train_Loss: 0.6982
training Epoch: 50, train_Loss: 1.1305
training Epoch: 50, train_Loss: 0.7281
training Epoch: 50, train_Loss: 4.2184
training Epoch: 50, train_Loss: 0.3689
training Epoch: 50, train_Loss: 1.6335
training Epoch: 50, train_Loss: 0.5974
training Epoch: 50, train_Loss: 2.1113
training Epoch: 50, train_Loss: 0.4392
training Epoch: 50, train_Loss: 2.2529
training Epoch: 50, train_Loss: 2.4668
training Epoch: 50, train_Loss: 0.8586
training Epoch: 50, train_Loss: 0.8166
training Epoch: 50, train_Loss: 1.8195
training Epoch: 50, train_Loss: 1.0724
training Epoch: 50, train_Loss: 0.5483
training Epoch: 50, train_Loss: 1.7027
training Epoch: 50, train_Loss: 0.7906
training Epoch: 50, train_Loss: 0.8359
training Epoch: 50, train_Loss: 0.9022
training Epoch: 50, train_Loss: 1.0068
training Epoch: 50, train_Loss: 0.7811
training Epoch: 50, train_Loss: 1.5961
training Epoch: 50, train_Loss: 1.2210
training Epoch: 50, train_Loss: 1.1512
training Epoch: 50, train_Loss: 1.3701
training Epoch: 50, train_Loss: 1.0887
training Epoch: 50, train_Loss: 0.8765
training Epoch: 50, train_Loss: 0.6286
training Epoch: 50, train_Loss: 1.3231
training Epoch: 50, train_Loss: 0.2768
training Epoch: 50, train_Loss: 0.7154
training Epoch: 50, train_Loss: 0.2591
training Epoch: 50, train_Loss: 2.5717
training Epoch: 50, train_Loss: 0.3743
training Epoch: 50, train_Loss: 1.6044
training Epoch: 50, train_Loss: 1.7831
training Epoch: 50, train_Loss: 0.9420
training Epoch: 50, train_Loss: 0.9030
training Epoch: 50, train_Loss: 0.8534
training Epoch: 50, train_Loss: 0.7056
training Epoch: 50, train_Loss: 0.4604
training Epoch: 50, train_Loss: 0.4887
training Epoch: 50, train_Loss: 0.3851
training Epoch: 50, train_Loss: 0.5722
training Epoch: 50, train_Loss: 1.4423
training Epoch: 50, train_Loss: 0.8021
training Epoch: 50, train_Loss: 0.6783
training Epoch: 50, train_Loss: 0.6861
training Epoch: 50, train_Loss: 1.4510
training Epoch: 50, train_Loss: 0.8469
training Epoch: 50, train_Loss: 0.5817
training Epoch: 50, train_Loss: 0.6751
training Epoch: 50, train_Loss: 0.9333
training Epoch: 50, train_Loss: 0.5400
training Epoch: 50, train_Loss: 0.5337
training Epoch: 50, train_Loss: 1.5487
training Epoch: 50, train_Loss: 0.5642
training Epoch: 50, train_Loss: 0.2658
training Epoch: 50, train_Loss: 0.3002
training Epoch: 50, train_Loss: 1.7357
training Epoch: 50, train_Loss: 2.4064
training Epoch: 50, train_Loss: 0.2119
training Epoch: 50, train_Loss: 2.5665
training Epoch: 50, train_Loss: 1.5793
training Epoch: 50, train_Loss: 0.6993
training Epoch: 50, train_Loss: 1.1189
training Epoch: 50, train_Loss: 1.1379
training Epoch: 50, train_Loss: 1.9499
training Epoch: 50, train_Loss: 0.6230
training Epoch: 50, train_Loss: 1.0511
training Epoch: 50, train_Loss: 0.7019
training Epoch: 50, train_Loss: 0.6445
training Epoch: 50, train_Loss: 0.6727
training Epoch: 50, train_Loss: 1.5507
training Epoch: 50, train_Loss: 0.3799
training Epoch: 50, train_Loss: 0.4549
training Epoch: 50, train_Loss: 0.5793
training Epoch: 50, train_Loss: 1.7647
training Epoch: 50, train_Loss: 1.1105
training Epoch: 50, train_Loss: 0.9675
training Epoch: 50, train_Loss: 1.4543
training Epoch: 50, train_Loss: 0.6241
training Epoch: 50, train_Loss: 1.4844
training Epoch: 50, train_Loss: 1.6212
training Epoch: 50, train_Loss: 0.5367
training Epoch: 50, train_Loss: 0.7780
training Epoch: 50, train_Loss: 0.9360
training Epoch: 50, train_Loss: 0.5196
training Epoch: 50, train_Loss: 0.5686
training Epoch: 50, train_Loss: 0.3208
training Epoch: 50, train_Loss: 1.6929
training Epoch: 50, train_Loss: 0.7182
training Epoch: 50, train_Loss: 0.8203
training Epoch: 50, train_Loss: 0.8114
training Epoch: 50, train_Loss: 1.2507
training Epoch: 50, train_Loss: 2.0920
training Epoch: 50, train_Loss: 0.5901
training Epoch: 50, train_Loss: 0.8798
training Epoch: 50, train_Loss: 0.7235
training Epoch: 50, train_Loss: 0.7680
training Epoch: 50, train_Loss: 0.3435
training Epoch: 50, train_Loss: 1.7450
training Epoch: 50, train_Loss: 1.0735
training Epoch: 50, train_Loss: 0.7906
training Epoch: 50, train_Loss: 1.1330
training Epoch: 50, train_Loss: 0.2946
training Epoch: 50, train_Loss: 2.0916
training Epoch: 50, train_Loss: 1.7101
training Epoch: 50, train_Loss: 0.4538
training Epoch: 50, train_Loss: 1.2992
training Epoch: 50, train_Loss: 0.3315
training Epoch: 50, train_Loss: 0.7271
training Epoch: 50, train_Loss: 2.3500
training Epoch: 50, train_Loss: 0.9361
training Epoch: 50, train_Loss: 1.5524
training Epoch: 50, train_Loss: 2.1928
training Epoch: 50, train_Loss: 0.8710
training Epoch: 50, train_Loss: 1.3537
training Epoch: 50, train_Loss: 1.4093
training Epoch: 50, train_Loss: 1.2343
training Epoch: 50, train_Loss: 1.2878
training Epoch: 50, train_Loss: 1.6679
training Epoch: 50, train_Loss: 0.7855
training Epoch: 50, train_Loss: 1.2756
training Epoch: 50, train_Loss: 0.6541
training Epoch: 50, train_Loss: 0.9000
training Epoch: 50, train_Loss: 1.9514
training Epoch: 50, train_Loss: 1.6730
training Epoch: 50, train_Loss: 0.8451
training Epoch: 50, train_Loss: 1.2990
training Epoch: 50, train_Loss: 0.7324
training Epoch: 50, train_Loss: 1.1673
training Epoch: 50, train_Loss: 0.5976
training Epoch: 50, train_Loss: 2.1002
training Epoch: 50, train_Loss: 1.2351
training Epoch: 50, train_Loss: 2.3231
training Epoch: 50, train_Loss: 0.4880
fold,epoch,train_loss: 2 49 1.0901694
fold,epoch,train_loss: 2 50 1.0926538
fold,epoch,train_loss: 2 51 1.0940651
fold,epoch,train_loss: 2 52 1.0891513
fold,epoch,train_loss: 2 53 1.090814
fold,epoch,train_loss: 2 54 1.0877284
fold,epoch,train_loss: 2 55 1.090438
fold,epoch,train_loss: 2 56 1.0843748
fold,epoch,train_loss: 2 57 1.0924503
fold,epoch,train_loss: 2 58 1.0904337
fold,epoch,train_loss: 2 59 1.0920007
fold,epoch,train_loss: 2 60 1.0890874
fold,epoch,train_loss: 2 61 1.087852
fold,epoch,train_loss: 2 62 1.0834347
fold,epoch,train_loss: 2 63 1.092128
fold,epoch,train_loss: 2 64 1.0906134
fold,epoch,train_loss: 2 65 1.0892465
fold,epoch,train_loss: 2 66 1.0930327
fold,epoch,train_loss: 2 67 1.0854663
fold,epoch,train_loss: 2 68 1.0912585
fold,epoch,train_loss: 2 69 1.083829
fold,epoch,train_loss: 2 70 1.0963268
fold,epoch,train_loss: 2 71 1.0877613
fold,epoch,train_loss: 2 72 1.088114
fold,epoch,train_loss: 2 73 1.0876704
fold,epoch,train_loss: 2 74 1.093146
fold,epoch,train_loss: 2 75 1.0924037
fold,epoch,train_loss: 2 76 1.0912305
fold,epoch,train_loss: 2 77 1.0924797
fold,epoch,train_loss: 2 78 1.0918664
fold,epoch,train_loss: 2 79 1.0881966
fold,epoch,train_loss: 2 80 1.0850912
fold,epoch,train_loss: 2 81 1.0906625
fold,epoch,train_loss: 2 82 1.0912282
fold,epoch,train_loss: 2 83 1.0878677
fold,epoch,train_loss: 2 84 1.0856397
fold,epoch,train_loss: 2 85 1.0894198
fold,epoch,train_loss: 2 86 1.0914475
fold,epoch,train_loss: 2 87 1.0881333
fold,epoch,train_loss: 2 88 1.0896299
fold,epoch,train_loss: 2 89 1.0871471
fold,epoch,train_loss: 2 90 1.088509
fold,epoch,train_loss: 2 91 1.0953462
fold,epoch,train_loss: 2 92 1.0906128
fold,epoch,train_loss: 2 93 1.0890199
fold,epoch,train_loss: 2 94 1.0934424
fold,epoch,train_loss: 2 95 1.0851289
fold,epoch,train_loss: 2 96 1.0961375
fold,epoch,train_loss: 2 97 1.0954475
fold,epoch,train_loss: 2 98 1.0919838
training Epoch: 100, train_Loss: 1.5788
training Epoch: 100, train_Loss: 1.4142
training Epoch: 100, train_Loss: 0.3714
training Epoch: 100, train_Loss: 0.6328
training Epoch: 100, train_Loss: 0.7989
training Epoch: 100, train_Loss: 1.9311
training Epoch: 100, train_Loss: 1.3878
training Epoch: 100, train_Loss: 1.2368
training Epoch: 100, train_Loss: 1.0167
training Epoch: 100, train_Loss: 0.7651
training Epoch: 100, train_Loss: 0.3447
training Epoch: 100, train_Loss: 0.5022
training Epoch: 100, train_Loss: 0.7356
training Epoch: 100, train_Loss: 0.8095
training Epoch: 100, train_Loss: 0.8633
training Epoch: 100, train_Loss: 0.8273
training Epoch: 100, train_Loss: 0.5086
training Epoch: 100, train_Loss: 0.6418
training Epoch: 100, train_Loss: 1.3139
training Epoch: 100, train_Loss: 0.9454
training Epoch: 100, train_Loss: 0.6579
training Epoch: 100, train_Loss: 1.1647
training Epoch: 100, train_Loss: 0.8348
training Epoch: 100, train_Loss: 1.8389
training Epoch: 100, train_Loss: 1.3434
training Epoch: 100, train_Loss: 0.8415
training Epoch: 100, train_Loss: 2.1693
training Epoch: 100, train_Loss: 2.9316
training Epoch: 100, train_Loss: 0.5795
training Epoch: 100, train_Loss: 1.6883
training Epoch: 100, train_Loss: 0.4446
training Epoch: 100, train_Loss: 2.7641
training Epoch: 100, train_Loss: 0.8387
training Epoch: 100, train_Loss: 1.2736
training Epoch: 100, train_Loss: 0.9679
training Epoch: 100, train_Loss: 1.9908
training Epoch: 100, train_Loss: 0.9389
training Epoch: 100, train_Loss: 0.8653
training Epoch: 100, train_Loss: 0.5986
training Epoch: 100, train_Loss: 0.4373
training Epoch: 100, train_Loss: 0.8416
training Epoch: 100, train_Loss: 0.3527
training Epoch: 100, train_Loss: 0.8210
training Epoch: 100, train_Loss: 0.6415
training Epoch: 100, train_Loss: 0.3856
training Epoch: 100, train_Loss: 1.4510
training Epoch: 100, train_Loss: 1.2333
training Epoch: 100, train_Loss: 1.1392
training Epoch: 100, train_Loss: 1.0950
training Epoch: 100, train_Loss: 0.2228
training Epoch: 100, train_Loss: 0.7137
training Epoch: 100, train_Loss: 1.7661
training Epoch: 100, train_Loss: 2.4845
training Epoch: 100, train_Loss: 1.0839
training Epoch: 100, train_Loss: 0.6925
training Epoch: 100, train_Loss: 0.3568
training Epoch: 100, train_Loss: 0.5841
training Epoch: 100, train_Loss: 1.0811
training Epoch: 100, train_Loss: 0.6013
training Epoch: 100, train_Loss: 0.7111
training Epoch: 100, train_Loss: 2.0046
training Epoch: 100, train_Loss: 1.0231
training Epoch: 100, train_Loss: 0.7260
training Epoch: 100, train_Loss: 1.9919
training Epoch: 100, train_Loss: 0.6889
training Epoch: 100, train_Loss: 0.9576
training Epoch: 100, train_Loss: 1.1240
training Epoch: 100, train_Loss: 1.1887
training Epoch: 100, train_Loss: 3.0146
training Epoch: 100, train_Loss: 1.7731
training Epoch: 100, train_Loss: 2.3561
training Epoch: 100, train_Loss: 0.8082
training Epoch: 100, train_Loss: 1.2683
training Epoch: 100, train_Loss: 0.5740
training Epoch: 100, train_Loss: 1.0111
training Epoch: 100, train_Loss: 1.0749
training Epoch: 100, train_Loss: 2.1281
training Epoch: 100, train_Loss: 0.5273
training Epoch: 100, train_Loss: 0.5960
training Epoch: 100, train_Loss: 1.2592
training Epoch: 100, train_Loss: 0.9085
training Epoch: 100, train_Loss: 0.6198
training Epoch: 100, train_Loss: 0.5569
training Epoch: 100, train_Loss: 1.8412
training Epoch: 100, train_Loss: 1.4856
training Epoch: 100, train_Loss: 1.4260
training Epoch: 100, train_Loss: 0.4302
training Epoch: 100, train_Loss: 2.4968
training Epoch: 100, train_Loss: 1.3202
training Epoch: 100, train_Loss: 0.4551
training Epoch: 100, train_Loss: 1.1996
training Epoch: 100, train_Loss: 0.5584
training Epoch: 100, train_Loss: 0.6537
training Epoch: 100, train_Loss: 0.5653
training Epoch: 100, train_Loss: 0.4507
training Epoch: 100, train_Loss: 0.7767
training Epoch: 100, train_Loss: 0.3296
training Epoch: 100, train_Loss: 1.2345
training Epoch: 100, train_Loss: 0.3929
training Epoch: 100, train_Loss: 1.2365
training Epoch: 100, train_Loss: 0.7230
training Epoch: 100, train_Loss: 0.4566
training Epoch: 100, train_Loss: 1.0783
training Epoch: 100, train_Loss: 1.2720
training Epoch: 100, train_Loss: 0.9866
training Epoch: 100, train_Loss: 2.2112
training Epoch: 100, train_Loss: 1.0405
training Epoch: 100, train_Loss: 0.2336
training Epoch: 100, train_Loss: 0.6170
training Epoch: 100, train_Loss: 0.6617
training Epoch: 100, train_Loss: 2.2454
training Epoch: 100, train_Loss: 0.2525
training Epoch: 100, train_Loss: 0.4104
training Epoch: 100, train_Loss: 3.0228
training Epoch: 100, train_Loss: 0.4252
training Epoch: 100, train_Loss: 0.8037
training Epoch: 100, train_Loss: 1.4062
training Epoch: 100, train_Loss: 2.4348
training Epoch: 100, train_Loss: 0.4846
training Epoch: 100, train_Loss: 0.4477
training Epoch: 100, train_Loss: 2.3129
training Epoch: 100, train_Loss: 0.8445
training Epoch: 100, train_Loss: 1.7983
training Epoch: 100, train_Loss: 0.7707
training Epoch: 100, train_Loss: 0.6136
training Epoch: 100, train_Loss: 1.4143
training Epoch: 100, train_Loss: 1.5145
training Epoch: 100, train_Loss: 0.6561
training Epoch: 100, train_Loss: 0.9050
training Epoch: 100, train_Loss: 0.5148
training Epoch: 100, train_Loss: 1.5147
training Epoch: 100, train_Loss: 2.0631
training Epoch: 100, train_Loss: 0.4870
training Epoch: 100, train_Loss: 0.5112
training Epoch: 100, train_Loss: 2.6056
training Epoch: 100, train_Loss: 1.0430
training Epoch: 100, train_Loss: 1.0614
training Epoch: 100, train_Loss: 0.6805
training Epoch: 100, train_Loss: 0.6803
training Epoch: 100, train_Loss: 1.6482
training Epoch: 100, train_Loss: 0.8657
training Epoch: 100, train_Loss: 1.2775
training Epoch: 100, train_Loss: 0.8477
training Epoch: 100, train_Loss: 1.9890
training Epoch: 100, train_Loss: 0.6508
training Epoch: 100, train_Loss: 0.4557
training Epoch: 100, train_Loss: 1.6259
training Epoch: 100, train_Loss: 0.5680
training Epoch: 100, train_Loss: 0.3530
training Epoch: 100, train_Loss: 0.5028
training Epoch: 100, train_Loss: 3.1973
training Epoch: 100, train_Loss: 0.5428
training Epoch: 100, train_Loss: 0.3486
training Epoch: 100, train_Loss: 0.5782
training Epoch: 100, train_Loss: 1.4562
training Epoch: 100, train_Loss: 0.4650
training Epoch: 100, train_Loss: 0.5392
training Epoch: 100, train_Loss: 2.0403
training Epoch: 100, train_Loss: 0.7542
training Epoch: 100, train_Loss: 0.8888
training Epoch: 100, train_Loss: 0.9655
training Epoch: 100, train_Loss: 0.3721
training Epoch: 100, train_Loss: 0.4670
training Epoch: 100, train_Loss: 1.9468
training Epoch: 100, train_Loss: 1.2456
training Epoch: 100, train_Loss: 0.7184
training Epoch: 100, train_Loss: 0.3072
training Epoch: 100, train_Loss: 0.2953
training Epoch: 100, train_Loss: 0.9204
training Epoch: 100, train_Loss: 0.3391
training Epoch: 100, train_Loss: 1.3242
training Epoch: 100, train_Loss: 2.5452
training Epoch: 100, train_Loss: 0.8841
training Epoch: 100, train_Loss: 0.7336
training Epoch: 100, train_Loss: 1.8816
training Epoch: 100, train_Loss: 0.5712
training Epoch: 100, train_Loss: 1.7360
training Epoch: 100, train_Loss: 1.4309
training Epoch: 100, train_Loss: 0.7215
training Epoch: 100, train_Loss: 0.6337
training Epoch: 100, train_Loss: 1.1130
training Epoch: 100, train_Loss: 0.9890
training Epoch: 100, train_Loss: 1.3892
training Epoch: 100, train_Loss: 0.9433
training Epoch: 100, train_Loss: 2.4532
training Epoch: 100, train_Loss: 0.7193
training Epoch: 100, train_Loss: 1.6756
training Epoch: 100, train_Loss: 0.4158
training Epoch: 100, train_Loss: 0.6478
training Epoch: 100, train_Loss: 1.6010
training Epoch: 100, train_Loss: 0.5755
training Epoch: 100, train_Loss: 1.8921
training Epoch: 100, train_Loss: 0.9815
training Epoch: 100, train_Loss: 0.7372
training Epoch: 100, train_Loss: 0.7821
training Epoch: 100, train_Loss: 1.1815
training Epoch: 100, train_Loss: 0.8393
training Epoch: 100, train_Loss: 1.2176
training Epoch: 100, train_Loss: 0.4062
training Epoch: 100, train_Loss: 1.0347
training Epoch: 100, train_Loss: 3.4197
training Epoch: 100, train_Loss: 0.6570
training Epoch: 100, train_Loss: 0.8634
training Epoch: 100, train_Loss: 0.3710
training Epoch: 100, train_Loss: 0.6721
training Epoch: 100, train_Loss: 0.8185
training Epoch: 100, train_Loss: 1.0857
training Epoch: 100, train_Loss: 2.1692
training Epoch: 100, train_Loss: 1.3288
training Epoch: 100, train_Loss: 0.5942
training Epoch: 100, train_Loss: 1.9917
training Epoch: 100, train_Loss: 0.9104
training Epoch: 100, train_Loss: 0.5088
training Epoch: 100, train_Loss: 1.0783
training Epoch: 100, train_Loss: 1.8679
training Epoch: 100, train_Loss: 0.5121
training Epoch: 100, train_Loss: 1.0880
training Epoch: 100, train_Loss: 0.7672
training Epoch: 100, train_Loss: 0.6357
training Epoch: 100, train_Loss: 0.5173
training Epoch: 100, train_Loss: 0.6772
training Epoch: 100, train_Loss: 1.2080
training Epoch: 100, train_Loss: 1.1727
training Epoch: 100, train_Loss: 1.0227
training Epoch: 100, train_Loss: 1.3385
training Epoch: 100, train_Loss: 1.1843
training Epoch: 100, train_Loss: 0.6092
training Epoch: 100, train_Loss: 0.3799
training Epoch: 100, train_Loss: 0.5910
training Epoch: 100, train_Loss: 1.1638
training Epoch: 100, train_Loss: 1.1640
training Epoch: 100, train_Loss: 0.3481
training Epoch: 100, train_Loss: 1.7016
training Epoch: 100, train_Loss: 0.4664
training Epoch: 100, train_Loss: 0.6494
training Epoch: 100, train_Loss: 0.5277
training Epoch: 100, train_Loss: 1.1452
training Epoch: 100, train_Loss: 0.8324
training Epoch: 100, train_Loss: 0.9251
training Epoch: 100, train_Loss: 1.5805
training Epoch: 100, train_Loss: 0.6507
training Epoch: 100, train_Loss: 0.6187
training Epoch: 100, train_Loss: 1.3112
training Epoch: 100, train_Loss: 0.4440
training Epoch: 100, train_Loss: 0.6430
training Epoch: 100, train_Loss: 1.0466
training Epoch: 100, train_Loss: 0.4182
training Epoch: 100, train_Loss: 0.3229
training Epoch: 100, train_Loss: 0.7055
training Epoch: 100, train_Loss: 0.6890
training Epoch: 100, train_Loss: 1.4916
training Epoch: 100, train_Loss: 1.0353
training Epoch: 100, train_Loss: 1.4490
training Epoch: 100, train_Loss: 1.9022
training Epoch: 100, train_Loss: 2.3323
training Epoch: 100, train_Loss: 0.6113
training Epoch: 100, train_Loss: 1.1775
training Epoch: 100, train_Loss: 1.3404
training Epoch: 100, train_Loss: 0.3558
training Epoch: 100, train_Loss: 0.8640
training Epoch: 100, train_Loss: 2.6419
training Epoch: 100, train_Loss: 2.4690
training Epoch: 100, train_Loss: 0.6936
training Epoch: 100, train_Loss: 0.9049
training Epoch: 100, train_Loss: 2.3675
training Epoch: 100, train_Loss: 0.6364
training Epoch: 100, train_Loss: 1.6484
training Epoch: 100, train_Loss: 0.9559
training Epoch: 100, train_Loss: 1.4930
training Epoch: 100, train_Loss: 1.3143
training Epoch: 100, train_Loss: 1.3787
training Epoch: 100, train_Loss: 0.9926
training Epoch: 100, train_Loss: 2.2424
training Epoch: 100, train_Loss: 0.8980
training Epoch: 100, train_Loss: 1.2151
training Epoch: 100, train_Loss: 1.6016
training Epoch: 100, train_Loss: 1.1493
training Epoch: 100, train_Loss: 1.4623
training Epoch: 100, train_Loss: 0.7488
training Epoch: 100, train_Loss: 1.1190
training Epoch: 100, train_Loss: 2.0711
training Epoch: 100, train_Loss: 1.6745
training Epoch: 100, train_Loss: 0.9579
training Epoch: 100, train_Loss: 0.9974
training Epoch: 100, train_Loss: 0.4294
training Epoch: 100, train_Loss: 0.7365
training Epoch: 100, train_Loss: 0.9971
training Epoch: 100, train_Loss: 1.0553
training Epoch: 100, train_Loss: 1.3106
training Epoch: 100, train_Loss: 0.7973
training Epoch: 100, train_Loss: 0.5805
training Epoch: 100, train_Loss: 0.3667
training Epoch: 100, train_Loss: 0.2706
training Epoch: 100, train_Loss: 1.2693
training Epoch: 100, train_Loss: 0.2597
training Epoch: 100, train_Loss: 1.5957
training Epoch: 100, train_Loss: 1.2741
training Epoch: 100, train_Loss: 1.2979
training Epoch: 100, train_Loss: 0.7990
training Epoch: 100, train_Loss: 0.7837
training Epoch: 100, train_Loss: 1.7325
training Epoch: 100, train_Loss: 0.7069
training Epoch: 100, train_Loss: 0.3369
training Epoch: 100, train_Loss: 0.6104
training Epoch: 100, train_Loss: 1.0207
training Epoch: 100, train_Loss: 0.3933
training Epoch: 100, train_Loss: 1.0469
training Epoch: 100, train_Loss: 0.3758
training Epoch: 100, train_Loss: 2.0115
training Epoch: 100, train_Loss: 2.0355
training Epoch: 100, train_Loss: 1.1820
training Epoch: 100, train_Loss: 1.3017
training Epoch: 100, train_Loss: 0.5734
training Epoch: 100, train_Loss: 1.4628
training Epoch: 100, train_Loss: 0.6468
training Epoch: 100, train_Loss: 0.9399
training Epoch: 100, train_Loss: 0.3678
training Epoch: 100, train_Loss: 2.4644
training Epoch: 100, train_Loss: 1.3935
training Epoch: 100, train_Loss: 1.1311
training Epoch: 100, train_Loss: 1.9831
training Epoch: 100, train_Loss: 0.7802
training Epoch: 100, train_Loss: 1.5077
training Epoch: 100, train_Loss: 0.6501
training Epoch: 100, train_Loss: 1.2601
training Epoch: 100, train_Loss: 1.0801
training Epoch: 100, train_Loss: 1.0375
training Epoch: 100, train_Loss: 1.1129
training Epoch: 100, train_Loss: 1.1755
training Epoch: 100, train_Loss: 1.9568
training Epoch: 100, train_Loss: 1.6160
training Epoch: 100, train_Loss: 0.8087
training Epoch: 100, train_Loss: 0.6554
training Epoch: 100, train_Loss: 1.3476
training Epoch: 100, train_Loss: 0.8665
training Epoch: 100, train_Loss: 1.2541
training Epoch: 100, train_Loss: 0.9531
training Epoch: 100, train_Loss: 1.1380
training Epoch: 100, train_Loss: 2.8337
training Epoch: 100, train_Loss: 0.9974
training Epoch: 100, train_Loss: 1.2162
training Epoch: 100, train_Loss: 0.9091
training Epoch: 100, train_Loss: 1.4864
training Epoch: 100, train_Loss: 2.7418
training Epoch: 100, train_Loss: 0.9715
training Epoch: 100, train_Loss: 0.9363
training Epoch: 100, train_Loss: 0.4284
training Epoch: 100, train_Loss: 0.6826
training Epoch: 100, train_Loss: 0.7977
training Epoch: 100, train_Loss: 0.5079
training Epoch: 100, train_Loss: 0.5328
training Epoch: 100, train_Loss: 0.3339
training Epoch: 100, train_Loss: 0.7430
training Epoch: 100, train_Loss: 0.5616
training Epoch: 100, train_Loss: 1.3654
training Epoch: 100, train_Loss: 0.7221
training Epoch: 100, train_Loss: 2.6667
training Epoch: 100, train_Loss: 0.6412
training Epoch: 100, train_Loss: 0.1518
training Epoch: 100, train_Loss: 1.2610
training Epoch: 100, train_Loss: 3.2973
training Epoch: 100, train_Loss: 0.1816
training Epoch: 100, train_Loss: 0.7631
training Epoch: 100, train_Loss: 0.7927
training Epoch: 100, train_Loss: 0.5073
training Epoch: 100, train_Loss: 0.3333
training Epoch: 100, train_Loss: 0.4559
training Epoch: 100, train_Loss: 0.2419
training Epoch: 100, train_Loss: 0.7073
training Epoch: 100, train_Loss: 1.7920
training Epoch: 100, train_Loss: 0.5112
training Epoch: 100, train_Loss: 2.1049
training Epoch: 100, train_Loss: 0.4674
training Epoch: 100, train_Loss: 0.8165
training Epoch: 100, train_Loss: 1.7034
training Epoch: 100, train_Loss: 0.5640
training Epoch: 100, train_Loss: 1.5467
training Epoch: 100, train_Loss: 1.8428
training Epoch: 100, train_Loss: 0.4021
training Epoch: 100, train_Loss: 1.3059
training Epoch: 100, train_Loss: 1.2285
training Epoch: 100, train_Loss: 2.2006
training Epoch: 100, train_Loss: 0.5036
training Epoch: 100, train_Loss: 0.5674
training Epoch: 100, train_Loss: 1.7016
training Epoch: 100, train_Loss: 0.8134
training Epoch: 100, train_Loss: 0.6368
training Epoch: 100, train_Loss: 0.5515
training Epoch: 100, train_Loss: 3.1879
training Epoch: 100, train_Loss: 1.0568
training Epoch: 100, train_Loss: 0.6511
training Epoch: 100, train_Loss: 1.7364
training Epoch: 100, train_Loss: 1.1602
training Epoch: 100, train_Loss: 0.7059
training Epoch: 100, train_Loss: 0.5540
training Epoch: 100, train_Loss: 0.5847
training Epoch: 100, train_Loss: 0.5773
training Epoch: 100, train_Loss: 0.8411
training Epoch: 100, train_Loss: 0.8809
training Epoch: 100, train_Loss: 2.7279
training Epoch: 100, train_Loss: 0.3732
training Epoch: 100, train_Loss: 0.6811
training Epoch: 100, train_Loss: 2.1712
training Epoch: 100, train_Loss: 0.7284
training Epoch: 100, train_Loss: 0.9324
training Epoch: 100, train_Loss: 0.4469
training Epoch: 100, train_Loss: 1.0597
training Epoch: 100, train_Loss: 0.8878
training Epoch: 100, train_Loss: 1.2959
training Epoch: 100, train_Loss: 1.4465
training Epoch: 100, train_Loss: 2.3510
training Epoch: 100, train_Loss: 1.4050
training Epoch: 100, train_Loss: 0.3842
training Epoch: 100, train_Loss: 0.9560
training Epoch: 100, train_Loss: 2.5506
training Epoch: 100, train_Loss: 0.9168
training Epoch: 100, train_Loss: 0.7786
training Epoch: 100, train_Loss: 1.4325
training Epoch: 100, train_Loss: 0.6545
training Epoch: 100, train_Loss: 1.1248
training Epoch: 100, train_Loss: 0.9502
training Epoch: 100, train_Loss: 1.0360
training Epoch: 100, train_Loss: 0.4895
training Epoch: 100, train_Loss: 1.4784
training Epoch: 100, train_Loss: 0.4863
training Epoch: 100, train_Loss: 1.5339
training Epoch: 100, train_Loss: 1.5254
training Epoch: 100, train_Loss: 1.6619
training Epoch: 100, train_Loss: 0.4659
training Epoch: 100, train_Loss: 0.6266
training Epoch: 100, train_Loss: 1.8053
training Epoch: 100, train_Loss: 1.5153
training Epoch: 100, train_Loss: 0.5840
training Epoch: 100, train_Loss: 0.5759
training Epoch: 100, train_Loss: 1.6123
training Epoch: 100, train_Loss: 2.2247
training Epoch: 100, train_Loss: 0.8813
training Epoch: 100, train_Loss: 0.7494
training Epoch: 100, train_Loss: 2.5041
training Epoch: 100, train_Loss: 1.1527
training Epoch: 100, train_Loss: 0.9023
training Epoch: 100, train_Loss: 0.6736
training Epoch: 100, train_Loss: 0.4303
training Epoch: 100, train_Loss: 0.9832
training Epoch: 100, train_Loss: 1.7414
training Epoch: 100, train_Loss: 0.6923
training Epoch: 100, train_Loss: 0.5974
training Epoch: 100, train_Loss: 0.5078
training Epoch: 100, train_Loss: 0.3328
training Epoch: 100, train_Loss: 2.9404
training Epoch: 100, train_Loss: 0.5296
training Epoch: 100, train_Loss: 1.5009
training Epoch: 100, train_Loss: 0.3945
training Epoch: 100, train_Loss: 2.4314
training Epoch: 100, train_Loss: 0.4244
training Epoch: 100, train_Loss: 1.8126
training Epoch: 100, train_Loss: 0.7764
training Epoch: 100, train_Loss: 0.7037
training Epoch: 100, train_Loss: 1.7023
training Epoch: 100, train_Loss: 0.4748
training Epoch: 100, train_Loss: 0.7248
training Epoch: 100, train_Loss: 1.7168
training Epoch: 100, train_Loss: 1.0303
training Epoch: 100, train_Loss: 0.4883
training Epoch: 100, train_Loss: 1.7271
training Epoch: 100, train_Loss: 1.0281
training Epoch: 100, train_Loss: 0.4414
training Epoch: 100, train_Loss: 1.1315
training Epoch: 100, train_Loss: 2.4195
training Epoch: 100, train_Loss: 0.7742
training Epoch: 100, train_Loss: 0.6688
training Epoch: 100, train_Loss: 1.0749
training Epoch: 100, train_Loss: 0.4771
training Epoch: 100, train_Loss: 0.5344
training Epoch: 100, train_Loss: 0.3352
training Epoch: 100, train_Loss: 1.9328
training Epoch: 100, train_Loss: 1.8601
training Epoch: 100, train_Loss: 0.5794
training Epoch: 100, train_Loss: 1.3231
training Epoch: 100, train_Loss: 1.9983
training Epoch: 100, train_Loss: 1.1184
training Epoch: 100, train_Loss: 1.6514
training Epoch: 100, train_Loss: 3.0491
training Epoch: 100, train_Loss: 0.5375
training Epoch: 100, train_Loss: 1.3361
training Epoch: 100, train_Loss: 0.8227
training Epoch: 100, train_Loss: 0.5201
training Epoch: 100, train_Loss: 1.3755
training Epoch: 100, train_Loss: 0.6362
training Epoch: 100, train_Loss: 0.8348
training Epoch: 100, train_Loss: 1.6039
training Epoch: 100, train_Loss: 2.0693
training Epoch: 100, train_Loss: 1.9944
training Epoch: 100, train_Loss: 0.6630
training Epoch: 100, train_Loss: 0.3108
training Epoch: 100, train_Loss: 1.2643
training Epoch: 100, train_Loss: 2.5858
training Epoch: 100, train_Loss: 3.2463
training Epoch: 100, train_Loss: 0.6346
training Epoch: 100, train_Loss: 0.4865
training Epoch: 100, train_Loss: 0.5283
training Epoch: 100, train_Loss: 0.6168
training Epoch: 100, train_Loss: 1.5547
training Epoch: 100, train_Loss: 0.7257
training Epoch: 100, train_Loss: 1.9099
training Epoch: 100, train_Loss: 0.4498
training Epoch: 100, train_Loss: 1.2944
training Epoch: 100, train_Loss: 1.4351
training Epoch: 100, train_Loss: 0.4122
training Epoch: 100, train_Loss: 0.8655
training Epoch: 100, train_Loss: 1.5559
training Epoch: 100, train_Loss: 0.6852
training Epoch: 100, train_Loss: 0.5213
training Epoch: 100, train_Loss: 0.7277
training Epoch: 100, train_Loss: 1.2804
training Epoch: 100, train_Loss: 1.4168
training Epoch: 100, train_Loss: 1.3896
training Epoch: 100, train_Loss: 1.0708
training Epoch: 100, train_Loss: 2.4030
training Epoch: 100, train_Loss: 0.9905
training Epoch: 100, train_Loss: 1.1703
training Epoch: 100, train_Loss: 0.7242
training Epoch: 100, train_Loss: 0.3215
training Epoch: 100, train_Loss: 0.4159
training Epoch: 100, train_Loss: 0.6041
training Epoch: 100, train_Loss: 2.7689
training Epoch: 100, train_Loss: 2.0523
training Epoch: 100, train_Loss: 0.7763
training Epoch: 100, train_Loss: 1.2814
training Epoch: 100, train_Loss: 1.0102
training Epoch: 100, train_Loss: 1.5053
training Epoch: 100, train_Loss: 1.0117
training Epoch: 100, train_Loss: 0.8524
training Epoch: 100, train_Loss: 2.2101
training Epoch: 100, train_Loss: 0.7131
training Epoch: 100, train_Loss: 0.4963
training Epoch: 100, train_Loss: 1.8890
training Epoch: 100, train_Loss: 0.5055
training Epoch: 100, train_Loss: 0.7449
training Epoch: 100, train_Loss: 0.7647
training Epoch: 100, train_Loss: 0.3599
training Epoch: 100, train_Loss: 0.3183
training Epoch: 100, train_Loss: 1.3613
training Epoch: 100, train_Loss: 1.4865
training Epoch: 100, train_Loss: 2.2495
training Epoch: 100, train_Loss: 1.6752
training Epoch: 100, train_Loss: 0.5924
training Epoch: 100, train_Loss: 0.6584
training Epoch: 100, train_Loss: 1.0194
training Epoch: 100, train_Loss: 1.4337
training Epoch: 100, train_Loss: 1.9844
training Epoch: 100, train_Loss: 0.6106
training Epoch: 100, train_Loss: 0.3969
training Epoch: 100, train_Loss: 0.9706
training Epoch: 100, train_Loss: 0.2910
training Epoch: 100, train_Loss: 1.0216
training Epoch: 100, train_Loss: 0.6476
training Epoch: 100, train_Loss: 0.2901
training Epoch: 100, train_Loss: 2.0759
training Epoch: 100, train_Loss: 0.5359
training Epoch: 100, train_Loss: 0.7525
training Epoch: 100, train_Loss: 1.2635
training Epoch: 100, train_Loss: 0.4528
training Epoch: 100, train_Loss: 1.9972
training Epoch: 100, train_Loss: 0.9062
training Epoch: 100, train_Loss: 0.2945
training Epoch: 100, train_Loss: 0.6349
training Epoch: 100, train_Loss: 1.0568
training Epoch: 100, train_Loss: 0.9347
training Epoch: 100, train_Loss: 2.0929
training Epoch: 100, train_Loss: 0.4501
training Epoch: 100, train_Loss: 0.8235
training Epoch: 100, train_Loss: 1.6913
training Epoch: 100, train_Loss: 0.3359
training Epoch: 100, train_Loss: 0.2869
fold,epoch,train_loss: 2 99 1.0854679
fold,epoch,train_loss: 2 100 1.089386
====Evaluation
fold:2, epoch:100,train:1.089386, valid:1.080498 

fold: 3
fold,epoch,train_loss: 3 0 1.0901107
fold,epoch,train_loss: 3 1 1.0904883
fold,epoch,train_loss: 3 2 1.0894396
fold,epoch,train_loss: 3 3 1.0880802
fold,epoch,train_loss: 3 4 1.0921006
fold,epoch,train_loss: 3 5 1.0860465
fold,epoch,train_loss: 3 6 1.0866392
fold,epoch,train_loss: 3 7 1.0885407
fold,epoch,train_loss: 3 8 1.0881698
fold,epoch,train_loss: 3 9 1.089483
fold,epoch,train_loss: 3 10 1.0914966
fold,epoch,train_loss: 3 11 1.0886657
fold,epoch,train_loss: 3 12 1.0909736
fold,epoch,train_loss: 3 13 1.0881484
fold,epoch,train_loss: 3 14 1.0941875
fold,epoch,train_loss: 3 15 1.0865289
fold,epoch,train_loss: 3 16 1.0923471
fold,epoch,train_loss: 3 17 1.0904852
fold,epoch,train_loss: 3 18 1.0893185
fold,epoch,train_loss: 3 19 1.0986587
fold,epoch,train_loss: 3 20 1.0915334
fold,epoch,train_loss: 3 21 1.0879099
fold,epoch,train_loss: 3 22 1.0885999
fold,epoch,train_loss: 3 23 1.0938874
fold,epoch,train_loss: 3 24 1.0873097
fold,epoch,train_loss: 3 25 1.0902947
fold,epoch,train_loss: 3 26 1.0836725
fold,epoch,train_loss: 3 27 1.0986954
fold,epoch,train_loss: 3 28 1.091482
fold,epoch,train_loss: 3 29 1.0854441
fold,epoch,train_loss: 3 30 1.0939062
fold,epoch,train_loss: 3 31 1.0869592
fold,epoch,train_loss: 3 32 1.0837733
fold,epoch,train_loss: 3 33 1.0862335
fold,epoch,train_loss: 3 34 1.086222
fold,epoch,train_loss: 3 35 1.0881344
fold,epoch,train_loss: 3 36 1.0897735
fold,epoch,train_loss: 3 37 1.0875616
fold,epoch,train_loss: 3 38 1.0915906
fold,epoch,train_loss: 3 39 1.0960525
fold,epoch,train_loss: 3 40 1.0916119
fold,epoch,train_loss: 3 41 1.0927974
fold,epoch,train_loss: 3 42 1.087273
fold,epoch,train_loss: 3 43 1.0857439
fold,epoch,train_loss: 3 44 1.084436
fold,epoch,train_loss: 3 45 1.0939277
fold,epoch,train_loss: 3 46 1.0919816
fold,epoch,train_loss: 3 47 1.0828139
fold,epoch,train_loss: 3 48 1.0883285
training Epoch: 50, train_Loss: 1.9520
training Epoch: 50, train_Loss: 0.5546
training Epoch: 50, train_Loss: 0.7018
training Epoch: 50, train_Loss: 0.8217
training Epoch: 50, train_Loss: 1.0968
training Epoch: 50, train_Loss: 1.0149
training Epoch: 50, train_Loss: 2.4830
training Epoch: 50, train_Loss: 0.7435
training Epoch: 50, train_Loss: 2.7557
training Epoch: 50, train_Loss: 0.7272
training Epoch: 50, train_Loss: 1.0186
training Epoch: 50, train_Loss: 1.8101
training Epoch: 50, train_Loss: 0.9126
training Epoch: 50, train_Loss: 1.3933
training Epoch: 50, train_Loss: 0.6219
training Epoch: 50, train_Loss: 1.6779
training Epoch: 50, train_Loss: 0.8991
training Epoch: 50, train_Loss: 2.6749
training Epoch: 50, train_Loss: 0.4873
training Epoch: 50, train_Loss: 0.5342
training Epoch: 50, train_Loss: 0.5982
training Epoch: 50, train_Loss: 0.7451
training Epoch: 50, train_Loss: 2.0075
training Epoch: 50, train_Loss: 0.3163
training Epoch: 50, train_Loss: 2.3895
training Epoch: 50, train_Loss: 0.3733
training Epoch: 50, train_Loss: 2.7074
training Epoch: 50, train_Loss: 1.8509
training Epoch: 50, train_Loss: 1.4106
training Epoch: 50, train_Loss: 1.8941
training Epoch: 50, train_Loss: 0.6909
training Epoch: 50, train_Loss: 0.8151
training Epoch: 50, train_Loss: 0.8658
training Epoch: 50, train_Loss: 0.8483
training Epoch: 50, train_Loss: 0.9130
training Epoch: 50, train_Loss: 0.9752
training Epoch: 50, train_Loss: 0.4241
training Epoch: 50, train_Loss: 0.8247
training Epoch: 50, train_Loss: 1.9934
training Epoch: 50, train_Loss: 0.8289
training Epoch: 50, train_Loss: 0.5427
training Epoch: 50, train_Loss: 1.5325
training Epoch: 50, train_Loss: 0.8532
training Epoch: 50, train_Loss: 2.0173
training Epoch: 50, train_Loss: 0.5261
training Epoch: 50, train_Loss: 0.3179
training Epoch: 50, train_Loss: 0.4733
training Epoch: 50, train_Loss: 2.2491
training Epoch: 50, train_Loss: 1.0581
training Epoch: 50, train_Loss: 0.7632
training Epoch: 50, train_Loss: 1.1715
training Epoch: 50, train_Loss: 0.4358
training Epoch: 50, train_Loss: 0.3381
training Epoch: 50, train_Loss: 1.0112
training Epoch: 50, train_Loss: 0.3395
training Epoch: 50, train_Loss: 0.6383
training Epoch: 50, train_Loss: 1.1031
training Epoch: 50, train_Loss: 2.6274
training Epoch: 50, train_Loss: 1.3491
training Epoch: 50, train_Loss: 0.9998
training Epoch: 50, train_Loss: 0.5702
training Epoch: 50, train_Loss: 1.2914
training Epoch: 50, train_Loss: 0.6378
training Epoch: 50, train_Loss: 2.0085
training Epoch: 50, train_Loss: 0.3632
training Epoch: 50, train_Loss: 1.1376
training Epoch: 50, train_Loss: 0.4247
training Epoch: 50, train_Loss: 1.4979
training Epoch: 50, train_Loss: 0.5523
training Epoch: 50, train_Loss: 0.3705
training Epoch: 50, train_Loss: 0.7354
training Epoch: 50, train_Loss: 1.2478
training Epoch: 50, train_Loss: 0.9987
training Epoch: 50, train_Loss: 1.6410
training Epoch: 50, train_Loss: 0.5269
training Epoch: 50, train_Loss: 0.6762
training Epoch: 50, train_Loss: 1.1320
training Epoch: 50, train_Loss: 1.0492
training Epoch: 50, train_Loss: 1.7133
training Epoch: 50, train_Loss: 0.8502
training Epoch: 50, train_Loss: 0.4886
training Epoch: 50, train_Loss: 0.8501
training Epoch: 50, train_Loss: 0.7792
training Epoch: 50, train_Loss: 1.1709
training Epoch: 50, train_Loss: 0.6339
training Epoch: 50, train_Loss: 1.0876
training Epoch: 50, train_Loss: 1.1470
training Epoch: 50, train_Loss: 1.3771
training Epoch: 50, train_Loss: 0.4877
training Epoch: 50, train_Loss: 1.3844
training Epoch: 50, train_Loss: 1.4612
training Epoch: 50, train_Loss: 0.5219
training Epoch: 50, train_Loss: 1.8797
training Epoch: 50, train_Loss: 0.7577
training Epoch: 50, train_Loss: 0.4780
training Epoch: 50, train_Loss: 0.6338
training Epoch: 50, train_Loss: 0.7543
training Epoch: 50, train_Loss: 1.5179
training Epoch: 50, train_Loss: 0.9592
training Epoch: 50, train_Loss: 0.8450
training Epoch: 50, train_Loss: 0.6729
training Epoch: 50, train_Loss: 1.3136
training Epoch: 50, train_Loss: 1.4793
training Epoch: 50, train_Loss: 1.1505
training Epoch: 50, train_Loss: 0.4773
training Epoch: 50, train_Loss: 0.3689
training Epoch: 50, train_Loss: 1.9936
training Epoch: 50, train_Loss: 0.6329
training Epoch: 50, train_Loss: 2.3673
training Epoch: 50, train_Loss: 0.8482
training Epoch: 50, train_Loss: 1.2581
training Epoch: 50, train_Loss: 0.8444
training Epoch: 50, train_Loss: 0.4465
training Epoch: 50, train_Loss: 0.5433
training Epoch: 50, train_Loss: 1.7627
training Epoch: 50, train_Loss: 0.8032
training Epoch: 50, train_Loss: 1.3681
training Epoch: 50, train_Loss: 1.1830
training Epoch: 50, train_Loss: 1.9125
training Epoch: 50, train_Loss: 0.5239
training Epoch: 50, train_Loss: 0.5897
training Epoch: 50, train_Loss: 2.9417
training Epoch: 50, train_Loss: 0.4941
training Epoch: 50, train_Loss: 0.3938
training Epoch: 50, train_Loss: 0.7211
training Epoch: 50, train_Loss: 0.8107
training Epoch: 50, train_Loss: 1.4550
training Epoch: 50, train_Loss: 0.9273
training Epoch: 50, train_Loss: 2.5554
training Epoch: 50, train_Loss: 0.4697
training Epoch: 50, train_Loss: 0.3128
training Epoch: 50, train_Loss: 0.8906
training Epoch: 50, train_Loss: 1.2555
training Epoch: 50, train_Loss: 0.5671
training Epoch: 50, train_Loss: 0.5613
training Epoch: 50, train_Loss: 0.6955
training Epoch: 50, train_Loss: 0.4479
training Epoch: 50, train_Loss: 0.4989
training Epoch: 50, train_Loss: 1.1338
training Epoch: 50, train_Loss: 1.3515
training Epoch: 50, train_Loss: 0.3109
training Epoch: 50, train_Loss: 2.7103
training Epoch: 50, train_Loss: 0.7913
training Epoch: 50, train_Loss: 0.7446
training Epoch: 50, train_Loss: 1.9725
training Epoch: 50, train_Loss: 1.3704
training Epoch: 50, train_Loss: 0.4233
training Epoch: 50, train_Loss: 0.9413
training Epoch: 50, train_Loss: 1.8080
training Epoch: 50, train_Loss: 0.8651
training Epoch: 50, train_Loss: 0.9136
training Epoch: 50, train_Loss: 0.6928
training Epoch: 50, train_Loss: 0.5830
training Epoch: 50, train_Loss: 1.1603
training Epoch: 50, train_Loss: 0.6146
training Epoch: 50, train_Loss: 0.6099
training Epoch: 50, train_Loss: 0.9057
training Epoch: 50, train_Loss: 3.0256
training Epoch: 50, train_Loss: 0.8067
training Epoch: 50, train_Loss: 0.3400
training Epoch: 50, train_Loss: 1.2229
training Epoch: 50, train_Loss: 1.1165
training Epoch: 50, train_Loss: 0.6718
training Epoch: 50, train_Loss: 0.5612
training Epoch: 50, train_Loss: 0.9249
training Epoch: 50, train_Loss: 0.5453
training Epoch: 50, train_Loss: 1.8356
training Epoch: 50, train_Loss: 1.5641
training Epoch: 50, train_Loss: 1.6670
training Epoch: 50, train_Loss: 1.7959
training Epoch: 50, train_Loss: 0.8099
training Epoch: 50, train_Loss: 0.9408
training Epoch: 50, train_Loss: 1.6556
training Epoch: 50, train_Loss: 0.9669
training Epoch: 50, train_Loss: 0.7657
training Epoch: 50, train_Loss: 1.0765
training Epoch: 50, train_Loss: 2.3305
training Epoch: 50, train_Loss: 0.6964
training Epoch: 50, train_Loss: 1.5514
training Epoch: 50, train_Loss: 0.8551
training Epoch: 50, train_Loss: 0.4529
training Epoch: 50, train_Loss: 0.4591
training Epoch: 50, train_Loss: 0.9692
training Epoch: 50, train_Loss: 0.8937
training Epoch: 50, train_Loss: 0.3663
training Epoch: 50, train_Loss: 0.7878
training Epoch: 50, train_Loss: 0.7162
training Epoch: 50, train_Loss: 0.7745
training Epoch: 50, train_Loss: 0.3815
training Epoch: 50, train_Loss: 0.5068
training Epoch: 50, train_Loss: 0.4857
training Epoch: 50, train_Loss: 0.6565
training Epoch: 50, train_Loss: 0.9026
training Epoch: 50, train_Loss: 0.4392
training Epoch: 50, train_Loss: 0.4775
training Epoch: 50, train_Loss: 3.0636
training Epoch: 50, train_Loss: 2.1138
training Epoch: 50, train_Loss: 0.2525
training Epoch: 50, train_Loss: 0.6160
training Epoch: 50, train_Loss: 0.7902
training Epoch: 50, train_Loss: 0.6562
training Epoch: 50, train_Loss: 1.3159
training Epoch: 50, train_Loss: 0.4990
training Epoch: 50, train_Loss: 1.1684
training Epoch: 50, train_Loss: 0.3617
training Epoch: 50, train_Loss: 1.5269
training Epoch: 50, train_Loss: 1.1476
training Epoch: 50, train_Loss: 2.7570
training Epoch: 50, train_Loss: 1.0872
training Epoch: 50, train_Loss: 0.9872
training Epoch: 50, train_Loss: 0.5306
training Epoch: 50, train_Loss: 1.3394
training Epoch: 50, train_Loss: 0.7802
training Epoch: 50, train_Loss: 1.2211
training Epoch: 50, train_Loss: 1.0540
training Epoch: 50, train_Loss: 0.6349
training Epoch: 50, train_Loss: 2.3185
training Epoch: 50, train_Loss: 0.6102
training Epoch: 50, train_Loss: 1.4891
training Epoch: 50, train_Loss: 0.6807
training Epoch: 50, train_Loss: 0.6390
training Epoch: 50, train_Loss: 2.0744
training Epoch: 50, train_Loss: 0.5390
training Epoch: 50, train_Loss: 1.2506
training Epoch: 50, train_Loss: 0.7744
training Epoch: 50, train_Loss: 0.6878
training Epoch: 50, train_Loss: 1.7883
training Epoch: 50, train_Loss: 0.4579
training Epoch: 50, train_Loss: 0.4918
training Epoch: 50, train_Loss: 0.8093
training Epoch: 50, train_Loss: 1.3120
training Epoch: 50, train_Loss: 2.7886
training Epoch: 50, train_Loss: 0.6049
training Epoch: 50, train_Loss: 1.6398
training Epoch: 50, train_Loss: 0.9700
training Epoch: 50, train_Loss: 1.4711
training Epoch: 50, train_Loss: 3.7156
training Epoch: 50, train_Loss: 0.3941
training Epoch: 50, train_Loss: 0.5182
training Epoch: 50, train_Loss: 1.4784
training Epoch: 50, train_Loss: 0.4359
training Epoch: 50, train_Loss: 1.2183
training Epoch: 50, train_Loss: 1.0205
training Epoch: 50, train_Loss: 0.7784
training Epoch: 50, train_Loss: 0.7944
training Epoch: 50, train_Loss: 0.5388
training Epoch: 50, train_Loss: 1.9430
training Epoch: 50, train_Loss: 0.7292
training Epoch: 50, train_Loss: 0.3576
training Epoch: 50, train_Loss: 0.9192
training Epoch: 50, train_Loss: 1.0020
training Epoch: 50, train_Loss: 0.9958
training Epoch: 50, train_Loss: 0.3696
training Epoch: 50, train_Loss: 0.9032
training Epoch: 50, train_Loss: 0.9103
training Epoch: 50, train_Loss: 1.0432
training Epoch: 50, train_Loss: 0.3752
training Epoch: 50, train_Loss: 0.7931
training Epoch: 50, train_Loss: 1.0441
training Epoch: 50, train_Loss: 0.6740
training Epoch: 50, train_Loss: 1.9219
training Epoch: 50, train_Loss: 1.0480
training Epoch: 50, train_Loss: 1.4702
training Epoch: 50, train_Loss: 1.6449
training Epoch: 50, train_Loss: 1.2933
training Epoch: 50, train_Loss: 0.3774
training Epoch: 50, train_Loss: 1.0202
training Epoch: 50, train_Loss: 1.5589
training Epoch: 50, train_Loss: 0.3648
training Epoch: 50, train_Loss: 1.6174
training Epoch: 50, train_Loss: 0.3752
training Epoch: 50, train_Loss: 1.2427
training Epoch: 50, train_Loss: 1.0055
training Epoch: 50, train_Loss: 1.5864
training Epoch: 50, train_Loss: 0.3254
training Epoch: 50, train_Loss: 1.4673
training Epoch: 50, train_Loss: 0.6306
training Epoch: 50, train_Loss: 0.9682
training Epoch: 50, train_Loss: 0.6096
training Epoch: 50, train_Loss: 1.6343
training Epoch: 50, train_Loss: 0.4484
training Epoch: 50, train_Loss: 0.3967
training Epoch: 50, train_Loss: 0.6305
training Epoch: 50, train_Loss: 0.8624
training Epoch: 50, train_Loss: 0.3673
training Epoch: 50, train_Loss: 2.2712
training Epoch: 50, train_Loss: 0.9909
training Epoch: 50, train_Loss: 0.2577
training Epoch: 50, train_Loss: 1.8428
training Epoch: 50, train_Loss: 1.4789
training Epoch: 50, train_Loss: 0.4976
training Epoch: 50, train_Loss: 0.5387
training Epoch: 50, train_Loss: 0.8103
training Epoch: 50, train_Loss: 1.1402
training Epoch: 50, train_Loss: 1.1091
training Epoch: 50, train_Loss: 0.3278
training Epoch: 50, train_Loss: 0.8013
training Epoch: 50, train_Loss: 1.3586
training Epoch: 50, train_Loss: 1.2663
training Epoch: 50, train_Loss: 1.2082
training Epoch: 50, train_Loss: 2.1567
training Epoch: 50, train_Loss: 0.5207
training Epoch: 50, train_Loss: 0.2809
training Epoch: 50, train_Loss: 1.4169
training Epoch: 50, train_Loss: 0.2667
training Epoch: 50, train_Loss: 0.4636
training Epoch: 50, train_Loss: 0.9487
training Epoch: 50, train_Loss: 0.8106
training Epoch: 50, train_Loss: 0.9521
training Epoch: 50, train_Loss: 1.9160
training Epoch: 50, train_Loss: 0.6846
training Epoch: 50, train_Loss: 0.9044
training Epoch: 50, train_Loss: 0.9855
training Epoch: 50, train_Loss: 0.8211
training Epoch: 50, train_Loss: 1.0399
training Epoch: 50, train_Loss: 3.1500
training Epoch: 50, train_Loss: 0.8795
training Epoch: 50, train_Loss: 0.5404
training Epoch: 50, train_Loss: 0.5407
training Epoch: 50, train_Loss: 0.5441
training Epoch: 50, train_Loss: 0.4672
training Epoch: 50, train_Loss: 1.7508
training Epoch: 50, train_Loss: 0.3962
training Epoch: 50, train_Loss: 1.4300
training Epoch: 50, train_Loss: 1.9729
training Epoch: 50, train_Loss: 0.6062
training Epoch: 50, train_Loss: 1.2998
training Epoch: 50, train_Loss: 0.4216
training Epoch: 50, train_Loss: 1.9417
training Epoch: 50, train_Loss: 1.3894
training Epoch: 50, train_Loss: 0.7216
training Epoch: 50, train_Loss: 1.3231
training Epoch: 50, train_Loss: 2.1185
training Epoch: 50, train_Loss: 0.6839
training Epoch: 50, train_Loss: 0.8129
training Epoch: 50, train_Loss: 1.9293
training Epoch: 50, train_Loss: 0.4573
training Epoch: 50, train_Loss: 0.4911
training Epoch: 50, train_Loss: 1.4416
training Epoch: 50, train_Loss: 1.3096
training Epoch: 50, train_Loss: 0.8085
training Epoch: 50, train_Loss: 2.5990
training Epoch: 50, train_Loss: 1.1950
training Epoch: 50, train_Loss: 0.7258
training Epoch: 50, train_Loss: 1.0814
training Epoch: 50, train_Loss: 1.8808
training Epoch: 50, train_Loss: 0.5106
training Epoch: 50, train_Loss: 0.4602
training Epoch: 50, train_Loss: 1.1637
training Epoch: 50, train_Loss: 0.3178
training Epoch: 50, train_Loss: 3.1133
training Epoch: 50, train_Loss: 0.4664
training Epoch: 50, train_Loss: 1.0530
training Epoch: 50, train_Loss: 1.4799
training Epoch: 50, train_Loss: 1.4592
training Epoch: 50, train_Loss: 1.2394
training Epoch: 50, train_Loss: 0.7607
training Epoch: 50, train_Loss: 0.8943
training Epoch: 50, train_Loss: 1.8227
training Epoch: 50, train_Loss: 0.9145
training Epoch: 50, train_Loss: 0.6554
training Epoch: 50, train_Loss: 0.8096
training Epoch: 50, train_Loss: 0.9010
training Epoch: 50, train_Loss: 2.8170
training Epoch: 50, train_Loss: 0.3958
training Epoch: 50, train_Loss: 0.5554
training Epoch: 50, train_Loss: 0.5087
training Epoch: 50, train_Loss: 2.2162
training Epoch: 50, train_Loss: 1.0586
training Epoch: 50, train_Loss: 1.1809
training Epoch: 50, train_Loss: 0.3070
training Epoch: 50, train_Loss: 0.9602
training Epoch: 50, train_Loss: 0.8914
training Epoch: 50, train_Loss: 3.5951
training Epoch: 50, train_Loss: 0.8174
training Epoch: 50, train_Loss: 0.4790
training Epoch: 50, train_Loss: 0.4793
training Epoch: 50, train_Loss: 0.6348
training Epoch: 50, train_Loss: 1.6212
training Epoch: 50, train_Loss: 0.8083
training Epoch: 50, train_Loss: 0.8073
training Epoch: 50, train_Loss: 0.2937
training Epoch: 50, train_Loss: 0.7034
training Epoch: 50, train_Loss: 0.8636
training Epoch: 50, train_Loss: 0.6473
training Epoch: 50, train_Loss: 0.4653
training Epoch: 50, train_Loss: 1.0595
training Epoch: 50, train_Loss: 0.9266
training Epoch: 50, train_Loss: 0.8191
training Epoch: 50, train_Loss: 1.6368
training Epoch: 50, train_Loss: 0.2445
training Epoch: 50, train_Loss: 0.4608
training Epoch: 50, train_Loss: 0.2202
training Epoch: 50, train_Loss: 1.3109
training Epoch: 50, train_Loss: 0.6320
training Epoch: 50, train_Loss: 1.2734
training Epoch: 50, train_Loss: 1.2403
training Epoch: 50, train_Loss: 0.3792
training Epoch: 50, train_Loss: 0.5531
training Epoch: 50, train_Loss: 2.5935
training Epoch: 50, train_Loss: 1.0005
training Epoch: 50, train_Loss: 0.6389
training Epoch: 50, train_Loss: 2.3982
training Epoch: 50, train_Loss: 0.6565
training Epoch: 50, train_Loss: 1.5712
training Epoch: 50, train_Loss: 0.3492
training Epoch: 50, train_Loss: 3.7401
training Epoch: 50, train_Loss: 1.5149
training Epoch: 50, train_Loss: 0.8882
training Epoch: 50, train_Loss: 2.5495
training Epoch: 50, train_Loss: 1.5977
training Epoch: 50, train_Loss: 0.7637
training Epoch: 50, train_Loss: 0.7283
training Epoch: 50, train_Loss: 1.0458
training Epoch: 50, train_Loss: 0.9195
training Epoch: 50, train_Loss: 0.8265
training Epoch: 50, train_Loss: 1.5456
training Epoch: 50, train_Loss: 0.7978
training Epoch: 50, train_Loss: 0.5053
training Epoch: 50, train_Loss: 1.3475
training Epoch: 50, train_Loss: 2.3533
training Epoch: 50, train_Loss: 0.5800
training Epoch: 50, train_Loss: 0.6167
training Epoch: 50, train_Loss: 0.6050
training Epoch: 50, train_Loss: 1.6359
training Epoch: 50, train_Loss: 0.4152
training Epoch: 50, train_Loss: 1.7506
training Epoch: 50, train_Loss: 1.2898
training Epoch: 50, train_Loss: 0.9462
training Epoch: 50, train_Loss: 2.6557
training Epoch: 50, train_Loss: 1.1656
training Epoch: 50, train_Loss: 1.5088
training Epoch: 50, train_Loss: 0.2789
training Epoch: 50, train_Loss: 2.3590
training Epoch: 50, train_Loss: 1.2588
training Epoch: 50, train_Loss: 0.7065
training Epoch: 50, train_Loss: 0.8543
training Epoch: 50, train_Loss: 1.0799
training Epoch: 50, train_Loss: 1.1868
training Epoch: 50, train_Loss: 2.0687
training Epoch: 50, train_Loss: 1.1590
training Epoch: 50, train_Loss: 1.1363
training Epoch: 50, train_Loss: 1.2685
training Epoch: 50, train_Loss: 0.6885
training Epoch: 50, train_Loss: 0.5791
training Epoch: 50, train_Loss: 1.9453
training Epoch: 50, train_Loss: 0.3893
training Epoch: 50, train_Loss: 1.0243
training Epoch: 50, train_Loss: 0.8340
training Epoch: 50, train_Loss: 0.9470
training Epoch: 50, train_Loss: 1.0696
training Epoch: 50, train_Loss: 2.0328
training Epoch: 50, train_Loss: 0.4172
training Epoch: 50, train_Loss: 0.4082
training Epoch: 50, train_Loss: 0.2872
training Epoch: 50, train_Loss: 0.2416
training Epoch: 50, train_Loss: 1.0067
training Epoch: 50, train_Loss: 1.5480
training Epoch: 50, train_Loss: 0.2120
training Epoch: 50, train_Loss: 1.1078
training Epoch: 50, train_Loss: 0.7349
training Epoch: 50, train_Loss: 0.3712
training Epoch: 50, train_Loss: 2.7733
training Epoch: 50, train_Loss: 0.8315
training Epoch: 50, train_Loss: 0.5644
training Epoch: 50, train_Loss: 0.9602
training Epoch: 50, train_Loss: 0.1646
training Epoch: 50, train_Loss: 0.1960
training Epoch: 50, train_Loss: 0.2519
training Epoch: 50, train_Loss: 0.9294
training Epoch: 50, train_Loss: 1.2133
training Epoch: 50, train_Loss: 1.8973
training Epoch: 50, train_Loss: 0.8487
training Epoch: 50, train_Loss: 0.4096
training Epoch: 50, train_Loss: 0.4199
training Epoch: 50, train_Loss: 2.9866
training Epoch: 50, train_Loss: 0.7874
training Epoch: 50, train_Loss: 0.4338
training Epoch: 50, train_Loss: 0.9738
training Epoch: 50, train_Loss: 1.3279
training Epoch: 50, train_Loss: 0.6395
training Epoch: 50, train_Loss: 1.3221
training Epoch: 50, train_Loss: 1.9041
training Epoch: 50, train_Loss: 2.0248
training Epoch: 50, train_Loss: 1.3729
training Epoch: 50, train_Loss: 1.8640
training Epoch: 50, train_Loss: 0.8336
training Epoch: 50, train_Loss: 0.5926
training Epoch: 50, train_Loss: 1.7647
training Epoch: 50, train_Loss: 1.0214
training Epoch: 50, train_Loss: 1.2305
training Epoch: 50, train_Loss: 1.5798
training Epoch: 50, train_Loss: 1.1673
training Epoch: 50, train_Loss: 1.1925
training Epoch: 50, train_Loss: 1.3161
training Epoch: 50, train_Loss: 0.9654
training Epoch: 50, train_Loss: 0.7762
training Epoch: 50, train_Loss: 1.9974
training Epoch: 50, train_Loss: 1.2290
training Epoch: 50, train_Loss: 0.8926
training Epoch: 50, train_Loss: 2.9992
training Epoch: 50, train_Loss: 0.4841
training Epoch: 50, train_Loss: 2.0369
training Epoch: 50, train_Loss: 0.8103
training Epoch: 50, train_Loss: 0.4333
training Epoch: 50, train_Loss: 1.2637
training Epoch: 50, train_Loss: 5.1301
training Epoch: 50, train_Loss: 0.4137
training Epoch: 50, train_Loss: 0.7591
training Epoch: 50, train_Loss: 1.2847
training Epoch: 50, train_Loss: 1.7447
training Epoch: 50, train_Loss: 0.3478
training Epoch: 50, train_Loss: 1.8708
training Epoch: 50, train_Loss: 0.4609
training Epoch: 50, train_Loss: 0.9206
training Epoch: 50, train_Loss: 0.4318
training Epoch: 50, train_Loss: 2.2600
training Epoch: 50, train_Loss: 0.6204
training Epoch: 50, train_Loss: 1.2223
training Epoch: 50, train_Loss: 2.0157
training Epoch: 50, train_Loss: 0.6371
training Epoch: 50, train_Loss: 1.4552
training Epoch: 50, train_Loss: 0.5923
training Epoch: 50, train_Loss: 1.7899
training Epoch: 50, train_Loss: 0.4432
training Epoch: 50, train_Loss: 0.3971
training Epoch: 50, train_Loss: 1.7598
training Epoch: 50, train_Loss: 2.2357
training Epoch: 50, train_Loss: 1.5313
training Epoch: 50, train_Loss: 2.6397
training Epoch: 50, train_Loss: 1.2204
training Epoch: 50, train_Loss: 1.7617
training Epoch: 50, train_Loss: 1.6515
training Epoch: 50, train_Loss: 0.8596
training Epoch: 50, train_Loss: 1.0692
training Epoch: 50, train_Loss: 1.8539
training Epoch: 50, train_Loss: 0.5246
training Epoch: 50, train_Loss: 1.2074
training Epoch: 50, train_Loss: 1.0573
training Epoch: 50, train_Loss: 1.7321
training Epoch: 50, train_Loss: 0.6023
training Epoch: 50, train_Loss: 1.5522
training Epoch: 50, train_Loss: 1.1192
training Epoch: 50, train_Loss: 1.1781
training Epoch: 50, train_Loss: 1.4271
training Epoch: 50, train_Loss: 0.6597
training Epoch: 50, train_Loss: 0.7894
training Epoch: 50, train_Loss: 0.8614
training Epoch: 50, train_Loss: 1.0721
training Epoch: 50, train_Loss: 1.7556
training Epoch: 50, train_Loss: 0.9754
training Epoch: 50, train_Loss: 2.2660
training Epoch: 50, train_Loss: 1.3043
training Epoch: 50, train_Loss: 0.9502
training Epoch: 50, train_Loss: 1.0181
training Epoch: 50, train_Loss: 1.1781
training Epoch: 50, train_Loss: 0.4879
training Epoch: 50, train_Loss: 1.0415
training Epoch: 50, train_Loss: 0.4740
training Epoch: 50, train_Loss: 0.8972
training Epoch: 50, train_Loss: 0.3333
training Epoch: 50, train_Loss: 0.5505
training Epoch: 50, train_Loss: 0.7658
training Epoch: 50, train_Loss: 0.4539
training Epoch: 50, train_Loss: 1.0074
training Epoch: 50, train_Loss: 0.9587
training Epoch: 50, train_Loss: 1.2732
training Epoch: 50, train_Loss: 0.1646
training Epoch: 50, train_Loss: 0.2911
training Epoch: 50, train_Loss: 2.5610
training Epoch: 50, train_Loss: 1.8519
training Epoch: 50, train_Loss: 1.3139
training Epoch: 50, train_Loss: 0.1710
training Epoch: 50, train_Loss: 2.6114
training Epoch: 50, train_Loss: 0.3360
fold,epoch,train_loss: 3 49 1.0840029
fold,epoch,train_loss: 3 50 1.087517
fold,epoch,train_loss: 3 51 1.0906337
fold,epoch,train_loss: 3 52 1.0869882
fold,epoch,train_loss: 3 53 1.0861175
fold,epoch,train_loss: 3 54 1.089844
fold,epoch,train_loss: 3 55 1.0900286
fold,epoch,train_loss: 3 56 1.0879713
fold,epoch,train_loss: 3 57 1.0910829
fold,epoch,train_loss: 3 58 1.0893983
fold,epoch,train_loss: 3 59 1.0853337
fold,epoch,train_loss: 3 60 1.0871136
fold,epoch,train_loss: 3 61 1.0876263
fold,epoch,train_loss: 3 62 1.0897467
fold,epoch,train_loss: 3 63 1.093579
fold,epoch,train_loss: 3 64 1.0903149
fold,epoch,train_loss: 3 65 1.0909022
fold,epoch,train_loss: 3 66 1.0926161
fold,epoch,train_loss: 3 67 1.0897154
fold,epoch,train_loss: 3 68 1.0836719
fold,epoch,train_loss: 3 69 1.0836799
fold,epoch,train_loss: 3 70 1.0822896
fold,epoch,train_loss: 3 71 1.0882144
fold,epoch,train_loss: 3 72 1.0869625
fold,epoch,train_loss: 3 73 1.0924126
fold,epoch,train_loss: 3 74 1.08868
fold,epoch,train_loss: 3 75 1.0894344
fold,epoch,train_loss: 3 76 1.0890597
fold,epoch,train_loss: 3 77 1.0901115
fold,epoch,train_loss: 3 78 1.0907817
fold,epoch,train_loss: 3 79 1.0887598
fold,epoch,train_loss: 3 80 1.0932449
fold,epoch,train_loss: 3 81 1.0864136
fold,epoch,train_loss: 3 82 1.0863765
fold,epoch,train_loss: 3 83 1.0942261
fold,epoch,train_loss: 3 84 1.0895884
fold,epoch,train_loss: 3 85 1.0920991
fold,epoch,train_loss: 3 86 1.0879515
fold,epoch,train_loss: 3 87 1.0925229
fold,epoch,train_loss: 3 88 1.0888757
fold,epoch,train_loss: 3 89 1.0928756
fold,epoch,train_loss: 3 90 1.0913296
fold,epoch,train_loss: 3 91 1.0901545
fold,epoch,train_loss: 3 92 1.0883688
fold,epoch,train_loss: 3 93 1.0915449
fold,epoch,train_loss: 3 94 1.0879165
fold,epoch,train_loss: 3 95 1.0931234
fold,epoch,train_loss: 3 96 1.0917499
fold,epoch,train_loss: 3 97 1.0889037
fold,epoch,train_loss: 3 98 1.0914317
training Epoch: 100, train_Loss: 0.9902
training Epoch: 100, train_Loss: 2.1896
training Epoch: 100, train_Loss: 0.4237
training Epoch: 100, train_Loss: 0.4878
training Epoch: 100, train_Loss: 1.1506
training Epoch: 100, train_Loss: 0.3698
training Epoch: 100, train_Loss: 0.7091
training Epoch: 100, train_Loss: 1.2606
training Epoch: 100, train_Loss: 0.6141
training Epoch: 100, train_Loss: 1.3227
training Epoch: 100, train_Loss: 0.2607
training Epoch: 100, train_Loss: 0.6702
training Epoch: 100, train_Loss: 0.9523
training Epoch: 100, train_Loss: 0.2599
training Epoch: 100, train_Loss: 0.7383
training Epoch: 100, train_Loss: 1.8352
training Epoch: 100, train_Loss: 0.7192
training Epoch: 100, train_Loss: 1.5286
training Epoch: 100, train_Loss: 1.5698
training Epoch: 100, train_Loss: 0.9998
training Epoch: 100, train_Loss: 2.1930
training Epoch: 100, train_Loss: 1.9152
training Epoch: 100, train_Loss: 0.8129
training Epoch: 100, train_Loss: 1.7949
training Epoch: 100, train_Loss: 1.0572
training Epoch: 100, train_Loss: 1.7707
training Epoch: 100, train_Loss: 0.7359
training Epoch: 100, train_Loss: 0.7542
training Epoch: 100, train_Loss: 3.4166
training Epoch: 100, train_Loss: 0.7491
training Epoch: 100, train_Loss: 2.0487
training Epoch: 100, train_Loss: 2.0008
training Epoch: 100, train_Loss: 0.7235
training Epoch: 100, train_Loss: 1.1691
training Epoch: 100, train_Loss: 1.3218
training Epoch: 100, train_Loss: 1.0539
training Epoch: 100, train_Loss: 1.5941
training Epoch: 100, train_Loss: 0.3112
training Epoch: 100, train_Loss: 0.8982
training Epoch: 100, train_Loss: 0.8624
training Epoch: 100, train_Loss: 1.0856
training Epoch: 100, train_Loss: 1.4568
training Epoch: 100, train_Loss: 1.0579
training Epoch: 100, train_Loss: 0.8410
training Epoch: 100, train_Loss: 0.5869
training Epoch: 100, train_Loss: 0.9373
training Epoch: 100, train_Loss: 0.5564
training Epoch: 100, train_Loss: 1.4780
training Epoch: 100, train_Loss: 1.2381
training Epoch: 100, train_Loss: 1.0814
training Epoch: 100, train_Loss: 0.2362
training Epoch: 100, train_Loss: 0.3576
training Epoch: 100, train_Loss: 1.2898
training Epoch: 100, train_Loss: 2.3627
training Epoch: 100, train_Loss: 0.5555
training Epoch: 100, train_Loss: 0.3671
training Epoch: 100, train_Loss: 2.4563
training Epoch: 100, train_Loss: 1.0409
training Epoch: 100, train_Loss: 0.9135
training Epoch: 100, train_Loss: 0.1874
training Epoch: 100, train_Loss: 0.5744
training Epoch: 100, train_Loss: 2.1558
training Epoch: 100, train_Loss: 0.7786
training Epoch: 100, train_Loss: 0.2857
training Epoch: 100, train_Loss: 0.7518
training Epoch: 100, train_Loss: 1.4338
training Epoch: 100, train_Loss: 0.5005
training Epoch: 100, train_Loss: 0.5599
training Epoch: 100, train_Loss: 0.7041
training Epoch: 100, train_Loss: 1.9817
training Epoch: 100, train_Loss: 2.4753
training Epoch: 100, train_Loss: 0.9914
training Epoch: 100, train_Loss: 1.2387
training Epoch: 100, train_Loss: 3.3695
training Epoch: 100, train_Loss: 0.9812
training Epoch: 100, train_Loss: 0.5450
training Epoch: 100, train_Loss: 0.6042
training Epoch: 100, train_Loss: 2.4643
training Epoch: 100, train_Loss: 0.9143
training Epoch: 100, train_Loss: 0.4537
training Epoch: 100, train_Loss: 0.4884
training Epoch: 100, train_Loss: 0.6058
training Epoch: 100, train_Loss: 0.7903
training Epoch: 100, train_Loss: 1.7540
training Epoch: 100, train_Loss: 1.5083
training Epoch: 100, train_Loss: 1.1391
training Epoch: 100, train_Loss: 0.6333
training Epoch: 100, train_Loss: 0.5233
training Epoch: 100, train_Loss: 0.7278
training Epoch: 100, train_Loss: 0.4934
training Epoch: 100, train_Loss: 0.5348
training Epoch: 100, train_Loss: 1.3943
training Epoch: 100, train_Loss: 0.3288
training Epoch: 100, train_Loss: 0.7317
training Epoch: 100, train_Loss: 1.5169
training Epoch: 100, train_Loss: 0.3127
training Epoch: 100, train_Loss: 1.0762
training Epoch: 100, train_Loss: 1.1747
training Epoch: 100, train_Loss: 2.9809
training Epoch: 100, train_Loss: 0.5579
training Epoch: 100, train_Loss: 2.8361
training Epoch: 100, train_Loss: 1.6212
training Epoch: 100, train_Loss: 0.5989
training Epoch: 100, train_Loss: 0.5743
training Epoch: 100, train_Loss: 0.5000
training Epoch: 100, train_Loss: 1.9223
training Epoch: 100, train_Loss: 0.3277
training Epoch: 100, train_Loss: 0.8176
training Epoch: 100, train_Loss: 0.9748
training Epoch: 100, train_Loss: 1.2966
training Epoch: 100, train_Loss: 0.9531
training Epoch: 100, train_Loss: 0.7719
training Epoch: 100, train_Loss: 0.8232
training Epoch: 100, train_Loss: 1.9286
training Epoch: 100, train_Loss: 0.6795
training Epoch: 100, train_Loss: 1.0799
training Epoch: 100, train_Loss: 1.6827
training Epoch: 100, train_Loss: 0.4320
training Epoch: 100, train_Loss: 1.1770
training Epoch: 100, train_Loss: 0.6857
training Epoch: 100, train_Loss: 1.2751
training Epoch: 100, train_Loss: 0.7844
training Epoch: 100, train_Loss: 0.9625
training Epoch: 100, train_Loss: 0.4392
training Epoch: 100, train_Loss: 2.8827
training Epoch: 100, train_Loss: 1.0753
training Epoch: 100, train_Loss: 2.5902
training Epoch: 100, train_Loss: 0.5517
training Epoch: 100, train_Loss: 0.7791
training Epoch: 100, train_Loss: 1.1481
training Epoch: 100, train_Loss: 0.2856
training Epoch: 100, train_Loss: 1.5947
training Epoch: 100, train_Loss: 0.4819
training Epoch: 100, train_Loss: 0.5376
training Epoch: 100, train_Loss: 0.9841
training Epoch: 100, train_Loss: 0.9600
training Epoch: 100, train_Loss: 0.3787
training Epoch: 100, train_Loss: 1.6877
training Epoch: 100, train_Loss: 0.4662
training Epoch: 100, train_Loss: 1.0684
training Epoch: 100, train_Loss: 0.3843
training Epoch: 100, train_Loss: 1.1914
training Epoch: 100, train_Loss: 0.6597
training Epoch: 100, train_Loss: 0.5148
training Epoch: 100, train_Loss: 0.6274
training Epoch: 100, train_Loss: 0.5513
training Epoch: 100, train_Loss: 2.6105
training Epoch: 100, train_Loss: 1.1470
training Epoch: 100, train_Loss: 0.3466
training Epoch: 100, train_Loss: 1.8999
training Epoch: 100, train_Loss: 1.7236
training Epoch: 100, train_Loss: 0.4562
training Epoch: 100, train_Loss: 0.6848
training Epoch: 100, train_Loss: 0.7330
training Epoch: 100, train_Loss: 0.4626
training Epoch: 100, train_Loss: 0.4368
training Epoch: 100, train_Loss: 0.3575
training Epoch: 100, train_Loss: 1.4299
training Epoch: 100, train_Loss: 2.6832
training Epoch: 100, train_Loss: 1.1408
training Epoch: 100, train_Loss: 0.7997
training Epoch: 100, train_Loss: 1.8499
training Epoch: 100, train_Loss: 3.9370
training Epoch: 100, train_Loss: 1.4076
training Epoch: 100, train_Loss: 0.9448
training Epoch: 100, train_Loss: 0.6389
training Epoch: 100, train_Loss: 0.9819
training Epoch: 100, train_Loss: 0.8766
training Epoch: 100, train_Loss: 1.2020
training Epoch: 100, train_Loss: 0.4914
training Epoch: 100, train_Loss: 2.0401
training Epoch: 100, train_Loss: 0.5346
training Epoch: 100, train_Loss: 1.1172
training Epoch: 100, train_Loss: 1.6949
training Epoch: 100, train_Loss: 0.9269
training Epoch: 100, train_Loss: 1.5267
training Epoch: 100, train_Loss: 0.6433
training Epoch: 100, train_Loss: 0.5513
training Epoch: 100, train_Loss: 1.6917
training Epoch: 100, train_Loss: 0.5102
training Epoch: 100, train_Loss: 1.6452
training Epoch: 100, train_Loss: 1.5869
training Epoch: 100, train_Loss: 1.3350
training Epoch: 100, train_Loss: 1.7607
training Epoch: 100, train_Loss: 0.4583
training Epoch: 100, train_Loss: 0.5587
training Epoch: 100, train_Loss: 1.0404
training Epoch: 100, train_Loss: 0.3877
training Epoch: 100, train_Loss: 0.6880
training Epoch: 100, train_Loss: 1.3764
training Epoch: 100, train_Loss: 0.7858
training Epoch: 100, train_Loss: 1.4064
training Epoch: 100, train_Loss: 1.3113
training Epoch: 100, train_Loss: 0.4098
training Epoch: 100, train_Loss: 0.9647
training Epoch: 100, train_Loss: 1.4798
training Epoch: 100, train_Loss: 0.6935
training Epoch: 100, train_Loss: 0.9303
training Epoch: 100, train_Loss: 1.7653
training Epoch: 100, train_Loss: 0.3194
training Epoch: 100, train_Loss: 1.0847
training Epoch: 100, train_Loss: 0.7222
training Epoch: 100, train_Loss: 0.4324
training Epoch: 100, train_Loss: 0.2976
training Epoch: 100, train_Loss: 3.1030
training Epoch: 100, train_Loss: 0.8158
training Epoch: 100, train_Loss: 0.3644
training Epoch: 100, train_Loss: 0.4607
training Epoch: 100, train_Loss: 1.5752
training Epoch: 100, train_Loss: 0.5778
training Epoch: 100, train_Loss: 0.7365
training Epoch: 100, train_Loss: 1.9155
training Epoch: 100, train_Loss: 4.4177
training Epoch: 100, train_Loss: 1.0314
training Epoch: 100, train_Loss: 0.9101
training Epoch: 100, train_Loss: 1.1077
training Epoch: 100, train_Loss: 0.4441
training Epoch: 100, train_Loss: 0.6302
training Epoch: 100, train_Loss: 0.9951
training Epoch: 100, train_Loss: 0.6519
training Epoch: 100, train_Loss: 1.8897
training Epoch: 100, train_Loss: 0.6418
training Epoch: 100, train_Loss: 2.0511
training Epoch: 100, train_Loss: 2.1057
training Epoch: 100, train_Loss: 0.8715
training Epoch: 100, train_Loss: 1.0379
training Epoch: 100, train_Loss: 1.3083
training Epoch: 100, train_Loss: 0.9986
training Epoch: 100, train_Loss: 0.8490
training Epoch: 100, train_Loss: 0.8816
training Epoch: 100, train_Loss: 0.9785
training Epoch: 100, train_Loss: 0.7043
training Epoch: 100, train_Loss: 0.6797
training Epoch: 100, train_Loss: 0.7574
training Epoch: 100, train_Loss: 2.4047
training Epoch: 100, train_Loss: 0.4437
training Epoch: 100, train_Loss: 1.4320
training Epoch: 100, train_Loss: 0.4472
training Epoch: 100, train_Loss: 3.6960
training Epoch: 100, train_Loss: 4.1834
training Epoch: 100, train_Loss: 1.7165
training Epoch: 100, train_Loss: 0.2809
training Epoch: 100, train_Loss: 0.5014
training Epoch: 100, train_Loss: 0.6381
training Epoch: 100, train_Loss: 3.5747
training Epoch: 100, train_Loss: 1.1563
training Epoch: 100, train_Loss: 0.5286
training Epoch: 100, train_Loss: 0.7428
training Epoch: 100, train_Loss: 1.6117
training Epoch: 100, train_Loss: 1.4211
training Epoch: 100, train_Loss: 1.0988
training Epoch: 100, train_Loss: 2.6302
training Epoch: 100, train_Loss: 2.1057
training Epoch: 100, train_Loss: 0.6856
training Epoch: 100, train_Loss: 0.6316
training Epoch: 100, train_Loss: 1.1378
training Epoch: 100, train_Loss: 1.4022
training Epoch: 100, train_Loss: 0.8556
training Epoch: 100, train_Loss: 1.7667
training Epoch: 100, train_Loss: 1.2630
training Epoch: 100, train_Loss: 0.7925
training Epoch: 100, train_Loss: 0.5649
training Epoch: 100, train_Loss: 1.0225
training Epoch: 100, train_Loss: 1.3609
training Epoch: 100, train_Loss: 2.3950
training Epoch: 100, train_Loss: 2.0769
training Epoch: 100, train_Loss: 0.5066
training Epoch: 100, train_Loss: 1.2954
training Epoch: 100, train_Loss: 1.4678
training Epoch: 100, train_Loss: 0.8641
training Epoch: 100, train_Loss: 1.1148
training Epoch: 100, train_Loss: 0.8135
training Epoch: 100, train_Loss: 1.1600
training Epoch: 100, train_Loss: 1.3059
training Epoch: 100, train_Loss: 0.7563
training Epoch: 100, train_Loss: 0.4848
training Epoch: 100, train_Loss: 0.8743
training Epoch: 100, train_Loss: 1.3430
training Epoch: 100, train_Loss: 1.2405
training Epoch: 100, train_Loss: 0.5599
training Epoch: 100, train_Loss: 1.1940
training Epoch: 100, train_Loss: 1.1479
training Epoch: 100, train_Loss: 0.7429
training Epoch: 100, train_Loss: 2.1134
training Epoch: 100, train_Loss: 0.7318
training Epoch: 100, train_Loss: 1.7835
training Epoch: 100, train_Loss: 1.5724
training Epoch: 100, train_Loss: 0.3974
training Epoch: 100, train_Loss: 1.0451
training Epoch: 100, train_Loss: 1.8526
training Epoch: 100, train_Loss: 0.7477
training Epoch: 100, train_Loss: 0.8554
training Epoch: 100, train_Loss: 0.8940
training Epoch: 100, train_Loss: 0.3629
training Epoch: 100, train_Loss: 0.5222
training Epoch: 100, train_Loss: 0.6170
training Epoch: 100, train_Loss: 0.5088
training Epoch: 100, train_Loss: 1.0037
training Epoch: 100, train_Loss: 0.4395
training Epoch: 100, train_Loss: 1.2849
training Epoch: 100, train_Loss: 1.1714
training Epoch: 100, train_Loss: 1.6971
training Epoch: 100, train_Loss: 1.6031
training Epoch: 100, train_Loss: 0.8542
training Epoch: 100, train_Loss: 0.8261
training Epoch: 100, train_Loss: 0.3361
training Epoch: 100, train_Loss: 1.1996
training Epoch: 100, train_Loss: 0.2821
training Epoch: 100, train_Loss: 2.5666
training Epoch: 100, train_Loss: 0.5687
training Epoch: 100, train_Loss: 1.0612
training Epoch: 100, train_Loss: 0.6814
training Epoch: 100, train_Loss: 0.3848
training Epoch: 100, train_Loss: 1.6985
training Epoch: 100, train_Loss: 0.3751
training Epoch: 100, train_Loss: 0.4337
training Epoch: 100, train_Loss: 0.6376
training Epoch: 100, train_Loss: 0.5247
training Epoch: 100, train_Loss: 1.2233
training Epoch: 100, train_Loss: 0.4385
training Epoch: 100, train_Loss: 2.1169
training Epoch: 100, train_Loss: 1.1040
training Epoch: 100, train_Loss: 1.1317
training Epoch: 100, train_Loss: 1.9631
training Epoch: 100, train_Loss: 1.0467
training Epoch: 100, train_Loss: 0.5737
training Epoch: 100, train_Loss: 0.8942
training Epoch: 100, train_Loss: 0.7045
training Epoch: 100, train_Loss: 1.8127
training Epoch: 100, train_Loss: 1.5336
training Epoch: 100, train_Loss: 0.8413
training Epoch: 100, train_Loss: 0.5593
training Epoch: 100, train_Loss: 0.4443
training Epoch: 100, train_Loss: 0.6167
training Epoch: 100, train_Loss: 0.6434
training Epoch: 100, train_Loss: 1.7021
training Epoch: 100, train_Loss: 0.6374
training Epoch: 100, train_Loss: 0.4385
training Epoch: 100, train_Loss: 0.6649
training Epoch: 100, train_Loss: 0.4715
training Epoch: 100, train_Loss: 1.3036
training Epoch: 100, train_Loss: 1.5114
training Epoch: 100, train_Loss: 0.2550
training Epoch: 100, train_Loss: 0.4349
training Epoch: 100, train_Loss: 0.3344
training Epoch: 100, train_Loss: 0.6240
training Epoch: 100, train_Loss: 1.2147
training Epoch: 100, train_Loss: 2.7009
training Epoch: 100, train_Loss: 0.3288
training Epoch: 100, train_Loss: 0.3600
training Epoch: 100, train_Loss: 0.8349
training Epoch: 100, train_Loss: 0.2566
training Epoch: 100, train_Loss: 1.7179
training Epoch: 100, train_Loss: 1.0182
training Epoch: 100, train_Loss: 1.1933
training Epoch: 100, train_Loss: 1.4100
training Epoch: 100, train_Loss: 0.7457
training Epoch: 100, train_Loss: 0.9698
training Epoch: 100, train_Loss: 0.3294
training Epoch: 100, train_Loss: 0.3768
training Epoch: 100, train_Loss: 2.0861
training Epoch: 100, train_Loss: 0.8086
training Epoch: 100, train_Loss: 1.2077
training Epoch: 100, train_Loss: 0.8407
training Epoch: 100, train_Loss: 0.7839
training Epoch: 100, train_Loss: 0.7448
training Epoch: 100, train_Loss: 0.8726
training Epoch: 100, train_Loss: 0.5283
training Epoch: 100, train_Loss: 0.4538
training Epoch: 100, train_Loss: 1.1255
training Epoch: 100, train_Loss: 0.5090
training Epoch: 100, train_Loss: 0.4885
training Epoch: 100, train_Loss: 0.8600
training Epoch: 100, train_Loss: 1.0155
training Epoch: 100, train_Loss: 0.3686
training Epoch: 100, train_Loss: 0.7280
training Epoch: 100, train_Loss: 1.7163
training Epoch: 100, train_Loss: 0.5857
training Epoch: 100, train_Loss: 2.9929
training Epoch: 100, train_Loss: 0.9117
training Epoch: 100, train_Loss: 0.8827
training Epoch: 100, train_Loss: 0.2621
training Epoch: 100, train_Loss: 0.3922
training Epoch: 100, train_Loss: 1.1268
training Epoch: 100, train_Loss: 0.6868
training Epoch: 100, train_Loss: 0.8284
training Epoch: 100, train_Loss: 1.6496
training Epoch: 100, train_Loss: 0.3094
training Epoch: 100, train_Loss: 0.7941
training Epoch: 100, train_Loss: 0.3571
training Epoch: 100, train_Loss: 0.3588
training Epoch: 100, train_Loss: 1.3920
training Epoch: 100, train_Loss: 0.8937
training Epoch: 100, train_Loss: 1.7074
training Epoch: 100, train_Loss: 0.8677
training Epoch: 100, train_Loss: 0.2990
training Epoch: 100, train_Loss: 0.3077
training Epoch: 100, train_Loss: 0.7287
training Epoch: 100, train_Loss: 0.5417
training Epoch: 100, train_Loss: 2.0511
training Epoch: 100, train_Loss: 0.4040
training Epoch: 100, train_Loss: 1.0074
training Epoch: 100, train_Loss: 1.3384
training Epoch: 100, train_Loss: 1.8692
training Epoch: 100, train_Loss: 2.4444
training Epoch: 100, train_Loss: 0.3360
training Epoch: 100, train_Loss: 1.2941
training Epoch: 100, train_Loss: 1.4667
training Epoch: 100, train_Loss: 0.8904
training Epoch: 100, train_Loss: 0.3728
training Epoch: 100, train_Loss: 2.1961
training Epoch: 100, train_Loss: 0.4030
training Epoch: 100, train_Loss: 0.8714
training Epoch: 100, train_Loss: 0.4931
training Epoch: 100, train_Loss: 0.5467
training Epoch: 100, train_Loss: 1.7563
training Epoch: 100, train_Loss: 1.5559
training Epoch: 100, train_Loss: 0.4439
training Epoch: 100, train_Loss: 0.8702
training Epoch: 100, train_Loss: 0.6443
training Epoch: 100, train_Loss: 1.4501
training Epoch: 100, train_Loss: 1.6417
training Epoch: 100, train_Loss: 0.5333
training Epoch: 100, train_Loss: 0.4884
training Epoch: 100, train_Loss: 2.3334
training Epoch: 100, train_Loss: 1.9556
training Epoch: 100, train_Loss: 0.4428
training Epoch: 100, train_Loss: 1.4201
training Epoch: 100, train_Loss: 0.9183
training Epoch: 100, train_Loss: 4.6359
training Epoch: 100, train_Loss: 1.4480
training Epoch: 100, train_Loss: 2.0499
training Epoch: 100, train_Loss: 1.4001
training Epoch: 100, train_Loss: 0.8125
training Epoch: 100, train_Loss: 1.0612
training Epoch: 100, train_Loss: 1.5756
training Epoch: 100, train_Loss: 1.4816
training Epoch: 100, train_Loss: 0.7079
training Epoch: 100, train_Loss: 1.2991
training Epoch: 100, train_Loss: 0.8109
training Epoch: 100, train_Loss: 1.3620
training Epoch: 100, train_Loss: 1.2669
training Epoch: 100, train_Loss: 1.9870
training Epoch: 100, train_Loss: 0.6442
training Epoch: 100, train_Loss: 0.8690
training Epoch: 100, train_Loss: 1.4330
training Epoch: 100, train_Loss: 1.4065
training Epoch: 100, train_Loss: 0.9919
training Epoch: 100, train_Loss: 0.6934
training Epoch: 100, train_Loss: 1.8146
training Epoch: 100, train_Loss: 0.4657
training Epoch: 100, train_Loss: 0.8102
training Epoch: 100, train_Loss: 1.2578
training Epoch: 100, train_Loss: 0.4685
training Epoch: 100, train_Loss: 0.7634
training Epoch: 100, train_Loss: 0.6803
training Epoch: 100, train_Loss: 0.9250
training Epoch: 100, train_Loss: 0.8890
training Epoch: 100, train_Loss: 1.9080
training Epoch: 100, train_Loss: 0.9385
training Epoch: 100, train_Loss: 0.4196
training Epoch: 100, train_Loss: 2.8689
training Epoch: 100, train_Loss: 0.6933
training Epoch: 100, train_Loss: 1.3886
training Epoch: 100, train_Loss: 1.9550
training Epoch: 100, train_Loss: 3.2320
training Epoch: 100, train_Loss: 0.9438
training Epoch: 100, train_Loss: 0.5099
training Epoch: 100, train_Loss: 1.3920
training Epoch: 100, train_Loss: 0.8308
training Epoch: 100, train_Loss: 0.6470
training Epoch: 100, train_Loss: 0.5162
training Epoch: 100, train_Loss: 2.4070
training Epoch: 100, train_Loss: 0.9387
training Epoch: 100, train_Loss: 1.8705
training Epoch: 100, train_Loss: 1.0016
training Epoch: 100, train_Loss: 1.1696
training Epoch: 100, train_Loss: 2.2064
training Epoch: 100, train_Loss: 1.0442
training Epoch: 100, train_Loss: 0.7389
training Epoch: 100, train_Loss: 2.0122
training Epoch: 100, train_Loss: 0.7231
training Epoch: 100, train_Loss: 1.1468
training Epoch: 100, train_Loss: 1.3033
training Epoch: 100, train_Loss: 1.6060
training Epoch: 100, train_Loss: 0.5003
training Epoch: 100, train_Loss: 0.6678
training Epoch: 100, train_Loss: 1.7164
training Epoch: 100, train_Loss: 0.8904
training Epoch: 100, train_Loss: 1.6033
training Epoch: 100, train_Loss: 0.9076
training Epoch: 100, train_Loss: 0.4819
training Epoch: 100, train_Loss: 1.0921
training Epoch: 100, train_Loss: 0.7749
training Epoch: 100, train_Loss: 1.2742
training Epoch: 100, train_Loss: 0.8692
training Epoch: 100, train_Loss: 0.8689
training Epoch: 100, train_Loss: 1.7239
training Epoch: 100, train_Loss: 0.7885
training Epoch: 100, train_Loss: 1.5279
training Epoch: 100, train_Loss: 1.8884
training Epoch: 100, train_Loss: 0.3412
training Epoch: 100, train_Loss: 1.1320
training Epoch: 100, train_Loss: 1.3115
training Epoch: 100, train_Loss: 0.5208
training Epoch: 100, train_Loss: 1.1746
training Epoch: 100, train_Loss: 0.6123
training Epoch: 100, train_Loss: 0.7674
training Epoch: 100, train_Loss: 0.5760
training Epoch: 100, train_Loss: 1.0943
training Epoch: 100, train_Loss: 2.1402
training Epoch: 100, train_Loss: 0.8411
training Epoch: 100, train_Loss: 1.3679
training Epoch: 100, train_Loss: 0.8350
training Epoch: 100, train_Loss: 0.7240
training Epoch: 100, train_Loss: 0.5554
training Epoch: 100, train_Loss: 0.6570
training Epoch: 100, train_Loss: 0.6944
training Epoch: 100, train_Loss: 1.7224
training Epoch: 100, train_Loss: 1.0392
training Epoch: 100, train_Loss: 2.0754
training Epoch: 100, train_Loss: 0.3864
training Epoch: 100, train_Loss: 0.4825
training Epoch: 100, train_Loss: 2.2438
training Epoch: 100, train_Loss: 0.3683
training Epoch: 100, train_Loss: 0.5890
training Epoch: 100, train_Loss: 1.0341
training Epoch: 100, train_Loss: 0.4230
training Epoch: 100, train_Loss: 1.1348
training Epoch: 100, train_Loss: 0.4620
training Epoch: 100, train_Loss: 1.4961
training Epoch: 100, train_Loss: 1.6945
training Epoch: 100, train_Loss: 1.0136
training Epoch: 100, train_Loss: 0.8309
training Epoch: 100, train_Loss: 1.1074
training Epoch: 100, train_Loss: 0.3998
training Epoch: 100, train_Loss: 0.5929
training Epoch: 100, train_Loss: 0.8595
training Epoch: 100, train_Loss: 0.8295
training Epoch: 100, train_Loss: 0.8906
training Epoch: 100, train_Loss: 1.2948
training Epoch: 100, train_Loss: 1.6547
training Epoch: 100, train_Loss: 0.2584
training Epoch: 100, train_Loss: 1.5177
training Epoch: 100, train_Loss: 1.6484
training Epoch: 100, train_Loss: 0.7867
training Epoch: 100, train_Loss: 2.1337
training Epoch: 100, train_Loss: 2.7349
training Epoch: 100, train_Loss: 1.8695
training Epoch: 100, train_Loss: 0.3686
training Epoch: 100, train_Loss: 1.2525
training Epoch: 100, train_Loss: 0.5041
training Epoch: 100, train_Loss: 0.3574
training Epoch: 100, train_Loss: 0.8610
training Epoch: 100, train_Loss: 1.1094
training Epoch: 100, train_Loss: 0.9818
training Epoch: 100, train_Loss: 1.3968
training Epoch: 100, train_Loss: 0.5922
training Epoch: 100, train_Loss: 0.5272
training Epoch: 100, train_Loss: 0.5278
training Epoch: 100, train_Loss: 1.0379
training Epoch: 100, train_Loss: 0.6155
training Epoch: 100, train_Loss: 0.5220
training Epoch: 100, train_Loss: 0.2815
training Epoch: 100, train_Loss: 0.9585
training Epoch: 100, train_Loss: 0.2521
training Epoch: 100, train_Loss: 0.8169
training Epoch: 100, train_Loss: 1.9412
training Epoch: 100, train_Loss: 1.3517
training Epoch: 100, train_Loss: 1.8337
training Epoch: 100, train_Loss: 1.3499
training Epoch: 100, train_Loss: 1.9059
training Epoch: 100, train_Loss: 1.9788
training Epoch: 100, train_Loss: 0.4360
training Epoch: 100, train_Loss: 0.1266
fold,epoch,train_loss: 3 99 1.0871855
fold,epoch,train_loss: 3 100 1.0878304
====Evaluation
fold:3, epoch:100,train:1.087830, valid:1.100004 

fold: 4
fold,epoch,train_loss: 4 0 1.0932256
fold,epoch,train_loss: 4 1 1.0865517
fold,epoch,train_loss: 4 2 1.0873032
fold,epoch,train_loss: 4 3 1.0909096
fold,epoch,train_loss: 4 4 1.0886545
fold,epoch,train_loss: 4 5 1.0900643
fold,epoch,train_loss: 4 6 1.0903484
fold,epoch,train_loss: 4 7 1.0909437
fold,epoch,train_loss: 4 8 1.091192
fold,epoch,train_loss: 4 9 1.0857471
fold,epoch,train_loss: 4 10 1.090073
fold,epoch,train_loss: 4 11 1.0864816
fold,epoch,train_loss: 4 12 1.0834711
fold,epoch,train_loss: 4 13 1.0952722
fold,epoch,train_loss: 4 14 1.0893414
fold,epoch,train_loss: 4 15 1.0970776
fold,epoch,train_loss: 4 16 1.0864573
fold,epoch,train_loss: 4 17 1.0880972
fold,epoch,train_loss: 4 18 1.0865093
fold,epoch,train_loss: 4 19 1.0905409
fold,epoch,train_loss: 4 20 1.0964518
fold,epoch,train_loss: 4 21 1.0875208
fold,epoch,train_loss: 4 22 1.0866803
fold,epoch,train_loss: 4 23 1.0887072
fold,epoch,train_loss: 4 24 1.0889249
fold,epoch,train_loss: 4 25 1.0814073
fold,epoch,train_loss: 4 26 1.0890335
fold,epoch,train_loss: 4 27 1.0902222
fold,epoch,train_loss: 4 28 1.0977062
fold,epoch,train_loss: 4 29 1.0938944
fold,epoch,train_loss: 4 30 1.0845053
fold,epoch,train_loss: 4 31 1.0912199
fold,epoch,train_loss: 4 32 1.092064
fold,epoch,train_loss: 4 33 1.0870935
fold,epoch,train_loss: 4 34 1.0874438
fold,epoch,train_loss: 4 35 1.0912757
fold,epoch,train_loss: 4 36 1.0925913
fold,epoch,train_loss: 4 37 1.0874301
fold,epoch,train_loss: 4 38 1.0891157
fold,epoch,train_loss: 4 39 1.0876784
fold,epoch,train_loss: 4 40 1.0905634
fold,epoch,train_loss: 4 41 1.0861535
fold,epoch,train_loss: 4 42 1.0929708
fold,epoch,train_loss: 4 43 1.0911785
fold,epoch,train_loss: 4 44 1.0912732
fold,epoch,train_loss: 4 45 1.0843893
fold,epoch,train_loss: 4 46 1.0923179
fold,epoch,train_loss: 4 47 1.093912
fold,epoch,train_loss: 4 48 1.0919447
training Epoch: 50, train_Loss: 0.4382
training Epoch: 50, train_Loss: 2.5672
training Epoch: 50, train_Loss: 1.9395
training Epoch: 50, train_Loss: 0.6431
training Epoch: 50, train_Loss: 0.4823
training Epoch: 50, train_Loss: 1.1546
training Epoch: 50, train_Loss: 0.5034
training Epoch: 50, train_Loss: 2.6551
training Epoch: 50, train_Loss: 0.4329
training Epoch: 50, train_Loss: 1.1220
training Epoch: 50, train_Loss: 0.5094
training Epoch: 50, train_Loss: 1.5658
training Epoch: 50, train_Loss: 1.3468
training Epoch: 50, train_Loss: 4.0355
training Epoch: 50, train_Loss: 1.6004
training Epoch: 50, train_Loss: 0.6500
training Epoch: 50, train_Loss: 1.8483
training Epoch: 50, train_Loss: 0.8471
training Epoch: 50, train_Loss: 1.0751
training Epoch: 50, train_Loss: 2.1988
training Epoch: 50, train_Loss: 0.8755
training Epoch: 50, train_Loss: 0.9173
training Epoch: 50, train_Loss: 1.5026
training Epoch: 50, train_Loss: 0.8051
training Epoch: 50, train_Loss: 0.8233
training Epoch: 50, train_Loss: 0.7636
training Epoch: 50, train_Loss: 1.8023
training Epoch: 50, train_Loss: 1.1440
training Epoch: 50, train_Loss: 1.0799
training Epoch: 50, train_Loss: 3.3872
training Epoch: 50, train_Loss: 1.1583
training Epoch: 50, train_Loss: 0.4892
training Epoch: 50, train_Loss: 1.2518
training Epoch: 50, train_Loss: 1.2968
training Epoch: 50, train_Loss: 2.1039
training Epoch: 50, train_Loss: 0.9232
training Epoch: 50, train_Loss: 0.8295
training Epoch: 50, train_Loss: 3.5760
training Epoch: 50, train_Loss: 2.1070
training Epoch: 50, train_Loss: 0.6587
training Epoch: 50, train_Loss: 0.6624
training Epoch: 50, train_Loss: 1.3033
training Epoch: 50, train_Loss: 0.8260
training Epoch: 50, train_Loss: 0.8663
training Epoch: 50, train_Loss: 0.7056
training Epoch: 50, train_Loss: 0.9177
training Epoch: 50, train_Loss: 1.6791
training Epoch: 50, train_Loss: 1.0388
training Epoch: 50, train_Loss: 1.3459
training Epoch: 50, train_Loss: 0.6341
training Epoch: 50, train_Loss: 2.5234
training Epoch: 50, train_Loss: 0.8142
training Epoch: 50, train_Loss: 0.6160
training Epoch: 50, train_Loss: 0.8271
training Epoch: 50, train_Loss: 0.7310
training Epoch: 50, train_Loss: 0.9115
training Epoch: 50, train_Loss: 0.8034
training Epoch: 50, train_Loss: 0.7814
training Epoch: 50, train_Loss: 0.9897
training Epoch: 50, train_Loss: 0.8510
training Epoch: 50, train_Loss: 1.7010
training Epoch: 50, train_Loss: 1.0310
training Epoch: 50, train_Loss: 0.8448
training Epoch: 50, train_Loss: 0.5560
training Epoch: 50, train_Loss: 0.6276
training Epoch: 50, train_Loss: 0.7685
training Epoch: 50, train_Loss: 2.2990
training Epoch: 50, train_Loss: 1.4255
training Epoch: 50, train_Loss: 0.4812
training Epoch: 50, train_Loss: 0.3620
training Epoch: 50, train_Loss: 1.0969
training Epoch: 50, train_Loss: 2.7889
training Epoch: 50, train_Loss: 0.3919
training Epoch: 50, train_Loss: 0.4603
training Epoch: 50, train_Loss: 0.4588
training Epoch: 50, train_Loss: 0.7004
training Epoch: 50, train_Loss: 0.8091
training Epoch: 50, train_Loss: 0.7686
training Epoch: 50, train_Loss: 0.4745
training Epoch: 50, train_Loss: 0.2657
training Epoch: 50, train_Loss: 1.8978
training Epoch: 50, train_Loss: 1.5638
training Epoch: 50, train_Loss: 1.6180
training Epoch: 50, train_Loss: 0.5474
training Epoch: 50, train_Loss: 0.4020
training Epoch: 50, train_Loss: 0.9196
training Epoch: 50, train_Loss: 1.3152
training Epoch: 50, train_Loss: 2.0008
training Epoch: 50, train_Loss: 1.3335
training Epoch: 50, train_Loss: 1.5619
training Epoch: 50, train_Loss: 1.7784
training Epoch: 50, train_Loss: 0.4996
training Epoch: 50, train_Loss: 0.5484
training Epoch: 50, train_Loss: 1.1344
training Epoch: 50, train_Loss: 1.3615
training Epoch: 50, train_Loss: 1.3193
training Epoch: 50, train_Loss: 0.7492
training Epoch: 50, train_Loss: 1.2075
training Epoch: 50, train_Loss: 3.7732
training Epoch: 50, train_Loss: 0.6520
training Epoch: 50, train_Loss: 0.9427
training Epoch: 50, train_Loss: 0.9023
training Epoch: 50, train_Loss: 1.5144
training Epoch: 50, train_Loss: 0.8771
training Epoch: 50, train_Loss: 0.7503
training Epoch: 50, train_Loss: 1.1046
training Epoch: 50, train_Loss: 0.5842
training Epoch: 50, train_Loss: 0.5324
training Epoch: 50, train_Loss: 1.4229
training Epoch: 50, train_Loss: 2.5993
training Epoch: 50, train_Loss: 0.6561
training Epoch: 50, train_Loss: 0.7587
training Epoch: 50, train_Loss: 2.5989
training Epoch: 50, train_Loss: 1.2274
training Epoch: 50, train_Loss: 0.8645
training Epoch: 50, train_Loss: 1.2484
training Epoch: 50, train_Loss: 0.9137
training Epoch: 50, train_Loss: 0.3683
training Epoch: 50, train_Loss: 1.4898
training Epoch: 50, train_Loss: 0.3310
training Epoch: 50, train_Loss: 2.1982
training Epoch: 50, train_Loss: 1.8780
training Epoch: 50, train_Loss: 0.4753
training Epoch: 50, train_Loss: 0.7661
training Epoch: 50, train_Loss: 2.0526
training Epoch: 50, train_Loss: 2.3308
training Epoch: 50, train_Loss: 0.8098
training Epoch: 50, train_Loss: 0.7606
training Epoch: 50, train_Loss: 0.7179
training Epoch: 50, train_Loss: 0.6149
training Epoch: 50, train_Loss: 1.1327
training Epoch: 50, train_Loss: 0.6453
training Epoch: 50, train_Loss: 1.8935
training Epoch: 50, train_Loss: 0.6654
training Epoch: 50, train_Loss: 0.8199
training Epoch: 50, train_Loss: 1.2626
training Epoch: 50, train_Loss: 1.6602
training Epoch: 50, train_Loss: 0.5155
training Epoch: 50, train_Loss: 0.9373
training Epoch: 50, train_Loss: 0.5264
training Epoch: 50, train_Loss: 0.6945
training Epoch: 50, train_Loss: 1.4472
training Epoch: 50, train_Loss: 1.3733
training Epoch: 50, train_Loss: 1.6826
training Epoch: 50, train_Loss: 3.1321
training Epoch: 50, train_Loss: 1.3969
training Epoch: 50, train_Loss: 1.9531
training Epoch: 50, train_Loss: 0.5181
training Epoch: 50, train_Loss: 1.1159
training Epoch: 50, train_Loss: 1.1208
training Epoch: 50, train_Loss: 0.7983
training Epoch: 50, train_Loss: 1.6834
training Epoch: 50, train_Loss: 0.6935
training Epoch: 50, train_Loss: 0.5274
training Epoch: 50, train_Loss: 0.6450
training Epoch: 50, train_Loss: 0.5443
training Epoch: 50, train_Loss: 0.5646
training Epoch: 50, train_Loss: 2.2088
training Epoch: 50, train_Loss: 0.8001
training Epoch: 50, train_Loss: 2.3820
training Epoch: 50, train_Loss: 1.0565
training Epoch: 50, train_Loss: 2.1108
training Epoch: 50, train_Loss: 1.3542
training Epoch: 50, train_Loss: 1.7275
training Epoch: 50, train_Loss: 0.6403
training Epoch: 50, train_Loss: 0.9368
training Epoch: 50, train_Loss: 0.5013
training Epoch: 50, train_Loss: 1.3406
training Epoch: 50, train_Loss: 1.5273
training Epoch: 50, train_Loss: 1.5450
training Epoch: 50, train_Loss: 0.8236
training Epoch: 50, train_Loss: 0.7511
training Epoch: 50, train_Loss: 1.5936
training Epoch: 50, train_Loss: 0.7080
training Epoch: 50, train_Loss: 0.9444
training Epoch: 50, train_Loss: 1.9010
training Epoch: 50, train_Loss: 0.7067
training Epoch: 50, train_Loss: 0.8336
training Epoch: 50, train_Loss: 1.5527
training Epoch: 50, train_Loss: 0.6126
training Epoch: 50, train_Loss: 1.0919
training Epoch: 50, train_Loss: 1.2106
training Epoch: 50, train_Loss: 0.5600
training Epoch: 50, train_Loss: 0.9056
training Epoch: 50, train_Loss: 0.9327
training Epoch: 50, train_Loss: 1.9921
training Epoch: 50, train_Loss: 0.5258
training Epoch: 50, train_Loss: 0.9436
training Epoch: 50, train_Loss: 2.0332
training Epoch: 50, train_Loss: 1.3220
training Epoch: 50, train_Loss: 0.3745
training Epoch: 50, train_Loss: 0.7956
training Epoch: 50, train_Loss: 0.4899
training Epoch: 50, train_Loss: 1.9776
training Epoch: 50, train_Loss: 2.4625
training Epoch: 50, train_Loss: 0.3622
training Epoch: 50, train_Loss: 0.5744
training Epoch: 50, train_Loss: 0.6529
training Epoch: 50, train_Loss: 1.0157
training Epoch: 50, train_Loss: 3.0584
training Epoch: 50, train_Loss: 0.3922
training Epoch: 50, train_Loss: 3.0200
training Epoch: 50, train_Loss: 1.1250
training Epoch: 50, train_Loss: 0.8579
training Epoch: 50, train_Loss: 0.4190
training Epoch: 50, train_Loss: 1.5251
training Epoch: 50, train_Loss: 1.4663
training Epoch: 50, train_Loss: 1.0267
training Epoch: 50, train_Loss: 1.2280
training Epoch: 50, train_Loss: 0.5919
training Epoch: 50, train_Loss: 0.6682
training Epoch: 50, train_Loss: 1.1082
training Epoch: 50, train_Loss: 0.5028
training Epoch: 50, train_Loss: 0.6711
training Epoch: 50, train_Loss: 0.3490
training Epoch: 50, train_Loss: 1.9343
training Epoch: 50, train_Loss: 0.8968
training Epoch: 50, train_Loss: 0.4486
training Epoch: 50, train_Loss: 0.4034
training Epoch: 50, train_Loss: 1.0270
training Epoch: 50, train_Loss: 0.9914
training Epoch: 50, train_Loss: 1.0515
training Epoch: 50, train_Loss: 0.4089
training Epoch: 50, train_Loss: 0.7929
training Epoch: 50, train_Loss: 0.2115
training Epoch: 50, train_Loss: 0.7703
training Epoch: 50, train_Loss: 0.6459
training Epoch: 50, train_Loss: 1.5748
training Epoch: 50, train_Loss: 1.8150
training Epoch: 50, train_Loss: 0.5169
training Epoch: 50, train_Loss: 0.9060
training Epoch: 50, train_Loss: 2.6997
training Epoch: 50, train_Loss: 2.3113
training Epoch: 50, train_Loss: 0.3979
training Epoch: 50, train_Loss: 0.5980
training Epoch: 50, train_Loss: 0.4295
training Epoch: 50, train_Loss: 1.5059
training Epoch: 50, train_Loss: 1.0016
training Epoch: 50, train_Loss: 0.7139
training Epoch: 50, train_Loss: 0.9714
training Epoch: 50, train_Loss: 0.8438
training Epoch: 50, train_Loss: 1.1869
training Epoch: 50, train_Loss: 0.3840
training Epoch: 50, train_Loss: 1.3795
training Epoch: 50, train_Loss: 0.5171
training Epoch: 50, train_Loss: 0.8597
training Epoch: 50, train_Loss: 0.6546
training Epoch: 50, train_Loss: 0.4212
training Epoch: 50, train_Loss: 1.1996
training Epoch: 50, train_Loss: 0.4078
training Epoch: 50, train_Loss: 0.5292
training Epoch: 50, train_Loss: 1.2964
training Epoch: 50, train_Loss: 0.3081
training Epoch: 50, train_Loss: 0.6101
training Epoch: 50, train_Loss: 0.6669
training Epoch: 50, train_Loss: 0.9253
training Epoch: 50, train_Loss: 1.4754
training Epoch: 50, train_Loss: 1.7455
training Epoch: 50, train_Loss: 1.0403
training Epoch: 50, train_Loss: 3.1525
training Epoch: 50, train_Loss: 0.8079
training Epoch: 50, train_Loss: 1.4664
training Epoch: 50, train_Loss: 0.3304
training Epoch: 50, train_Loss: 1.4557
training Epoch: 50, train_Loss: 0.4154
training Epoch: 50, train_Loss: 1.8103
training Epoch: 50, train_Loss: 1.0921
training Epoch: 50, train_Loss: 0.5277
training Epoch: 50, train_Loss: 1.2397
training Epoch: 50, train_Loss: 0.6011
training Epoch: 50, train_Loss: 0.5378
training Epoch: 50, train_Loss: 0.7863
training Epoch: 50, train_Loss: 0.7829
training Epoch: 50, train_Loss: 3.7732
training Epoch: 50, train_Loss: 0.5844
training Epoch: 50, train_Loss: 0.6028
training Epoch: 50, train_Loss: 1.3261
training Epoch: 50, train_Loss: 1.1245
training Epoch: 50, train_Loss: 0.7571
training Epoch: 50, train_Loss: 0.5300
training Epoch: 50, train_Loss: 1.4507
training Epoch: 50, train_Loss: 1.4096
training Epoch: 50, train_Loss: 0.2559
training Epoch: 50, train_Loss: 0.7629
training Epoch: 50, train_Loss: 0.5583
training Epoch: 50, train_Loss: 0.2919
training Epoch: 50, train_Loss: 2.0800
training Epoch: 50, train_Loss: 1.6866
training Epoch: 50, train_Loss: 0.6336
training Epoch: 50, train_Loss: 1.0832
training Epoch: 50, train_Loss: 0.6807
training Epoch: 50, train_Loss: 1.6581
training Epoch: 50, train_Loss: 1.5765
training Epoch: 50, train_Loss: 1.2402
training Epoch: 50, train_Loss: 0.7900
training Epoch: 50, train_Loss: 0.6293
training Epoch: 50, train_Loss: 0.8044
training Epoch: 50, train_Loss: 2.5675
training Epoch: 50, train_Loss: 0.6310
training Epoch: 50, train_Loss: 0.4595
training Epoch: 50, train_Loss: 2.7246
training Epoch: 50, train_Loss: 1.1751
training Epoch: 50, train_Loss: 1.5344
training Epoch: 50, train_Loss: 1.1116
training Epoch: 50, train_Loss: 2.2894
training Epoch: 50, train_Loss: 1.2953
training Epoch: 50, train_Loss: 1.0132
training Epoch: 50, train_Loss: 1.5841
training Epoch: 50, train_Loss: 0.9578
training Epoch: 50, train_Loss: 0.5275
training Epoch: 50, train_Loss: 0.6293
training Epoch: 50, train_Loss: 0.9197
training Epoch: 50, train_Loss: 0.9747
training Epoch: 50, train_Loss: 1.1853
training Epoch: 50, train_Loss: 0.7567
training Epoch: 50, train_Loss: 0.9825
training Epoch: 50, train_Loss: 0.4455
training Epoch: 50, train_Loss: 1.1761
training Epoch: 50, train_Loss: 1.4851
training Epoch: 50, train_Loss: 1.0673
training Epoch: 50, train_Loss: 1.2469
training Epoch: 50, train_Loss: 1.4250
training Epoch: 50, train_Loss: 0.3668
training Epoch: 50, train_Loss: 0.3846
training Epoch: 50, train_Loss: 1.1376
training Epoch: 50, train_Loss: 0.9563
training Epoch: 50, train_Loss: 0.3214
training Epoch: 50, train_Loss: 1.7852
training Epoch: 50, train_Loss: 1.0143
training Epoch: 50, train_Loss: 0.3838
training Epoch: 50, train_Loss: 1.4860
training Epoch: 50, train_Loss: 1.3359
training Epoch: 50, train_Loss: 1.2565
training Epoch: 50, train_Loss: 1.3042
training Epoch: 50, train_Loss: 0.4953
training Epoch: 50, train_Loss: 0.9556
training Epoch: 50, train_Loss: 1.8552
training Epoch: 50, train_Loss: 0.6751
training Epoch: 50, train_Loss: 0.8265
training Epoch: 50, train_Loss: 0.7656
training Epoch: 50, train_Loss: 0.7950
training Epoch: 50, train_Loss: 0.9426
training Epoch: 50, train_Loss: 1.4759
training Epoch: 50, train_Loss: 0.9494
training Epoch: 50, train_Loss: 1.8584
training Epoch: 50, train_Loss: 2.5592
training Epoch: 50, train_Loss: 0.6623
training Epoch: 50, train_Loss: 1.1037
training Epoch: 50, train_Loss: 0.5031
training Epoch: 50, train_Loss: 0.7106
training Epoch: 50, train_Loss: 0.6667
training Epoch: 50, train_Loss: 1.5132
training Epoch: 50, train_Loss: 1.0915
training Epoch: 50, train_Loss: 0.8141
training Epoch: 50, train_Loss: 0.7927
training Epoch: 50, train_Loss: 1.4120
training Epoch: 50, train_Loss: 1.2850
training Epoch: 50, train_Loss: 0.8057
training Epoch: 50, train_Loss: 0.7531
training Epoch: 50, train_Loss: 0.3350
training Epoch: 50, train_Loss: 0.4022
training Epoch: 50, train_Loss: 1.0651
training Epoch: 50, train_Loss: 0.3347
training Epoch: 50, train_Loss: 0.8391
training Epoch: 50, train_Loss: 0.9137
training Epoch: 50, train_Loss: 0.7006
training Epoch: 50, train_Loss: 2.1410
training Epoch: 50, train_Loss: 1.0376
training Epoch: 50, train_Loss: 1.9192
training Epoch: 50, train_Loss: 1.0250
training Epoch: 50, train_Loss: 2.9099
training Epoch: 50, train_Loss: 0.5263
training Epoch: 50, train_Loss: 1.7285
training Epoch: 50, train_Loss: 1.5527
training Epoch: 50, train_Loss: 0.3864
training Epoch: 50, train_Loss: 0.3182
training Epoch: 50, train_Loss: 0.6201
training Epoch: 50, train_Loss: 0.3435
training Epoch: 50, train_Loss: 1.4622
training Epoch: 50, train_Loss: 0.9016
training Epoch: 50, train_Loss: 2.1836
training Epoch: 50, train_Loss: 0.8523
training Epoch: 50, train_Loss: 0.8540
training Epoch: 50, train_Loss: 0.2185
training Epoch: 50, train_Loss: 1.6711
training Epoch: 50, train_Loss: 0.2346
training Epoch: 50, train_Loss: 0.2049
training Epoch: 50, train_Loss: 0.8292
training Epoch: 50, train_Loss: 0.7303
training Epoch: 50, train_Loss: 0.9690
training Epoch: 50, train_Loss: 0.5061
training Epoch: 50, train_Loss: 2.4165
training Epoch: 50, train_Loss: 0.2278
training Epoch: 50, train_Loss: 0.1562
training Epoch: 50, train_Loss: 1.3126
training Epoch: 50, train_Loss: 1.9705
training Epoch: 50, train_Loss: 0.2803
training Epoch: 50, train_Loss: 0.2871
training Epoch: 50, train_Loss: 0.9080
training Epoch: 50, train_Loss: 1.5259
training Epoch: 50, train_Loss: 0.3936
training Epoch: 50, train_Loss: 0.5354
training Epoch: 50, train_Loss: 2.3290
training Epoch: 50, train_Loss: 0.3328
training Epoch: 50, train_Loss: 0.8723
training Epoch: 50, train_Loss: 2.2980
training Epoch: 50, train_Loss: 1.0423
training Epoch: 50, train_Loss: 0.5605
training Epoch: 50, train_Loss: 3.6809
training Epoch: 50, train_Loss: 0.6776
training Epoch: 50, train_Loss: 0.7281
training Epoch: 50, train_Loss: 0.5160
training Epoch: 50, train_Loss: 0.9646
training Epoch: 50, train_Loss: 1.0374
training Epoch: 50, train_Loss: 1.2214
training Epoch: 50, train_Loss: 1.1627
training Epoch: 50, train_Loss: 0.7846
training Epoch: 50, train_Loss: 0.7521
training Epoch: 50, train_Loss: 1.3211
training Epoch: 50, train_Loss: 0.7688
training Epoch: 50, train_Loss: 0.5787
training Epoch: 50, train_Loss: 2.2654
training Epoch: 50, train_Loss: 0.6473
training Epoch: 50, train_Loss: 0.8758
training Epoch: 50, train_Loss: 0.7514
training Epoch: 50, train_Loss: 1.3099
training Epoch: 50, train_Loss: 1.8380
training Epoch: 50, train_Loss: 0.3537
training Epoch: 50, train_Loss: 1.8368
training Epoch: 50, train_Loss: 2.2509
training Epoch: 50, train_Loss: 0.5632
training Epoch: 50, train_Loss: 0.3040
training Epoch: 50, train_Loss: 0.5963
training Epoch: 50, train_Loss: 1.8999
training Epoch: 50, train_Loss: 0.5682
training Epoch: 50, train_Loss: 0.6184
training Epoch: 50, train_Loss: 0.6682
training Epoch: 50, train_Loss: 0.4672
training Epoch: 50, train_Loss: 1.8116
training Epoch: 50, train_Loss: 0.5781
training Epoch: 50, train_Loss: 0.3985
training Epoch: 50, train_Loss: 1.0362
training Epoch: 50, train_Loss: 0.2644
training Epoch: 50, train_Loss: 1.9722
training Epoch: 50, train_Loss: 1.7245
training Epoch: 50, train_Loss: 1.6983
training Epoch: 50, train_Loss: 0.9413
training Epoch: 50, train_Loss: 1.3851
training Epoch: 50, train_Loss: 0.5732
training Epoch: 50, train_Loss: 0.7142
training Epoch: 50, train_Loss: 0.6521
training Epoch: 50, train_Loss: 0.7897
training Epoch: 50, train_Loss: 0.9430
training Epoch: 50, train_Loss: 0.6715
training Epoch: 50, train_Loss: 2.0440
training Epoch: 50, train_Loss: 0.7494
training Epoch: 50, train_Loss: 2.9660
training Epoch: 50, train_Loss: 2.0902
training Epoch: 50, train_Loss: 0.4397
training Epoch: 50, train_Loss: 0.3747
training Epoch: 50, train_Loss: 0.6736
training Epoch: 50, train_Loss: 1.1696
training Epoch: 50, train_Loss: 0.7711
training Epoch: 50, train_Loss: 0.5301
training Epoch: 50, train_Loss: 1.2283
training Epoch: 50, train_Loss: 0.4967
training Epoch: 50, train_Loss: 0.4038
training Epoch: 50, train_Loss: 1.3390
training Epoch: 50, train_Loss: 1.4958
training Epoch: 50, train_Loss: 1.5992
training Epoch: 50, train_Loss: 1.7251
training Epoch: 50, train_Loss: 1.2586
training Epoch: 50, train_Loss: 0.3731
training Epoch: 50, train_Loss: 1.8609
training Epoch: 50, train_Loss: 0.6377
training Epoch: 50, train_Loss: 1.7679
training Epoch: 50, train_Loss: 0.3972
training Epoch: 50, train_Loss: 1.6493
training Epoch: 50, train_Loss: 0.7640
training Epoch: 50, train_Loss: 2.2749
training Epoch: 50, train_Loss: 0.5528
training Epoch: 50, train_Loss: 1.1292
training Epoch: 50, train_Loss: 2.1639
training Epoch: 50, train_Loss: 0.4629
training Epoch: 50, train_Loss: 0.3808
training Epoch: 50, train_Loss: 1.3970
training Epoch: 50, train_Loss: 0.6789
training Epoch: 50, train_Loss: 0.4459
training Epoch: 50, train_Loss: 0.3296
training Epoch: 50, train_Loss: 0.7308
training Epoch: 50, train_Loss: 0.5790
training Epoch: 50, train_Loss: 0.3435
training Epoch: 50, train_Loss: 0.3873
training Epoch: 50, train_Loss: 0.4441
training Epoch: 50, train_Loss: 0.7546
training Epoch: 50, train_Loss: 0.5748
training Epoch: 50, train_Loss: 0.3599
training Epoch: 50, train_Loss: 2.4974
training Epoch: 50, train_Loss: 1.4735
training Epoch: 50, train_Loss: 0.4917
training Epoch: 50, train_Loss: 0.1311
training Epoch: 50, train_Loss: 3.9904
training Epoch: 50, train_Loss: 0.7424
training Epoch: 50, train_Loss: 0.3371
training Epoch: 50, train_Loss: 1.9628
training Epoch: 50, train_Loss: 2.2322
training Epoch: 50, train_Loss: 1.1070
training Epoch: 50, train_Loss: 0.9970
training Epoch: 50, train_Loss: 0.4217
training Epoch: 50, train_Loss: 1.0444
training Epoch: 50, train_Loss: 1.6673
training Epoch: 50, train_Loss: 1.6718
training Epoch: 50, train_Loss: 0.3955
training Epoch: 50, train_Loss: 0.6591
training Epoch: 50, train_Loss: 1.2199
training Epoch: 50, train_Loss: 1.4787
training Epoch: 50, train_Loss: 0.5740
training Epoch: 50, train_Loss: 1.1057
training Epoch: 50, train_Loss: 0.4112
training Epoch: 50, train_Loss: 1.3847
training Epoch: 50, train_Loss: 0.5953
training Epoch: 50, train_Loss: 0.9387
training Epoch: 50, train_Loss: 0.4859
training Epoch: 50, train_Loss: 1.8246
training Epoch: 50, train_Loss: 0.6486
training Epoch: 50, train_Loss: 0.3938
training Epoch: 50, train_Loss: 1.2419
training Epoch: 50, train_Loss: 1.9772
training Epoch: 50, train_Loss: 0.9935
training Epoch: 50, train_Loss: 0.8236
training Epoch: 50, train_Loss: 1.8930
training Epoch: 50, train_Loss: 2.0603
training Epoch: 50, train_Loss: 0.2096
training Epoch: 50, train_Loss: 1.4801
training Epoch: 50, train_Loss: 0.5722
training Epoch: 50, train_Loss: 1.2797
training Epoch: 50, train_Loss: 0.7667
training Epoch: 50, train_Loss: 0.6203
training Epoch: 50, train_Loss: 0.6971
training Epoch: 50, train_Loss: 0.4932
training Epoch: 50, train_Loss: 0.7811
training Epoch: 50, train_Loss: 0.8429
training Epoch: 50, train_Loss: 0.4527
training Epoch: 50, train_Loss: 2.0144
training Epoch: 50, train_Loss: 0.4464
training Epoch: 50, train_Loss: 0.8427
training Epoch: 50, train_Loss: 0.4346
training Epoch: 50, train_Loss: 0.7322
training Epoch: 50, train_Loss: 0.9544
training Epoch: 50, train_Loss: 1.1268
training Epoch: 50, train_Loss: 2.6691
training Epoch: 50, train_Loss: 1.6732
training Epoch: 50, train_Loss: 0.4071
training Epoch: 50, train_Loss: 0.9106
training Epoch: 50, train_Loss: 0.6199
training Epoch: 50, train_Loss: 1.2428
training Epoch: 50, train_Loss: 0.7903
training Epoch: 50, train_Loss: 0.4739
training Epoch: 50, train_Loss: 0.4434
training Epoch: 50, train_Loss: 0.3388
training Epoch: 50, train_Loss: 0.5293
training Epoch: 50, train_Loss: 1.8737
training Epoch: 50, train_Loss: 0.8426
training Epoch: 50, train_Loss: 1.3215
training Epoch: 50, train_Loss: 2.1162
training Epoch: 50, train_Loss: 0.2008
training Epoch: 50, train_Loss: 1.7014
training Epoch: 50, train_Loss: 1.1682
training Epoch: 50, train_Loss: 1.6921
training Epoch: 50, train_Loss: 1.2481
training Epoch: 50, train_Loss: 1.1643
training Epoch: 50, train_Loss: 0.4448
training Epoch: 50, train_Loss: 1.4043
training Epoch: 50, train_Loss: 0.4258
training Epoch: 50, train_Loss: 0.3493
fold,epoch,train_loss: 4 49 1.083822
fold,epoch,train_loss: 4 50 1.0867667
fold,epoch,train_loss: 4 51 1.0843258
fold,epoch,train_loss: 4 52 1.0979241
fold,epoch,train_loss: 4 53 1.091372
fold,epoch,train_loss: 4 54 1.0938244
fold,epoch,train_loss: 4 55 1.0839295
fold,epoch,train_loss: 4 56 1.0899659
fold,epoch,train_loss: 4 57 1.0891948
fold,epoch,train_loss: 4 58 1.0918676
fold,epoch,train_loss: 4 59 1.085577
fold,epoch,train_loss: 4 60 1.0882616
fold,epoch,train_loss: 4 61 1.0959752
fold,epoch,train_loss: 4 62 1.0921211
fold,epoch,train_loss: 4 63 1.087488
fold,epoch,train_loss: 4 64 1.0901005
fold,epoch,train_loss: 4 65 1.0834404
fold,epoch,train_loss: 4 66 1.08625
fold,epoch,train_loss: 4 67 1.0879631
fold,epoch,train_loss: 4 68 1.0859721
fold,epoch,train_loss: 4 69 1.0930538
fold,epoch,train_loss: 4 70 1.0945594
fold,epoch,train_loss: 4 71 1.0928735
fold,epoch,train_loss: 4 72 1.0897565
fold,epoch,train_loss: 4 73 1.0942404
fold,epoch,train_loss: 4 74 1.0840322
fold,epoch,train_loss: 4 75 1.0888968
fold,epoch,train_loss: 4 76 1.092776
fold,epoch,train_loss: 4 77 1.0934385
fold,epoch,train_loss: 4 78 1.0886095
fold,epoch,train_loss: 4 79 1.0868984
fold,epoch,train_loss: 4 80 1.0886523
fold,epoch,train_loss: 4 81 1.0902832
fold,epoch,train_loss: 4 82 1.0879966
fold,epoch,train_loss: 4 83 1.0930222
fold,epoch,train_loss: 4 84 1.0906445
fold,epoch,train_loss: 4 85 1.0884032
fold,epoch,train_loss: 4 86 1.0874217
fold,epoch,train_loss: 4 87 1.0902889
fold,epoch,train_loss: 4 88 1.0903554
fold,epoch,train_loss: 4 89 1.0896381
fold,epoch,train_loss: 4 90 1.0856432
fold,epoch,train_loss: 4 91 1.0884129
fold,epoch,train_loss: 4 92 1.0870788
fold,epoch,train_loss: 4 93 1.0908666
fold,epoch,train_loss: 4 94 1.0889018
fold,epoch,train_loss: 4 95 1.0889997
fold,epoch,train_loss: 4 96 1.0916315
fold,epoch,train_loss: 4 97 1.0921319
fold,epoch,train_loss: 4 98 1.0855365
training Epoch: 100, train_Loss: 1.4320
training Epoch: 100, train_Loss: 1.1422
training Epoch: 100, train_Loss: 0.7592
training Epoch: 100, train_Loss: 2.5441
training Epoch: 100, train_Loss: 1.3158
training Epoch: 100, train_Loss: 0.5296
training Epoch: 100, train_Loss: 0.3582
training Epoch: 100, train_Loss: 1.1111
training Epoch: 100, train_Loss: 0.5088
training Epoch: 100, train_Loss: 0.6831
training Epoch: 100, train_Loss: 0.5795
training Epoch: 100, train_Loss: 0.6173
training Epoch: 100, train_Loss: 0.3228
training Epoch: 100, train_Loss: 2.2585
training Epoch: 100, train_Loss: 1.3818
training Epoch: 100, train_Loss: 1.9971
training Epoch: 100, train_Loss: 1.6914
training Epoch: 100, train_Loss: 0.7358
training Epoch: 100, train_Loss: 0.6665
training Epoch: 100, train_Loss: 0.6635
training Epoch: 100, train_Loss: 1.2092
training Epoch: 100, train_Loss: 0.7766
training Epoch: 100, train_Loss: 0.3615
training Epoch: 100, train_Loss: 1.7084
training Epoch: 100, train_Loss: 1.6715
training Epoch: 100, train_Loss: 0.8582
training Epoch: 100, train_Loss: 0.3572
training Epoch: 100, train_Loss: 0.4229
training Epoch: 100, train_Loss: 0.3418
training Epoch: 100, train_Loss: 0.9415
training Epoch: 100, train_Loss: 1.4630
training Epoch: 100, train_Loss: 0.2323
training Epoch: 100, train_Loss: 1.8584
training Epoch: 100, train_Loss: 1.4365
training Epoch: 100, train_Loss: 1.3654
training Epoch: 100, train_Loss: 3.0372
training Epoch: 100, train_Loss: 0.3154
training Epoch: 100, train_Loss: 0.2362
training Epoch: 100, train_Loss: 1.3113
training Epoch: 100, train_Loss: 0.2466
training Epoch: 100, train_Loss: 0.9004
training Epoch: 100, train_Loss: 0.2462
training Epoch: 100, train_Loss: 0.2644
training Epoch: 100, train_Loss: 2.6313
training Epoch: 100, train_Loss: 0.7765
training Epoch: 100, train_Loss: 2.0003
training Epoch: 100, train_Loss: 0.3183
training Epoch: 100, train_Loss: 0.7511
training Epoch: 100, train_Loss: 1.5673
training Epoch: 100, train_Loss: 1.1750
training Epoch: 100, train_Loss: 1.8729
training Epoch: 100, train_Loss: 0.8265
training Epoch: 100, train_Loss: 0.4105
training Epoch: 100, train_Loss: 0.5161
training Epoch: 100, train_Loss: 0.5639
training Epoch: 100, train_Loss: 1.0004
training Epoch: 100, train_Loss: 1.7573
training Epoch: 100, train_Loss: 0.6934
training Epoch: 100, train_Loss: 1.9841
training Epoch: 100, train_Loss: 1.3127
training Epoch: 100, train_Loss: 0.7646
training Epoch: 100, train_Loss: 0.8281
training Epoch: 100, train_Loss: 0.6534
training Epoch: 100, train_Loss: 1.8311
training Epoch: 100, train_Loss: 2.8670
training Epoch: 100, train_Loss: 0.5952
training Epoch: 100, train_Loss: 0.5919
training Epoch: 100, train_Loss: 0.9059
training Epoch: 100, train_Loss: 1.1371
training Epoch: 100, train_Loss: 0.6345
training Epoch: 100, train_Loss: 1.4406
training Epoch: 100, train_Loss: 2.6105
training Epoch: 100, train_Loss: 0.5865
training Epoch: 100, train_Loss: 0.7533
training Epoch: 100, train_Loss: 1.0676
training Epoch: 100, train_Loss: 1.2267
training Epoch: 100, train_Loss: 0.5754
training Epoch: 100, train_Loss: 1.7026
training Epoch: 100, train_Loss: 0.9027
training Epoch: 100, train_Loss: 1.0061
training Epoch: 100, train_Loss: 0.6558
training Epoch: 100, train_Loss: 1.3371
training Epoch: 100, train_Loss: 1.7288
training Epoch: 100, train_Loss: 0.8285
training Epoch: 100, train_Loss: 0.3314
training Epoch: 100, train_Loss: 1.6750
training Epoch: 100, train_Loss: 1.0186
training Epoch: 100, train_Loss: 0.4392
training Epoch: 100, train_Loss: 0.7922
training Epoch: 100, train_Loss: 1.6588
training Epoch: 100, train_Loss: 0.6912
training Epoch: 100, train_Loss: 1.2103
training Epoch: 100, train_Loss: 1.0280
training Epoch: 100, train_Loss: 2.2222
training Epoch: 100, train_Loss: 0.2610
training Epoch: 100, train_Loss: 0.9963
training Epoch: 100, train_Loss: 0.3753
training Epoch: 100, train_Loss: 0.4900
training Epoch: 100, train_Loss: 0.6608
training Epoch: 100, train_Loss: 0.3330
training Epoch: 100, train_Loss: 0.7161
training Epoch: 100, train_Loss: 0.5187
training Epoch: 100, train_Loss: 2.1173
training Epoch: 100, train_Loss: 1.1448
training Epoch: 100, train_Loss: 0.9804
training Epoch: 100, train_Loss: 0.3132
training Epoch: 100, train_Loss: 0.3276
training Epoch: 100, train_Loss: 0.8111
training Epoch: 100, train_Loss: 1.4790
training Epoch: 100, train_Loss: 1.0593
training Epoch: 100, train_Loss: 1.0852
training Epoch: 100, train_Loss: 1.3437
training Epoch: 100, train_Loss: 0.3301
training Epoch: 100, train_Loss: 2.1450
training Epoch: 100, train_Loss: 0.7282
training Epoch: 100, train_Loss: 0.3780
training Epoch: 100, train_Loss: 0.8103
training Epoch: 100, train_Loss: 0.6090
training Epoch: 100, train_Loss: 0.6997
training Epoch: 100, train_Loss: 0.6936
training Epoch: 100, train_Loss: 0.9291
training Epoch: 100, train_Loss: 0.4476
training Epoch: 100, train_Loss: 1.5152
training Epoch: 100, train_Loss: 0.6936
training Epoch: 100, train_Loss: 0.8413
training Epoch: 100, train_Loss: 1.3555
training Epoch: 100, train_Loss: 1.4787
training Epoch: 100, train_Loss: 0.9358
training Epoch: 100, train_Loss: 2.7988
training Epoch: 100, train_Loss: 0.3646
training Epoch: 100, train_Loss: 1.0070
training Epoch: 100, train_Loss: 0.8817
training Epoch: 100, train_Loss: 0.4979
training Epoch: 100, train_Loss: 0.6275
training Epoch: 100, train_Loss: 1.3991
training Epoch: 100, train_Loss: 1.0137
training Epoch: 100, train_Loss: 1.5176
training Epoch: 100, train_Loss: 1.5640
training Epoch: 100, train_Loss: 0.9114
training Epoch: 100, train_Loss: 0.5994
training Epoch: 100, train_Loss: 0.4182
training Epoch: 100, train_Loss: 0.4660
training Epoch: 100, train_Loss: 2.2022
training Epoch: 100, train_Loss: 2.0727
training Epoch: 100, train_Loss: 0.8283
training Epoch: 100, train_Loss: 0.3876
training Epoch: 100, train_Loss: 0.6895
training Epoch: 100, train_Loss: 0.4974
training Epoch: 100, train_Loss: 1.2373
training Epoch: 100, train_Loss: 0.7827
training Epoch: 100, train_Loss: 1.1285
training Epoch: 100, train_Loss: 0.6029
training Epoch: 100, train_Loss: 0.6964
training Epoch: 100, train_Loss: 0.6286
training Epoch: 100, train_Loss: 1.8139
training Epoch: 100, train_Loss: 1.3786
training Epoch: 100, train_Loss: 0.3670
training Epoch: 100, train_Loss: 3.3674
training Epoch: 100, train_Loss: 0.4244
training Epoch: 100, train_Loss: 1.2084
training Epoch: 100, train_Loss: 0.4137
training Epoch: 100, train_Loss: 1.4201
training Epoch: 100, train_Loss: 0.7346
training Epoch: 100, train_Loss: 0.9154
training Epoch: 100, train_Loss: 1.1687
training Epoch: 100, train_Loss: 0.5893
training Epoch: 100, train_Loss: 1.3166
training Epoch: 100, train_Loss: 0.5440
training Epoch: 100, train_Loss: 0.7067
training Epoch: 100, train_Loss: 2.6404
training Epoch: 100, train_Loss: 1.1678
training Epoch: 100, train_Loss: 2.1317
training Epoch: 100, train_Loss: 0.5336
training Epoch: 100, train_Loss: 0.8750
training Epoch: 100, train_Loss: 0.8432
training Epoch: 100, train_Loss: 1.3498
training Epoch: 100, train_Loss: 1.0612
training Epoch: 100, train_Loss: 0.3164
training Epoch: 100, train_Loss: 0.9766
training Epoch: 100, train_Loss: 1.6774
training Epoch: 100, train_Loss: 1.3941
training Epoch: 100, train_Loss: 0.6398
training Epoch: 100, train_Loss: 0.3574
training Epoch: 100, train_Loss: 0.5431
training Epoch: 100, train_Loss: 1.0636
training Epoch: 100, train_Loss: 1.1460
training Epoch: 100, train_Loss: 0.8797
training Epoch: 100, train_Loss: 0.5372
training Epoch: 100, train_Loss: 0.7316
training Epoch: 100, train_Loss: 0.6121
training Epoch: 100, train_Loss: 2.1042
training Epoch: 100, train_Loss: 0.6290
training Epoch: 100, train_Loss: 1.6593
training Epoch: 100, train_Loss: 0.6462
training Epoch: 100, train_Loss: 1.6445
training Epoch: 100, train_Loss: 1.1234
training Epoch: 100, train_Loss: 0.2082
training Epoch: 100, train_Loss: 1.8199
training Epoch: 100, train_Loss: 1.2770
training Epoch: 100, train_Loss: 0.7274
training Epoch: 100, train_Loss: 1.1552
training Epoch: 100, train_Loss: 0.7949
training Epoch: 100, train_Loss: 0.9580
training Epoch: 100, train_Loss: 0.8434
training Epoch: 100, train_Loss: 1.0730
training Epoch: 100, train_Loss: 0.9159
training Epoch: 100, train_Loss: 1.0305
training Epoch: 100, train_Loss: 0.9557
training Epoch: 100, train_Loss: 0.3682
training Epoch: 100, train_Loss: 0.4323
training Epoch: 100, train_Loss: 1.4460
training Epoch: 100, train_Loss: 0.3199
training Epoch: 100, train_Loss: 1.2551
training Epoch: 100, train_Loss: 1.6939
training Epoch: 100, train_Loss: 1.1003
training Epoch: 100, train_Loss: 0.2247
training Epoch: 100, train_Loss: 0.5036
training Epoch: 100, train_Loss: 2.2510
training Epoch: 100, train_Loss: 2.5822
training Epoch: 100, train_Loss: 0.5721
training Epoch: 100, train_Loss: 2.0195
training Epoch: 100, train_Loss: 0.3583
training Epoch: 100, train_Loss: 0.9326
training Epoch: 100, train_Loss: 0.2344
training Epoch: 100, train_Loss: 0.7535
training Epoch: 100, train_Loss: 1.0530
training Epoch: 100, train_Loss: 0.8873
training Epoch: 100, train_Loss: 0.4468
training Epoch: 100, train_Loss: 0.8133
training Epoch: 100, train_Loss: 0.3493
training Epoch: 100, train_Loss: 0.3436
training Epoch: 100, train_Loss: 2.2508
training Epoch: 100, train_Loss: 2.3516
training Epoch: 100, train_Loss: 0.3687
training Epoch: 100, train_Loss: 0.4644
training Epoch: 100, train_Loss: 2.9113
training Epoch: 100, train_Loss: 0.4258
training Epoch: 100, train_Loss: 1.1617
training Epoch: 100, train_Loss: 0.5344
training Epoch: 100, train_Loss: 1.3868
training Epoch: 100, train_Loss: 2.2168
training Epoch: 100, train_Loss: 0.8094
training Epoch: 100, train_Loss: 2.6932
training Epoch: 100, train_Loss: 1.5932
training Epoch: 100, train_Loss: 1.1564
training Epoch: 100, train_Loss: 2.1318
training Epoch: 100, train_Loss: 0.6587
training Epoch: 100, train_Loss: 1.3523
training Epoch: 100, train_Loss: 0.5992
training Epoch: 100, train_Loss: 1.3786
training Epoch: 100, train_Loss: 0.8535
training Epoch: 100, train_Loss: 1.6034
training Epoch: 100, train_Loss: 0.9090
training Epoch: 100, train_Loss: 1.9656
training Epoch: 100, train_Loss: 1.3009
training Epoch: 100, train_Loss: 1.3922
training Epoch: 100, train_Loss: 0.9758
training Epoch: 100, train_Loss: 0.5164
training Epoch: 100, train_Loss: 0.9052
training Epoch: 100, train_Loss: 1.3262
training Epoch: 100, train_Loss: 0.7784
training Epoch: 100, train_Loss: 0.8648
training Epoch: 100, train_Loss: 0.6315
training Epoch: 100, train_Loss: 0.8320
training Epoch: 100, train_Loss: 1.2046
training Epoch: 100, train_Loss: 0.7209
training Epoch: 100, train_Loss: 0.3093
training Epoch: 100, train_Loss: 2.0226
training Epoch: 100, train_Loss: 0.3454
training Epoch: 100, train_Loss: 0.4559
training Epoch: 100, train_Loss: 2.9711
training Epoch: 100, train_Loss: 1.2911
training Epoch: 100, train_Loss: 2.0204
training Epoch: 100, train_Loss: 1.5166
training Epoch: 100, train_Loss: 1.2009
training Epoch: 100, train_Loss: 0.2854
training Epoch: 100, train_Loss: 2.6666
training Epoch: 100, train_Loss: 0.7198
training Epoch: 100, train_Loss: 0.5999
training Epoch: 100, train_Loss: 0.7784
training Epoch: 100, train_Loss: 1.5155
training Epoch: 100, train_Loss: 0.9080
training Epoch: 100, train_Loss: 1.1158
training Epoch: 100, train_Loss: 0.7840
training Epoch: 100, train_Loss: 0.7711
training Epoch: 100, train_Loss: 2.4951
training Epoch: 100, train_Loss: 1.4018
training Epoch: 100, train_Loss: 2.3049
training Epoch: 100, train_Loss: 1.2084
training Epoch: 100, train_Loss: 2.6038
training Epoch: 100, train_Loss: 0.8595
training Epoch: 100, train_Loss: 2.4605
training Epoch: 100, train_Loss: 0.6301
training Epoch: 100, train_Loss: 0.6914
training Epoch: 100, train_Loss: 2.2488
training Epoch: 100, train_Loss: 0.7376
training Epoch: 100, train_Loss: 0.8456
training Epoch: 100, train_Loss: 1.2662
training Epoch: 100, train_Loss: 3.9152
training Epoch: 100, train_Loss: 0.6290
training Epoch: 100, train_Loss: 0.8088
training Epoch: 100, train_Loss: 1.2571
training Epoch: 100, train_Loss: 0.8166
training Epoch: 100, train_Loss: 0.5506
training Epoch: 100, train_Loss: 1.4104
training Epoch: 100, train_Loss: 0.4267
training Epoch: 100, train_Loss: 0.7514
training Epoch: 100, train_Loss: 0.6286
training Epoch: 100, train_Loss: 0.4000
training Epoch: 100, train_Loss: 0.2595
training Epoch: 100, train_Loss: 1.6728
training Epoch: 100, train_Loss: 0.8956
training Epoch: 100, train_Loss: 1.3653
training Epoch: 100, train_Loss: 1.7664
training Epoch: 100, train_Loss: 0.1729
training Epoch: 100, train_Loss: 1.3062
training Epoch: 100, train_Loss: 0.4126
training Epoch: 100, train_Loss: 0.5147
training Epoch: 100, train_Loss: 1.6833
training Epoch: 100, train_Loss: 0.2869
training Epoch: 100, train_Loss: 0.2256
training Epoch: 100, train_Loss: 1.6326
training Epoch: 100, train_Loss: 0.3542
training Epoch: 100, train_Loss: 0.8887
training Epoch: 100, train_Loss: 0.8968
training Epoch: 100, train_Loss: 0.6870
training Epoch: 100, train_Loss: 0.2601
training Epoch: 100, train_Loss: 2.5109
training Epoch: 100, train_Loss: 0.9000
training Epoch: 100, train_Loss: 0.7225
training Epoch: 100, train_Loss: 0.3942
training Epoch: 100, train_Loss: 0.6951
training Epoch: 100, train_Loss: 0.7910
training Epoch: 100, train_Loss: 1.9356
training Epoch: 100, train_Loss: 0.4353
training Epoch: 100, train_Loss: 0.3341
training Epoch: 100, train_Loss: 1.3181
training Epoch: 100, train_Loss: 1.8750
training Epoch: 100, train_Loss: 2.7678
training Epoch: 100, train_Loss: 0.9311
training Epoch: 100, train_Loss: 0.6026
training Epoch: 100, train_Loss: 0.4091
training Epoch: 100, train_Loss: 1.4116
training Epoch: 100, train_Loss: 0.5842
training Epoch: 100, train_Loss: 0.8726
training Epoch: 100, train_Loss: 0.9633
training Epoch: 100, train_Loss: 2.1696
training Epoch: 100, train_Loss: 0.6885
training Epoch: 100, train_Loss: 0.9054
training Epoch: 100, train_Loss: 0.3625
training Epoch: 100, train_Loss: 1.4068
training Epoch: 100, train_Loss: 0.3706
training Epoch: 100, train_Loss: 1.5278
training Epoch: 100, train_Loss: 1.6419
training Epoch: 100, train_Loss: 1.1681
training Epoch: 100, train_Loss: 1.5609
training Epoch: 100, train_Loss: 2.0507
training Epoch: 100, train_Loss: 1.8731
training Epoch: 100, train_Loss: 1.0471
training Epoch: 100, train_Loss: 1.0108
training Epoch: 100, train_Loss: 0.6627
training Epoch: 100, train_Loss: 0.8052
training Epoch: 100, train_Loss: 0.7838
training Epoch: 100, train_Loss: 1.7752
training Epoch: 100, train_Loss: 0.5998
training Epoch: 100, train_Loss: 1.1010
training Epoch: 100, train_Loss: 0.5126
training Epoch: 100, train_Loss: 1.8759
training Epoch: 100, train_Loss: 1.2556
training Epoch: 100, train_Loss: 0.5770
training Epoch: 100, train_Loss: 0.5943
training Epoch: 100, train_Loss: 0.4236
training Epoch: 100, train_Loss: 0.6789
training Epoch: 100, train_Loss: 0.7560
training Epoch: 100, train_Loss: 2.4130
training Epoch: 100, train_Loss: 0.8727
training Epoch: 100, train_Loss: 0.9055
training Epoch: 100, train_Loss: 0.3950
training Epoch: 100, train_Loss: 0.9554
training Epoch: 100, train_Loss: 0.7861
training Epoch: 100, train_Loss: 0.8200
training Epoch: 100, train_Loss: 0.2727
training Epoch: 100, train_Loss: 1.4292
training Epoch: 100, train_Loss: 0.3168
training Epoch: 100, train_Loss: 1.5693
training Epoch: 100, train_Loss: 1.0525
training Epoch: 100, train_Loss: 0.5203
training Epoch: 100, train_Loss: 0.8186
training Epoch: 100, train_Loss: 0.2967
training Epoch: 100, train_Loss: 0.3737
training Epoch: 100, train_Loss: 0.4423
training Epoch: 100, train_Loss: 4.7237
training Epoch: 100, train_Loss: 1.2417
training Epoch: 100, train_Loss: 0.5277
training Epoch: 100, train_Loss: 1.3652
training Epoch: 100, train_Loss: 0.8692
training Epoch: 100, train_Loss: 0.7158
training Epoch: 100, train_Loss: 0.6819
training Epoch: 100, train_Loss: 2.0749
training Epoch: 100, train_Loss: 1.0717
training Epoch: 100, train_Loss: 1.2155
training Epoch: 100, train_Loss: 1.4808
training Epoch: 100, train_Loss: 0.4886
training Epoch: 100, train_Loss: 0.4590
training Epoch: 100, train_Loss: 0.6295
training Epoch: 100, train_Loss: 0.6095
training Epoch: 100, train_Loss: 3.1042
training Epoch: 100, train_Loss: 0.8131
training Epoch: 100, train_Loss: 0.8926
training Epoch: 100, train_Loss: 0.5139
training Epoch: 100, train_Loss: 0.7777
training Epoch: 100, train_Loss: 3.0477
training Epoch: 100, train_Loss: 0.5074
training Epoch: 100, train_Loss: 0.4979
training Epoch: 100, train_Loss: 1.1694
training Epoch: 100, train_Loss: 0.6834
training Epoch: 100, train_Loss: 1.6454
training Epoch: 100, train_Loss: 0.7288
training Epoch: 100, train_Loss: 0.8176
training Epoch: 100, train_Loss: 0.6781
training Epoch: 100, train_Loss: 0.2448
training Epoch: 100, train_Loss: 0.3229
training Epoch: 100, train_Loss: 0.4317
training Epoch: 100, train_Loss: 0.3210
training Epoch: 100, train_Loss: 1.2382
training Epoch: 100, train_Loss: 1.1249
training Epoch: 100, train_Loss: 1.2982
training Epoch: 100, train_Loss: 1.3394
training Epoch: 100, train_Loss: 0.3966
training Epoch: 100, train_Loss: 2.0912
training Epoch: 100, train_Loss: 1.3554
training Epoch: 100, train_Loss: 0.3939
training Epoch: 100, train_Loss: 3.0663
training Epoch: 100, train_Loss: 2.8329
training Epoch: 100, train_Loss: 0.6933
training Epoch: 100, train_Loss: 0.4323
training Epoch: 100, train_Loss: 2.0864
training Epoch: 100, train_Loss: 1.2497
training Epoch: 100, train_Loss: 0.6070
training Epoch: 100, train_Loss: 0.7984
training Epoch: 100, train_Loss: 0.9375
training Epoch: 100, train_Loss: 2.8582
training Epoch: 100, train_Loss: 0.6569
training Epoch: 100, train_Loss: 0.8710
training Epoch: 100, train_Loss: 0.6490
training Epoch: 100, train_Loss: 0.5143
training Epoch: 100, train_Loss: 0.3987
training Epoch: 100, train_Loss: 0.3504
training Epoch: 100, train_Loss: 0.3669
training Epoch: 100, train_Loss: 0.5066
training Epoch: 100, train_Loss: 2.3806
training Epoch: 100, train_Loss: 0.5958
training Epoch: 100, train_Loss: 2.4023
training Epoch: 100, train_Loss: 0.4663
training Epoch: 100, train_Loss: 0.4257
training Epoch: 100, train_Loss: 0.9306
training Epoch: 100, train_Loss: 3.5519
training Epoch: 100, train_Loss: 3.0753
training Epoch: 100, train_Loss: 1.0951
training Epoch: 100, train_Loss: 0.6982
training Epoch: 100, train_Loss: 0.2457
training Epoch: 100, train_Loss: 1.3044
training Epoch: 100, train_Loss: 0.3497
training Epoch: 100, train_Loss: 0.3704
training Epoch: 100, train_Loss: 0.6474
training Epoch: 100, train_Loss: 1.5336
training Epoch: 100, train_Loss: 0.4567
training Epoch: 100, train_Loss: 1.8037
training Epoch: 100, train_Loss: 1.4619
training Epoch: 100, train_Loss: 0.3376
training Epoch: 100, train_Loss: 1.0312
training Epoch: 100, train_Loss: 1.0263
training Epoch: 100, train_Loss: 3.3271
training Epoch: 100, train_Loss: 0.6457
training Epoch: 100, train_Loss: 0.9329
training Epoch: 100, train_Loss: 0.9673
training Epoch: 100, train_Loss: 1.1297
training Epoch: 100, train_Loss: 0.5750
training Epoch: 100, train_Loss: 1.8993
training Epoch: 100, train_Loss: 0.6448
training Epoch: 100, train_Loss: 0.5824
training Epoch: 100, train_Loss: 1.2737
training Epoch: 100, train_Loss: 1.5322
training Epoch: 100, train_Loss: 0.5403
training Epoch: 100, train_Loss: 0.6323
training Epoch: 100, train_Loss: 2.2607
training Epoch: 100, train_Loss: 0.9172
training Epoch: 100, train_Loss: 1.0567
training Epoch: 100, train_Loss: 1.2308
training Epoch: 100, train_Loss: 1.4448
training Epoch: 100, train_Loss: 0.3112
training Epoch: 100, train_Loss: 0.7951
training Epoch: 100, train_Loss: 0.8578
training Epoch: 100, train_Loss: 1.0244
training Epoch: 100, train_Loss: 0.4315
training Epoch: 100, train_Loss: 0.2369
training Epoch: 100, train_Loss: 0.7700
training Epoch: 100, train_Loss: 1.3765
training Epoch: 100, train_Loss: 1.0573
training Epoch: 100, train_Loss: 0.8851
training Epoch: 100, train_Loss: 1.7255
training Epoch: 100, train_Loss: 2.4237
training Epoch: 100, train_Loss: 0.4434
training Epoch: 100, train_Loss: 1.2373
training Epoch: 100, train_Loss: 1.6532
training Epoch: 100, train_Loss: 3.1128
training Epoch: 100, train_Loss: 1.4808
training Epoch: 100, train_Loss: 1.2836
training Epoch: 100, train_Loss: 1.7917
training Epoch: 100, train_Loss: 0.6025
training Epoch: 100, train_Loss: 0.7185
training Epoch: 100, train_Loss: 0.8573
training Epoch: 100, train_Loss: 1.6900
training Epoch: 100, train_Loss: 1.2047
training Epoch: 100, train_Loss: 0.7832
training Epoch: 100, train_Loss: 0.6996
training Epoch: 100, train_Loss: 1.8700
training Epoch: 100, train_Loss: 0.5215
training Epoch: 100, train_Loss: 2.3090
training Epoch: 100, train_Loss: 0.7581
training Epoch: 100, train_Loss: 2.0821
training Epoch: 100, train_Loss: 0.8946
training Epoch: 100, train_Loss: 1.3081
training Epoch: 100, train_Loss: 0.4881
training Epoch: 100, train_Loss: 0.8066
training Epoch: 100, train_Loss: 1.5861
training Epoch: 100, train_Loss: 1.0353
training Epoch: 100, train_Loss: 1.1962
training Epoch: 100, train_Loss: 2.9495
training Epoch: 100, train_Loss: 0.5831
training Epoch: 100, train_Loss: 0.6159
training Epoch: 100, train_Loss: 1.0503
training Epoch: 100, train_Loss: 0.5081
training Epoch: 100, train_Loss: 0.4226
training Epoch: 100, train_Loss: 1.1323
training Epoch: 100, train_Loss: 2.1315
training Epoch: 100, train_Loss: 2.2027
training Epoch: 100, train_Loss: 2.0614
training Epoch: 100, train_Loss: 1.4594
training Epoch: 100, train_Loss: 1.2840
training Epoch: 100, train_Loss: 3.4149
training Epoch: 100, train_Loss: 0.7114
training Epoch: 100, train_Loss: 1.6055
training Epoch: 100, train_Loss: 0.7860
training Epoch: 100, train_Loss: 1.3418
training Epoch: 100, train_Loss: 1.1371
training Epoch: 100, train_Loss: 0.6353
training Epoch: 100, train_Loss: 0.6043
training Epoch: 100, train_Loss: 0.5864
training Epoch: 100, train_Loss: 0.7561
training Epoch: 100, train_Loss: 1.3998
training Epoch: 100, train_Loss: 1.0934
training Epoch: 100, train_Loss: 0.9295
training Epoch: 100, train_Loss: 0.8377
training Epoch: 100, train_Loss: 0.7901
training Epoch: 100, train_Loss: 0.3522
training Epoch: 100, train_Loss: 0.7805
training Epoch: 100, train_Loss: 1.3660
training Epoch: 100, train_Loss: 1.0401
training Epoch: 100, train_Loss: 1.8162
training Epoch: 100, train_Loss: 1.5147
training Epoch: 100, train_Loss: 0.2838
training Epoch: 100, train_Loss: 4.3470
training Epoch: 100, train_Loss: 0.9305
training Epoch: 100, train_Loss: 2.2983
training Epoch: 100, train_Loss: 0.3419
training Epoch: 100, train_Loss: 0.9531
training Epoch: 100, train_Loss: 0.7623
training Epoch: 100, train_Loss: 1.1200
training Epoch: 100, train_Loss: 1.5878
training Epoch: 100, train_Loss: 0.8535
training Epoch: 100, train_Loss: 1.1584
training Epoch: 100, train_Loss: 1.5086
training Epoch: 100, train_Loss: 0.6739
training Epoch: 100, train_Loss: 0.4498
fold,epoch,train_loss: 4 99 1.0884007
fold,epoch,train_loss: 4 100 1.0848595
====Evaluation
fold:4, epoch:100,train:1.084859, valid:1.077838 

test_loss:0.759625

